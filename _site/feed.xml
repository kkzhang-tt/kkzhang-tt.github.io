<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-05-23T23:55:31+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Find a needle in haystack</title><subtitle></subtitle><author><name>kkzhang</name></author><entry><title type="html">Kafka: Cross-Cluster Data Mirroring</title><link href="http://localhost:4000/kafka-in-action-7.html" rel="alternate" type="text/html" title="Kafka: Cross-Cluster Data Mirroring" /><published>2023-05-20T00:00:00+08:00</published><updated>2023-05-20T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-7</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-7.html">&lt;p&gt;我们把 Kafka 集群间的数据复制叫做&lt;strong&gt;镜像（mirroring）&lt;/strong&gt;。Kafka 内置的跨集群复制工具是 &lt;strong&gt;MirrorMaker&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;1-跨集群镜像的使用场景&quot;&gt;1. 跨集群镜像的使用场景&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;区域集群与中心集群&lt;/p&gt;

    &lt;p&gt;一个公司会有多个数据中心，分布在不同的地域，每个数据中心都有自己的 Kafka 集群。有些应用程序只需要与本地 Kafka 集群通信，有些需要访问多个数据中心的数据，需要把其他数据中心的集群数据镜像到一个中心集群上。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;冗余（&lt;em&gt;DR&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;作为 Kafka 主集群备份，当主集群不可用时，将客户端流量路由到备份集群。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2-多集群架构&quot;&gt;2. 多集群架构&lt;/h1&gt;

&lt;h2 id=&quot;21-跨数据中心通信的情况&quot;&gt;2.1 跨数据中心通信的情况&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;高延迟&lt;/p&gt;

    &lt;p&gt;Kafka 集群间通信延迟随着距离增加而增大&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;有限的带宽&lt;/p&gt;

    &lt;p&gt;数据中心广域网带宽资源一般比较有限&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;高成本&lt;/p&gt;

    &lt;p&gt;集群间通信成本更高&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;Kafka 服务端与客户端是按照单个数据中心进行设计，调优的，不建议跨多个数据中心部署 Kafka 集群。多数情况下，需要尽量避免向远程数据中心生成消息，如果必须这么做，需要接受高延迟的问题，并且客户端需要进行重试，增大缓冲区等来应对网络分区的风险。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;对于跨数据中心通信的需求，建议在每个数据中心部署一个 Kafka 集群，并在集群间复制数据，而不是让应用程序通过广域网访问。&lt;/p&gt;

&lt;p&gt;对于跨数据中心通信，有一些架构设计原则：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;每个数据中心至少一个集群&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;每两个数据中心间数据复制要做到每个消息只复制一次&lt;/em&gt;&lt;/strong&gt;（除非异常重试）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;如果有可能，尽量从远程数据中心读取数据，而不是向远程数据中心写数据&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;22-hub--spoke-架构&quot;&gt;2.2 Hub &amp;amp; Spoke 架构&lt;/h2&gt;

&lt;p&gt;这种架构适合一个中心 Kafka 集群对应多个本地集群的情况。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_7/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果只有一个本地集群，那么系统就剩两个集群：Leader 集群与 Follower 集群。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_7/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Hub &amp;amp; Spoke 架构的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据只会在本地数据中心生成，且每个数据中心的数据只会被镜像到中央数据中心一次&lt;/li&gt;
  &lt;li&gt;只处理单个数据中心数据的应用程序可以部署在本地数据中心内，需要处理多个数据中心数据的应用程序需要部署在中央数据中心内&lt;/li&gt;
  &lt;li&gt;数据单向复制，且消费者总是从同一个集群中读取数据，因此易于部署，监控&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据访问具有局限性：一个数据中心的应用程序无法访问另一个数据中心的数据。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;采用这种架构时，每个数据中心的数据都需要被镜像到中央数据中心上。&lt;/p&gt;

&lt;h2 id=&quot;23-双活架构&quot;&gt;2.3 双活架构&lt;/h2&gt;

&lt;p&gt;当两个或者多个数据中心需要共享数据且每个数据中心都可以生产和读取数据时，可以采用&lt;strong&gt;双活（active-active）架构&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_7/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这种架构的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;就近提供服务，性能较好&lt;/li&gt;
  &lt;li&gt;冗余 &amp;amp; 弹性：每个数据中心提供全量数据，当一个数据中心不可用时，可以把用户重定向到另一个数据中心&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要解决数据冲突，数据一致性，数据回环复制等问题&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;24-主备架构&quot;&gt;2.4 主备架构&lt;/h2&gt;

&lt;p&gt;有时候，使用多个集群只是为了灾备。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;两个集群包含相同的数据，平常只使用其中一个集群。当提供服务的集群不可用时，可以使用备份集群&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_7/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主备架构的优势：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;易于实现：不需要担心数据冲突等问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;缺点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;资源占用：大部分时间内，备份集群什么工作都不会处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;3-mirrormaker&quot;&gt;3. MirrorMaker&lt;/h1&gt;

&lt;p&gt;Kafka 提供了一个简单的工具，用于在两个数据中心间镜像数据，这个工具是 MirrorMaker。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MirrorMaker 包含一组消费者，同属一个消费者群组，用于从主题上读取数据&lt;/li&gt;
  &lt;li&gt;MirrorMaker 包哈一个单独的生产者&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;镜像流程：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MirrorMaker 为每个消费者分配一个线程，消费者从源主题分区上读取数据&lt;/li&gt;
  &lt;li&gt;消费者通过公共的生产者将数据发送到目标集群上，并等待目标集群的确认&lt;/li&gt;
  &lt;li&gt;目标集群确认后，消费者再通知源集群提交这些消息的偏移量（保证不丢失消息，但是可能会少量重复）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_7/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">我们把 Kafka 集群间的数据复制叫做镜像（mirroring）。Kafka 内置的跨集群复制工具是 MirrorMaker。</summary></entry><entry><title type="html">Kafka: Reliable Data Delivery</title><link href="http://localhost:4000/kafka-in-action-6.html" rel="alternate" type="text/html" title="Kafka: Reliable Data Delivery" /><published>2023-05-18T00:00:00+08:00</published><updated>2023-05-18T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-6</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-6.html">&lt;h1 id=&quot;1-可靠性保证&quot;&gt;1. 可靠性保证&lt;/h1&gt;

&lt;p&gt;Kafka 可以作出如下保证：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;分区消息的有序性&lt;/strong&gt;&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;如果消息 B 在消息 A 之后写入同一个分区，那么消息 B 的偏移量一定比 A 的偏移量大，并且消费者会先读取消息 A，再读取消息 B&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;只有当消息被写入分区的所有同步（in-sync）副本时（并不一定刷到磁盘上），才会被认为是已经提交的（committed）&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;生产者可以选择不同类型的确认机制，如消息被完全提交时的确认，消息被写入 Leader 副本时的确认，消息被发送到网络时的确认&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;只要还存在活跃副本，那么&lt;strong&gt;&lt;em&gt;已经提交的消息&lt;/em&gt;&lt;/strong&gt;就不会丢失&lt;/li&gt;
  &lt;li&gt;消费者&lt;strong&gt;&lt;em&gt;只能消费已经提交的消息&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述机制可以用来构建可靠的系统，但是仅仅依赖上述机制无法保证系统完全可靠。我们需要在消息存储的可靠性，低延迟，高吞吐量，可用性，一致性等方面作出权衡。&lt;/p&gt;

&lt;h1 id=&quot;2-复制&quot;&gt;2. 复制&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Kafka 的复制机制与分区多副本架构是 Kafka 可靠性保证的核心&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;多副本机制可以保证在 Kafka 发生崩溃时，仍能保证消息的持久性&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Kafka 主题被划分为多个分区。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;分区是基本的数据块，分区存储在单个磁盘上&lt;/li&gt;
  &lt;li&gt;Kafka 可以保证分区里的消息是有序的&lt;/li&gt;
  &lt;li&gt;分区可以是在线的（available），也可以是离线的（unavailable）&lt;/li&gt;
  &lt;li&gt;每个分区可以有多个副本，其中一个副本是 Leader 副本，其他副本是 Follower 副本
    &lt;ol&gt;
      &lt;li&gt;所有的消息都直接发送给 Leader 副本，或者直接从 Leader 副本中读取消息&lt;/li&gt;
      &lt;li&gt;Follower 副本只需要与 Leader 保持同步，并及时从 Leader 复制最新的消息&lt;/li&gt;
      &lt;li&gt;当 Leader 副本不可用时，其中一个同步副本会称为新的 Leader&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Leader 副本是同步（in-sync）副本，对于 Follower 副本来说，需要满足以下条件才会被认为是同步的：
    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;与 Zookeeper 之间存在活跃会话，并在 6s 内（可配置）向 Zookeeper 发送过心跳&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;10s 内（可配置）从 Leader 副本处获取过消息&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;&lt;em&gt;10s 内（可配置）从 Leader 副本处获取过最新消息&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;

    &lt;blockquote&gt;
      &lt;p&gt;如果 Follower 副本不能满足以上要求任意一条，那么将会被认为是不同步的（out of sync）。如与 Zookeeper 断开连接，或不再获取消息，或消息滞后了 10s 以上&lt;/p&gt;

    &lt;/blockquote&gt;

    &lt;p&gt;一个不同步的副本通过与 Zookeeper 重新建立连接，并且从 Leader 副本处获取最新消息，可以重新变成同步的。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;滞后的同步副本会导致生产者与消费者变慢&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在消息被提交(committed)之前，客户端会等待所有的同步副本复制消息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;非同步副本虽然也同样滞后，但是并不会对性能产生任何影响&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;因为不再关心其是否接收到消息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;同步（in-sync）副本数目越少，丢失数据的风险越大&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;3-broker-配置&quot;&gt;3. Broker 配置&lt;/h1&gt;

&lt;p&gt;Broker 有 3 个配置参数会影响消息存储的可靠性。&lt;/p&gt;

&lt;h2 id=&quot;31-复制系数&quot;&gt;3.1 复制系数&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;replication.factor&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;复制系数为 N，可以保证在 N-1 个 Broker 失效时，仍然可以向主题写入数据或者从主题读取数据&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;更高的复制系数带来更高的可用性，可靠性&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;同时，&lt;strong&gt;复制系数 N 需要至少 N 个 Broker，且有 N 个数据副本。&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要占用 N 倍的磁盘空间&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;因此，我们需要在可用性与硬件存储之间作出权衡。&lt;/p&gt;

&lt;h2 id=&quot;32-不完全的-leader-选举&quot;&gt;3.2 不完全的 Leader 选举&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;unclean.leader.election.enable 默认为 true&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;当分区 Leader 不可用时，一个同步（in-sync）副本会被选举成新的 Leader。如果选举过程中没有丢失数据，即&lt;strong&gt;已经提交（committed）的消息存在所有的同步（in-sync）副本上，那么这个选举就是完全的（clean）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如果分区 Leader 不可用时，所有副本都是不同步的，此时应当如何处理？参考以下场景：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;假设分区有 3 个副本，其中两个 Follower 副本不可用（如 Broker 崩溃）。如果生产者继续往分区 Leader 写入消息，那么所有的消息都会被提交，因为只存在 Leader 副本这一个同步副本。如果一段时间后 Leader 副本也不可用了，同时 Follower 副本重新可用。&lt;/li&gt;
  &lt;li&gt;假设分区有 3 个副本，其中两个 Follower 副本不同步（如网络延迟导致复制滞后）。Leader 仍在继续接收消息；如果此时 Leader 不可用，那么另外两个 Follower 副本不可能变成同步的。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于上述场景，我们需要作出选择：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;不同步的 Follower 副本不能被选举为新 Leader ⇒ 可用性降低&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;在分区旧 Leader 副本恢复之前，分区不可用，不可用时间不确定&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;不同步的 Follower 副本可以被选举为新 Leader ⇒ 数据不一致风险&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;那么在这个 Follower 副本变得不可用之后，所有写入旧 Leader 副本的消息全部丢失，导致数据不一致（从消费者的角度来看，消费的消息可能会比较混乱）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;33-最少同步副本&quot;&gt;3.3 最少同步副本&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;min.insync.replicas&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;在上面的场景描述中，假设一个分区有 3 个副本，那么可能会出现只有一个同步副本的情况。如果该副本不可用，我们需要在可用性与一致性之间作出选择。&lt;/p&gt;

&lt;p&gt;如果要确保已提交（committed）的消息不止写入一个同步副本，那么可以把最少同步副本设为较大的值。对于 3 个副本的分区，可以设置 &lt;em&gt;min.insync.replicas = 2，这样至少需要存在两个同步副本，才能向分区写入数据&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;如果可用的的同步副本数小于 min.insync.replicas 值，那么 &lt;em&gt;Broker 就会拒绝生产者的写入请求；消费者可以继续读取已经提交的消息。&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;此时分区变成只读状态&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;4-在可靠的系统中使用生产者&quot;&gt;4. 在可靠的系统中使用生产者&lt;/h1&gt;

&lt;p&gt;除了对 Broker 进行配置，也需要对生产者进行可靠性方面的配置，否则仍有数据丢失的风险。&lt;/p&gt;

&lt;p&gt;举例如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;假设分区副本数为 3，禁用不完全选举，参数 acks = 1&lt;/p&gt;

    &lt;p&gt;生产者将消息发送给 Leader 副本，Leader 写入成功，但是 Follower 副本还未复制该消息。Leader 向生产者返回消息写入成功的响应，随后崩溃。此时消息仍未同步到 Follower 副本，并且 Follower 副本仍被认为是同步的。当其中一个 Follower 副本被选举成新的 Leader 后，之前生产者发送的消息将丢失，并且生产者认为该消息是写入成功的；不过消费者看不到这条丢失的消息（Follower 副本未收到，那么该消息不被认为是已经提交的）。但是从生产者角度来看，确实丢失了消息&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;假设分区副本数为 3，禁用不完全选举，参数 acks = all&lt;/p&gt;

    &lt;p&gt;生产者发送消息给 Leader 副本，但是由于 Leader 不可用，返回 “Leader not Available” 异常。生产者没有对异常进行处理，也没有重试，那么消息将丢失（不过这并不算 Broker 的可靠性问题）&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;因此，当使用生产者时，我们需要配置恰当的 acks 参数，并正确处理异常。&lt;/p&gt;

&lt;h2 id=&quot;41-发送确认&quot;&gt;4.1 发送确认&lt;/h2&gt;

&lt;p&gt;生产者可以选择 3 中确认模式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 0&lt;/p&gt;

    &lt;p&gt;如果生产者能够通过网络把消息发出去，那就认为消息已经成功写入 Broker。&lt;/p&gt;

    &lt;p&gt;这种模式下，消息吞吐量非常高，但是很大可能会丢失消息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 1&lt;/p&gt;

    &lt;p&gt;Leader 副本在收到消息并写入分区数据文件（不一定刷新到磁盘上）时，会返回确认或者错误响应。&lt;/p&gt;

    &lt;p&gt;如果发生正常的 Leader 选举，那么生产者会收到一条 LeaderNotAvailableException 异常。在这种模式下，仍可能会丢失消息：消息成功写入 Leader 副本，但是未及时同步到 Follower 副本，随后 Leader 崩溃。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = all&lt;/p&gt;

    &lt;p&gt;Leader 副本在返回给生产者确认或者错误的响应之前，会等待所有同步副本都收到消息。&lt;/p&gt;

    &lt;p&gt;配合 min.insync.replica 参数，可以决定在返回给生产者之前至少有多少个副本能够收到消息。&lt;/p&gt;

    &lt;p&gt;这个模式最安全，但是吞吐量会降低。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;42-错误处理&quot;&gt;4.2 错误处理&lt;/h2&gt;

&lt;p&gt;通常，为了让生产者不丢失消息，最好让生产者在遇到可重试的错误时进行重试。但是，重试会带啦消息重复的风险。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;重试 + 错误处理可以保证每个消息“至少被保存一次”&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;生产者内置的重试机制可以处理大部份异常，但是对于不可重试的错误来说，仍需要开发人员手动处理。&lt;/p&gt;

&lt;h1 id=&quot;5-在可靠的系统中使用消费者&quot;&gt;5. 在可靠的系统中使用消费者&lt;/h1&gt;

&lt;p&gt;只有已经被提交的消息（写入所有同步副本的数据）才对消费者可见，意味着消费者消费的消息具备一致性。为了保证消费的可靠性，消费者需要做的就是跟踪哪些消息已经被消费过，哪些还未被消费。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;从分区读取数据时，消费者会获取一批消息，检查这批消息的最大偏移量，然后从这个偏移量处开始消费另一批消息。&lt;/li&gt;
  &lt;li&gt;如果一个消费者退出，另一个消费者需要知道从哪个位置开始继续处理。如果前一个消费者提交了偏移量，但是消息并未全部消费完，那么可能会造成消息丢失。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;区分已提交消息与已提交偏移量：
已提交消息：已经被写入所有同步副本，并且对消费者可见的消息
已提交偏移量：消费者发送给 Kafka 的偏移量，用于确认它已经收到并且处理好的消息位置&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;51-消费者的可靠性配置&quot;&gt;5.1 消费者的可靠性配置&lt;/h2&gt;

&lt;p&gt;为了保证消费者行为的可靠性，需要关注以下参数：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;group.id：如果两个消费者的 group.id 相同，并且订阅了同一个主题，那么每个消费者只会消费主题分区的一个子集。如果想要消费者看到所有消息，需要为其设置唯一的 group.id&lt;/li&gt;
  &lt;li&gt;auto.offset.reset：在消费者没有偏移量可以提交时，或者请求的偏移量不存在时，消费者应当如何做；有 earliest 与 latest 两种方式&lt;/li&gt;
  &lt;li&gt;enable.auto.commit：消费者提交偏移量的模式：自动提交与手动提交&lt;/li&gt;
  &lt;li&gt;auto.com mit.interval.ms：如果配置了自动提交的模式，可以通过该参数配置提交的频率&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;52-显示提交偏移量&quot;&gt;5.2 显示提交偏移量&lt;/h2&gt;

&lt;p&gt;为了提高消费者的可靠性，我们需要注意以下几点。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;总是在消息处理完之后再提交&lt;/li&gt;
  &lt;li&gt;提交频率是性能与重复消息数量之间的权衡&lt;/li&gt;
  &lt;li&gt;确保对提交的偏移量有清晰的认知&lt;/li&gt;
  &lt;li&gt;再均衡&lt;/li&gt;
  &lt;li&gt;消费者可能需要重试&lt;/li&gt;
  &lt;li&gt;消费者可能需要维护状态&lt;/li&gt;
  &lt;li&gt;长时间处理：注意消费者需要一直保持轮询&lt;/li&gt;
  &lt;li&gt;仅一次传递：需要外部系统支持&lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. 可靠性保证</summary></entry><entry><title type="html">Kafka: Kafka Internals</title><link href="http://localhost:4000/kafka-in-action-5.html" rel="alternate" type="text/html" title="Kafka: Kafka Internals" /><published>2023-05-17T00:00:00+08:00</published><updated>2023-05-17T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-5</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-5.html">&lt;h1 id=&quot;1-集群成员关系&quot;&gt;1. 集群成员关系&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Kafka 使用 Zookeeper 维护集群成员信息&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Broker 启动时，通过&lt;strong&gt;创建临时节点&lt;/strong&gt;将自己的唯一 ID 注册到 Zookeeper&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;每个 Broker 都有唯一标识符号，可以在配置文件中指定，也可以自动生成。
  注册路径:  /brokers/ids&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;不同的 Kafka 组件通过订阅注册路径，可以在 Broker 加入或者退出集群时获得通知&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;在 Broker 宕机或者网络分区时，与 Zookeeper 断开连接，那么启动时创建的临时节点就会被自动删除。同时，监听 Broker 列表的 Kafka 组件就会收到 Broker 被移除的通知。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;虽然 Broker 注册的临时节点会被清除，但是其 ID 会继续保存在其他数据结构中（如主题的副本列表中）。在 Broker 关闭之后，如果&lt;strong&gt;使用相同的 ID 启动一个新的 Broker，它会立即加入集群，并拥有与旧 Broker 相同的分区与主题&lt;/strong&gt;。&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;2-控制器&quot;&gt;2. 控制器&lt;/h1&gt;

&lt;p&gt;控制器也是一个 Broker，除了具有一般 Broker 的功能，还负责分区 Leader 的选举。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Kafka 使用 Zookeeper 的临时节点来选举控制器&lt;/strong&gt;：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;集群初始化选举&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Broker 集群中第一个启动的 Broker 通过在 Zookeeper 上创建临时节点（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/controller&lt;/code&gt;）使自己成为控制器&lt;/li&gt;
      &lt;li&gt;其他 Broker 在启动时，也尝试创建这个临时节点，但是会收到“节点已存在”异常，从而意识到集群控制器节点已经存在（集群已经存在控制器）&lt;/li&gt;
      &lt;li&gt;其他 Broker 在控制器节点上创建 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watch&lt;/code&gt; 对象（用于接收节点变更通知）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;控制器异常再次触发选举&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;如果控制器被关闭或者与 Zookeeper 断开连接，Zookeeper 临时节点（&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/controller&lt;/code&gt;）消失；其他 Broker 通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watch&lt;/code&gt; 对象收到节点消失的通知，因此尝试让自己成为新的控制器&lt;/li&gt;
      &lt;li&gt;同样，第一个在 Zookeeper 上成功创建控制器节点的 Broker 成为新的控制器，其他 Broker 在新的控制器节点上再次创建 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watch&lt;/code&gt; 对象&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;每个新选出的控制器通过 Zookeeper 的递增操作获得一个全新的，数值更大的 &lt;strong&gt;Controller Epoch&lt;/strong&gt;. 其他 Broker 在知道当前的 Controller Epoch 之后，会忽略旧控制器发出的包含旧 Epoch 的消息&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;&lt;strong&gt;控制器通过 epoch 来避免“脑裂”（集群中同时存在两个控制器）&lt;/strong&gt;&lt;/p&gt;

        &lt;/blockquote&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;控制器负责分区 Leader 管理：&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Broker 离开集群&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;控制器通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watch&lt;/code&gt; Broker 在 Zookeeper 上注册的路径，可以在 Broker 离开集群时收到通知；需要对失去 Leader 的分区进行 Leader 选举&lt;/li&gt;
      &lt;li&gt;控制器遍历分区，&lt;em&gt;选择分区副本列表中的下一个副本作为新的分区 Leader&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;控制器向包含新 Leader 或者现有 Follower 的 Broker 发送消息：包含分区 Leader 与 Follower 信息&lt;/li&gt;
      &lt;li&gt;新 Leader 开始处理生产者与消费者的请求，Follower 从 Leader 处开始复制消息&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Broker 加入集群&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;当新的 Broker 加入集群时，控制器会监测其 Broker ID 是否包含现有的分区副本&lt;/li&gt;
      &lt;li&gt;如果包含，则将变更通知发送给新加入的 Broker 及其他 Broker，之后新加入的 Broker 上的分区副本就从 Leader 副本开始复制消息&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3-复制&quot;&gt;3. 复制&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;多副本机制可以使得 Kafka 在个别节点失效时，仍能保证可用性与持久性&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Kafka 使用主题来组织数据，每个主题包含多个分区，每个分区包含多个副本。副本被分配在 Broker 上，每个 Broker 可以保存成百上千个副本。&lt;/p&gt;

&lt;p&gt;有两种类型的副本：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Leader 副本&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;每个分区都有一个 Leader 副本。&lt;/p&gt;

    &lt;p&gt;为了保证数据一致性，所有生产者与消费者的请求都会由 Leader 副本处理。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;&lt;em&gt;Follower 副本&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Leader 副本外的其他副本都是 Follower 副本。&lt;/p&gt;

    &lt;p&gt;Follower 副本不会处理来自客户端的请求，唯一的任务就是从 Leader 副本处复制消息，与 Leader 副本保持一致，以便在 Leader 副本不可用时从中选举出新的 Leader。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Leader 副本还需要判断哪些 Follower 副本的状态与自己是保持一致的。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Follower 副本为了与 Leader 保持一致，向 Leader 发送获取数据的请求（与消费者获取数据请求方式一样）；Leader 返回消息及对应偏移量&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Leader 副本通过检查每个 Follower 请求的最新偏移量，可以判断 Follower 的复制进度&lt;/em&gt;
    &lt;ul&gt;
      &lt;li&gt;如果 Follower 在 10s 内没有请求任何消息，或者虽然在请求消息，但是 10s 内没有请求最新数据，那么该 Follower 会被认为是&lt;strong&gt;不同步的（out of sync）&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;如果 Follower 持续请求最新消息，则被认为是&lt;strong&gt;同步的（in-sync）&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;在 Leader 副本失效后，只有同步的副本才可能被选为新的 Leader&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Follower 副本正常不活跃的时间或者在被认为不同步的时间通过参数 replica.lag.time.max.ms 控制&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;首选 Leader&lt;/strong&gt;：创建主题时选定的 Leader 就是分区的首选 Leader。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;分区副本列表中第一个副本一般就是首选 Leader&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;4-处理请求&quot;&gt;4. 处理请求&lt;/h1&gt;

&lt;p&gt;Broker 的大部分工作就是处理客户端，分区副本和控制器发送给分区 Leader 的请求。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Broker 按照请求到达的顺序进行处理&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每个监听端口上运行一个 Acceptor 线程，该线程会为请求创建一个连接，并交给 Processor 线程处理&lt;/li&gt;
  &lt;li&gt;Processor 线程从客户端获取请求消息，把它们放到请求队列，然后从响应队列获取响应消息，发送给客户端&lt;/li&gt;
  &lt;li&gt;请求消息被放入请求队列后，会由 IO 线程负责处理&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;所有请求都有如下标准头：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Request type&lt;/li&gt;
  &lt;li&gt;Request version：Broker 可以处理不同版本客户端的请求&lt;/li&gt;
  &lt;li&gt;Correlation ID：请求消息的唯一标识（响应中也会携带）&lt;/li&gt;
  &lt;li&gt;Client ID：客户端标识&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;41-元数据请求&quot;&gt;4.1 元数据请求&lt;/h2&gt;

&lt;p&gt;元数据请求包含了客户端感兴趣的主题列表，可以请求&lt;strong&gt;任意 Broker&lt;/strong&gt;。Broker 的响应中包含了请求主题包含的分区，每个分区的副本信息，以及副本 Leader 信息。&lt;/p&gt;

&lt;p&gt;客户端一般会把这些元数据信息缓存本地，并定时刷新，之后直接往目标 Broker 上发送生产请求或者获取请求。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;生产请求及获取请求必须发送给分区的 Leader 副本&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;42-生产请求&quot;&gt;4.2 生产请求&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;生产请求必须要发送给分区的 Leader 副本&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Leader 副本的位置信息由元数据请求返回&lt;/li&gt;
  &lt;li&gt;如果请求的 Broker 不包含对应分区的 Leader 副本，那么就会响应给客户端“非分区 Leader”的异常&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;包含 Leader 副本的 Broker 在收到生产请求时，会对请求做一些验证：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;是否有权限写入主题&lt;/li&gt;
  &lt;li&gt;请求中的 acks 值是否有效（0，1 or al）&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果 acks = all，是否有足够多的同步副本保证消息能够被安全写入&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;如果同步（in-sync）副本数量不足，Broker 可以拒绝新消息&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;之后，Broker 会将消息写入本地磁盘。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在 Linux 系统上，消息会被写入到文件系统缓存中，并不保证何时会被刷新到磁盘上&lt;/li&gt;
  &lt;li&gt;Kafka 不会一直等待数据写到磁盘上，反而&lt;strong&gt;通过数据复制功能保证消息的持久性&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;消息在被写入分区的 Leader 副本之后，Broker 再次检查 acks 配置参数&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 acks = 0/1，那么 Broker 立即返回响应&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;如果 acks = all，那么请求会被保存到一个被称为 &lt;em&gt;purgatory&lt;/em&gt; 的缓冲区中，直到所有的 Follower 副本都复制了消息，Leader 才会响应客户端&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;从生产者角度看，acks = 0 那么生产者在将消息发送出去之后，完全不需要等待 Broker 的响应；acks = 1 生产者会等待 Leader 副本写入成功；acks = all 生产者会等待所有同步副本都写入成功&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;42-获取请求&quot;&gt;4.2 获取请求&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;获取请求必须要发送给分区的 Leader 副本&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Leader 副本在收到获取请求后，会检查请求是否有效：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;偏移量在指定分区上是否存在
    &lt;ul&gt;
      &lt;li&gt;如果偏移量不存在（可能是数据已经被删除），那么将会返回给客户端一个错误&lt;/li&gt;
      &lt;li&gt;如果偏移量存在，则 Broker 按照指定的数量上限读取消息，并返回给客户端&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;客户端在发送获取请求时，除了需要指定获取的分区及偏移量，还需&lt;em&gt;要指定 Broker 最多从一个分区内可以返回多少数据量，以防止返回过多数据导致客户端内存耗尽。&lt;/em&gt;同时，也可以指定返回数据的下限，可以在 Broker 数据量较少的情况下减少回传次数，降低开销。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Kafka 比较知名的是，使用&lt;strong&gt;零拷贝（Zero-Copy）技术向客户端发送消息&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Kafka 直接把消息从文件（更确切的说是 Linux 文件系统缓存）发送到网络通道，不需要经过任何中间缓冲区。相比于其他数据库系统，在发送给客户端之前，需要先将数据缓存在本地&lt;/li&gt;
  &lt;li&gt;这项技术&lt;em&gt;避免了字节复制（降低 CPU 消耗），也不需要管理内存缓存，提高系统性能&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;客户端在请求 Leader 副本获取消息时，&lt;strong&gt;只能获取已经被写入所有同步（in-sync）副本的消息&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;也就是说，Leader 副本上的数据并不是都可以被消费&lt;/li&gt;
  &lt;li&gt;除了消费者，Follower 副本同样也只能获取已经被写入所有同步副本的消息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这么做的目的是为了&lt;strong&gt;确保数据一致性&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果消息还未被同步，那么当 Leader 崩溃后，新的 Leader 可能会丢失数据。从消费者的角度来说，前后消费的数据可能不一致。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;消费者只能看到高水位之上的消息；&lt;em&gt;参考 In-Sync Replicas 机制（副本同步机制）&lt;/em&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;相应的，如果 Broker 之间复制消息较慢，也会导致消费者消费消息的延迟增大。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;replica.lag.time.max.ms 参数可以配置消息复制的最大延迟&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;43-其他请求&quot;&gt;4.3 其他请求&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Broker 之间请求，如控制器发送给 Leader 副本及 Follower 副本的请求&lt;/li&gt;
  &lt;li&gt;Offset 请求，如客户端提交 Offset，拉取 Offset 请求&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-物理存储&quot;&gt;5. 物理存储&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;分区是 Kafka 基本存储单元&lt;/strong&gt;。一个分区无法在多个 Broker 间再拆分，也无法在同一个 Broker 上的多个磁盘间再细分。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在配置 Kafka 的时候，需要指定用于存储分区的目录清单：log.dirs&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;51-分区分配&quot;&gt;5.1 分区分配&lt;/h2&gt;

&lt;p&gt;在进行分区分配时，期望达到以下目标（用以&lt;strong&gt;&lt;em&gt;提高容灾能力&lt;/em&gt;&lt;/strong&gt;）：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Broker 间均匀分配分区副本（Follower + Leader）&lt;/li&gt;
  &lt;li&gt;每个分区的副本分配在不同的 Broker 上
    &lt;ul&gt;
      &lt;li&gt;如果为 Broker 指定了机架信息，那么每个分区副本尽量分配在不同机架的 Broker 上&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;假设需要在 m 个 Broker 上分配 n 个分区，且分区复制系数为 k。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;轮询将分区的 Leader 副本分配在 Broker 上&lt;/li&gt;
  &lt;li&gt;轮询将分区的 Follower 副本分配在 Broker 上&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;在轮询分配时，需要尽量保证上述目标&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在将分区副本分配到 Broker 上之后，需要为分区副本分配存储目录，分配规则为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;比较每个目录下的分区数量，新分区副本会被分配到分区数量最小的目录下面&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果新添加一个磁盘，那么新的分区都会分配到该磁盘下&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;52-文件管理&quot;&gt;5.2 文件管理&lt;/h2&gt;

&lt;p&gt;Kafka 不会一直保留数据，也不会等到所有的消费者都消费之后再删除数据。&lt;strong&gt;通过配置主题数据保留的期限与数据量大小&lt;/strong&gt;，来进行管理：满足配置的期限或者大小，就可以清除相应数据。&lt;/p&gt;

&lt;p&gt;如果一个分区的数据保留在一个文件中，那么这个文件可能会变得特别大，在进行数据查找与删除时会比较耗时。&lt;/p&gt;

&lt;p&gt;因此，&lt;strong&gt;Kafka 将分区划分成多个片段（Segment）&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;默认片段大小为 1GB 或 一周的数据&lt;/li&gt;
  &lt;li&gt;Broker 在往分区写入数据时，如果当前片段达到上限，则关闭当前文件，并打开新的文件&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当前正在写入数据的片段被称为&lt;strong&gt;活跃片段（Active Segment）&lt;/strong&gt;；活跃片段永远不会被删除。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Broker 会为每个片段打开一个句柄（包括已经关闭的片段），如果片段过多的话可能会导致文件句柄过多&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;53-文件格式&quot;&gt;5.3 文件格式&lt;/h2&gt;

&lt;p&gt;Kafka 将消息的&lt;em&gt;键，值，偏移量，消息大小，校验和，消息格式版本号，压缩算法，时间戳&lt;/em&gt;保存在磁盘文件。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;保存在磁盘上的数据格式与从生产者发送过来，或者发送给消费者的消息格式是一样的，不需要对消息进行再次压缩，解压操作。因此，&lt;strong&gt;Kafka 可以使用零复制（Zero-Copy）技术将消息发送给消费者（磁盘存储与网络传输格式均相同）&lt;/strong&gt;。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;如果生产者发送的是压缩消息，那么同一个批次的消息会被压缩，被当成“&lt;strong&gt;&lt;em&gt;包装消息&lt;/em&gt;&lt;/strong&gt;（Wrapper Message）”发送。消费者对包装消息解压，可以看到整个批次的消息，每个消息都有自己的偏移量及时间戳。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;消息 Offset 生成时机&lt;/p&gt;

    &lt;p&gt;Kafka 消息的 offset 是在消息被写入 Kafka 分区时生成的。具体来说，当 Producer 发送消息到 Kafka 时，Kafka 会为每条消息分配一个唯一的 offset，并将消息写入对应的分区中。每个分区的消息都有一个单独的连续的 offset 序列。&lt;/p&gt;

    &lt;p&gt;消息的 offset 是由 Kafka 服务器自动分配的，并且在消息被成功写入分区后才会生成。因此，offset 的生成时机可以分为两个阶段：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;生产者发送消息：当生产者发送消息到 Kafka Broker 时，Broker 会为消息分配一个 offset，并将消息写入对应的分区。这是 offset 的生成的第一个阶段，也是 offset 的初次分配。&lt;/li&gt;
      &lt;li&gt;消息成功写入分区：当消息成功写入分区后，offset 的生成完成。此时，消费者可以通过指定对应分区的 offset 来消费该消息。&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;需要注意的是，offset 是按照分区粒度生成的，每个分区都有独立的 offset 序列。不同分区的消息具有不同的 offset 值，并且每个分区的 offset 是连续递增的，从而保证了消息在分区内的顺序性。&lt;/p&gt;

    &lt;p&gt;消费者在消费消息时，可以通过指定分区和 offset 来定位和消费特定的消息。消费者可以跟踪已消费的消息的 offset，并定期提交这些 offset，以便在 Consumer 重启或故障恢复时能够从之前的消费位置继续消费。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;54-索引&quot;&gt;5.4 索引&lt;/h2&gt;

&lt;p&gt;为了更快定位到消费者请求的偏移量，Kafka 为每个分区维护了一个索引。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;索引把偏移量映射到片段（Segment）文件及偏移量在文件中的位置&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如果索引出现损坏，Kafka 会通过重新读取消息并录制偏移量及位置来生成新的索引。&lt;/p&gt;

&lt;h2 id=&quot;55-压缩&quot;&gt;5.5 压缩&lt;/h2&gt;

&lt;p&gt;通常，Kafka 会根据设置的时间保留数据，把过期的数据清理掉。&lt;/p&gt;

&lt;p&gt;但是，有些场景需要保留最新的数据，旧的数据可以被清理。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个应用程序使用 Kafka 保存自己的状态，每次状态变化时，都将最新状态写入 Kafka。如果程序崩溃，可以从 Kafka 中读取最新消息来恢复。此时，应用程序只关心崩溃前的最新状态，而运行过程中的状态并不关心。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Kafka 通过配置主题的保留策略来满足上述场景：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Delete&lt;/em&gt;&lt;/strong&gt;：&lt;em&gt;早于保留时间的事件会被删除&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;Compact&lt;/em&gt;&lt;/strong&gt;：&lt;em&gt;只保留每个 Key 的最新值&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;这种压缩清理的策略需要消息中既包含 key，也包含 value，才可以使用&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;压缩清理操作只针对已经关闭的片段&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;56-压缩原理&quot;&gt;5.6 压缩原理&lt;/h2&gt;

&lt;p&gt;每个日志片段可以分为两部分：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;干净的（Clean）&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;这部分消息之前被清理过，每个键只保留之前清理过程中的最新值。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;污浊的（Dirty）&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;这部分消息是之前清理之后写入的&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果启用压缩清理功能，Broker 会启动多个清理线程执行清理任务。清理线程会选择污浊率高的分区进行清理（污浊消息占分区总消息的大小）。&lt;/p&gt;

&lt;p&gt;清理线程创建一个 Map，并从片段的干净部份开始遍历，比对消息。清理前后的分区片段数据如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_5/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;57-删除消息&quot;&gt;5.7 删除消息&lt;/h2&gt;

&lt;p&gt;为了将消息从 Kafka 中删除，&lt;em&gt;生产者需要发送一个包含该 Key，且 Value 为 NULL 的消息&lt;/em&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;清理线程发现该消息时，先进行常规清理，只保留 Value 为 NULL 的消息；该消息被称为&lt;strong&gt;墓碑消息&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;墓碑消息会被保留一段时间（时间可配置）；在这期间，消费者仍可消费该消息&lt;/li&gt;
  &lt;li&gt;墓碑消息过期之后，清理线程会将其清除&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. 集群成员关系</summary></entry><entry><title type="html">Kafka: Reading Data from Kafka</title><link href="http://localhost:4000/kafka-in-action-4.html" rel="alternate" type="text/html" title="Kafka: Reading Data from Kafka" /><published>2023-05-14T00:00:00+08:00</published><updated>2023-05-14T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-4</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-4.html">&lt;h1 id=&quot;1-kafkaconsumer-概念&quot;&gt;1. KafkaConsumer 概念&lt;/h1&gt;

&lt;h2 id=&quot;11-消费者与消费者组&quot;&gt;1.1 消费者与消费者组&lt;/h2&gt;

&lt;p&gt;Kafka 消费者从属于&lt;strong&gt;消费者群组（Consumer Group）&lt;/strong&gt;。一个群组里的消费者订阅的是同一个主题，每个消费者消费该主题的一部分分区消息。
&lt;img src=&quot;/images/kafka/chapter_4/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如上所示，主题 Topic 1 有 4 个分区，消费者群组 Consumer Group 1 订阅该主题：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;消费者群组中只有一个消费者 C1，该消费者将接收 4 个分区的消息&lt;/li&gt;
  &lt;li&gt;消费者群组中添加一个消费者 C2，则 C1, C2 分别接收 2 个分区的消息&lt;/li&gt;
  &lt;li&gt;如果群组中有 4 个消费者，则每个消费者分别接收 1 个分区的消息&lt;/li&gt;
  &lt;li&gt;如果群组中的消费者继续增加，超过了主题分区的数量，那么会有一部分消费者被闲置，无法接收任何分区的消息&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通过&lt;strong&gt;往消费者群组中添加消费者，是横向扩展消费能力的主要方式&lt;/strong&gt;。但是，&lt;strong&gt;消费者的数量不要超过分区数&lt;/strong&gt;，不然会有部份消费者无法消费消息。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;单个消费者有时候无法跟上数据生产的速度，此时可以增加消费者数目，让每个消费者分担部份分区的消息&lt;/li&gt;
  &lt;li&gt;群组中的每个消费者只承担部份分区的消费&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;同时，Kafka 还支持多个消费组订阅同一个主题，每个消费组都可以接收全部主题消息，且互不影响。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;该设计适用于多个不同的应用程序订阅同一个主题的场景&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;不管是往消费组中添加消费者，还是新增新的消费组，都不会对 Kafka 的性能造成负面影响&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;12-消费者群组与分区再均衡&quot;&gt;1.2 消费者群组与分区再均衡&lt;/h2&gt;

&lt;h3 id=&quot;121-rebalance&quot;&gt;1.2.1 Rebalance&lt;/h3&gt;

&lt;p&gt;主题分区所有权由一个消费者转移到另一个消费者，被称为&lt;strong&gt;再均衡&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;以下场景会发生再均衡操作：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;新的消费者加入群组&lt;/strong&gt;：新增的消费者会读取原本属于其他消费者的分区消息&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;消费者（关闭或者发生崩溃）离开群组&lt;/strong&gt;：该消费者负责的分区将由其他消费者处理&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;主题分区发生变化&lt;/strong&gt;：由管理员新增或者删除分区&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再均衡可以使得消费者群组具有更好的可用性与伸缩性，但是&lt;strong&gt;再均衡期间，消费者将无法消费消息&lt;/strong&gt;，使得整个群组短时间不可用。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要避免不必要的再均衡操作&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;122-consumer-group&quot;&gt;1.2.2 Consumer Group&lt;/h3&gt;

&lt;p&gt;消费者通过向&lt;strong&gt;被指派&lt;/strong&gt;为&lt;strong&gt;群组协调器&lt;/strong&gt;（group coordinator ）的 Broker 发送心跳（heartbeats）来维持&lt;strong&gt;消费者与群组的从属关系&lt;/strong&gt;以及&lt;strong&gt;消费者与分区的所有权关系&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;不同的消费者群组可以有不同的群组协调器&lt;/p&gt;

  &lt;ul&gt;
    &lt;li&gt;如果消费者在指定时间间隔内正常发送心跳，则会被认为是活跃的&lt;/li&gt;
    &lt;li&gt;如果消费者停止发送心跳的时间较长，会话过期，群组协调器就会认为消费者已经死亡，触发再均衡&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;消费者会在消息轮询或者提交消息偏移量时发送心跳&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;消费者退出群组分为两种场景：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;消费者崩溃退出&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;消费者崩溃，并停止读取消息。协调器并不会立即触发再均衡，而是等待几秒，确认消费者已经死亡，之后再均衡&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;em&gt;消费者主动退出&lt;/em&gt;&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;消费者会通知协调器其将要离开群组，那么协调器就会立即触发一次再均衡&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;在 0.10.1 版本中，Kafka 引入一个独立的心跳线程，可以在消息轮询间隙发送心跳；使得发送心跳的频率与消息轮询的频率（与处理消息花费的时间有关）相互独立。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;123-分区分配过程&quot;&gt;1.2.3 分区分配过程&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;当消费者加入群组时，会向群组协调器发送一个 JoinGroup 的请求。
    &lt;ul&gt;
      &lt;li&gt;第一个加入群组的消费者会成为群组的 Leader&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;群组 Leader 从协调器获得群组的成员列表
    &lt;ul&gt;
      &lt;li&gt;最近向协调器发送过心跳，被认为是活跃的消费者列表&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;群组 Leader 为每个消费者分配分区子集
    &lt;ul&gt;
      &lt;li&gt;分配策略可以自定义实现，也可以使用 Kafka 内置策略&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;群组 Leader 把分配结果发送给群组协调器&lt;/li&gt;
  &lt;li&gt;协调器将这些信息发送给所有消费者
    &lt;ul&gt;
      &lt;li&gt;每个消费者只能看到自己的分配结果；群组 Leader 知道所有分配结果&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;再均衡发生时，重复上述流程&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2-创建-kafka-消费者&quot;&gt;2. 创建 Kafka 消费者&lt;/h1&gt;

&lt;p&gt;创建 KafkaConsumer 对象也需要 3 个必要属性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;bootstrap.servers：指定 Kafka 集群连接字符串&lt;/li&gt;
  &lt;li&gt;key.deserializer, value.deserializer：反序列化器，用于将字节数组转换成 java 对象&lt;/li&gt;
  &lt;li&gt;grop.id：指定了消费者属于哪个消费者组（非必需）；如果不指定，则不属于任何消费者组&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;props&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;broker1:9092,broker2:9092&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group.id&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;CountryCounter&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key.deserializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value.deserializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaConsumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;props&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;3-订阅主题&quot;&gt;3. 订阅主题&lt;/h1&gt;

&lt;p&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subcribe()&lt;/code&gt; 方法订阅主题：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 1. 订阅单个主题&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;subscribe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collections&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;singletonList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;customerCountries&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 2. 通过正则表达式订阅多个主题&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 当有新的主题添加时，立即触发 rebalance，消费者就可以消费新的主题&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;subscribe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test.*&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;4-轮询&quot;&gt;4. 轮询&lt;/h1&gt;

&lt;p&gt;消息轮询方法不仅能够获取消息，还包含其他操作：&lt;strong&gt;群组协调，分区 Rebalance，发送心跳&lt;/strong&gt;等。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当首次调用消费者的 poll 方法时，会查找群组协调器，加入群组，并接收被分配的分区&lt;/li&gt;
  &lt;li&gt;如果发生了 Rebalance，也需要在轮询过程中处理&lt;/li&gt;
  &lt;li&gt;心跳发送也是在轮询过程中发送的&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;我们需要确保轮询期间的操作尽快结束&lt;/p&gt;

&lt;/blockquote&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset = %d,
               customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
               &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
            &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updatedCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;custCountryMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;countainsValue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;updatedCount&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;custCountryMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
            &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;custCountryMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;updatedCount&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;JSONObject&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;JSONObject&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;custCountryMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;toString&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Consumer 必须持续轮训 Kafka Broker，否则会被认为已经死亡，触发 Rebalance。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 方法返回记录列表，包含：主题信息，分区信息，偏移量，记录的 key-value 对&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;close()&lt;/code&gt; 方法用于关闭消费者，除了关闭网络连接，也会触发一次 Rebalance（而不是等待消费者协调器去判断是否仍存活）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;在一个消费者群组中，无法让一个线程运行多个消费者，也无法让多个线程共享一个消费者。安全起见，需要让一个线程运行一个消费者&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;5-消费者配置&quot;&gt;5. 消费者配置&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;fetch.min.bytes&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;该参数指定了从 Broker 获取消息记录时的最小字节数。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Broker 收到消费者请求时，如果当前可用数据量小于该值，则会等待有足够多的数据时才返回&lt;/li&gt;
      &lt;li&gt;适当调大该值，可以降低 Broker 负载：Broker 不需要频繁处理请求&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;fetch.max.wait.ms&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;该参数用于指定 Broker 最长等待时间。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;当请求的数据量得不到满足时，最多等待该参数指定的时间&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;max.partition.fetch.bytes&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;该参数指定 Broker 从每个分区返回给消费者的最大字节数。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;该参数值的设置需要考虑消费者处理数据的时间。消费者需要频繁调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 方法来维持会话，如果返回的数据量过多，数据处理时间较长，可能无法及时进行下次 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 导致会话过期。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;session.timeout.ms&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;消费者于 Broker 之间会话过期时间，默认 3 秒。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;如果消费者在该时间范围内没有向 Broker 发送心跳，则会被认为已经死亡，触发 Rebalance&lt;/li&gt;
      &lt;li&gt;该参数表明消费者可以多长时间不发送心跳；另一个参数 heartbeat.interval.ms 则指定了 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 方法发送心跳的频率。这两个参数通常配合使用，heartbeat.interval.ms 一般为 session.timeout.ms 的 1/3&lt;/li&gt;
      &lt;li&gt;该参数值如果设置的比较小，有利于更快监测和恢复崩溃的节点，但是可能会导致非预期内的 Rebalance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;auto.offset.reset&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;该参数指定了消费者在读取一个&lt;strong&gt;没有偏移量&lt;/strong&gt;的分区或者&lt;strong&gt;偏移量无效&lt;/strong&gt;的情况下的处理方式&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;默认是 latest: 从最新记录处开始重新消费&lt;/li&gt;
      &lt;li&gt;earliest: 从分区起始位置开始重新消费&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;enable.auto.commit&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;该参数用于配置消费者是否自动提交偏移量，默认 true.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;如果设置为自动提交，可以配置 auto.commit.interval.ms 用来控制提交间隔&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;partition.assignment.strategy&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;用于指定分区分配给消费者的策略。默认有两种策略：&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;Range&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;把主题若干连续分区分配给消费者。假设有 5 个分区，2 个消费者，那么其中一个消费者被分配 [0,1,2] 分区，另一被分配 [3,4] 分区&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;RoundRobin&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;把主题的所有分区逐个分配给消费者。假设有 5 个分区，2 个消费者，那么其中一个消费者被分配 [0,2,4] 分区，另一被分配 [1,3] 分区&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;max.poll.records&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;用于控制单次 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 调用能够返回的消息数量。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;receive.buffer.bytes &amp;amp; send.buffer.bytes&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;用于设置 Sockets 在读写数据时用到的 TCP 缓冲区大小。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;默认为操作系统的默认值&lt;/li&gt;
      &lt;li&gt;如果消费者或者生产者与 Broker 位于不同的数据中心，可以适当提高缓冲区大小，因为网络通信延迟会比较高&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;6-提交偏移量&quot;&gt;6. 提交偏移量&lt;/h1&gt;

&lt;p&gt;当调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 方法时，会返回已经写入 Kafka Broker 但是消费者还未读取的记录。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Kafka 消费消息不需要得到消费者的确认，相反，消费者可以追踪消息在分区的位置（偏移量）&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;更新分区当前位置的操作被称为提交偏移量&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;消费者如何提交偏移量？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;消费者通过往 &lt;strong&gt;__consumer_offsets&lt;/strong&gt; 特殊主题发送消息，消息中包含每个分区的偏移量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;偏移量的用途？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果消费者一直稳定运行消费，那么偏移量没有什么用处&lt;/li&gt;
  &lt;li&gt;如果发生 Rebalance（消费者崩溃或者有新的消费者加入群组），那么消费者可能会被分配新的分区。为了能够继续按照之前的位置继续消费，&lt;strong&gt;消费者需要读取每个分区最后提交的偏移量，然后从偏移量的位置继续处理&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;发生 Rebalance 时，提交的偏移量可能带来的影响？&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;如果最近一次提交的偏移量小于消费者处理的最后一个消息的偏移量，那么两个偏移量之间的消息会被重复消费&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果最近一次提交的偏移量大于消费者处理的最后一个消息的偏移量，那么两个偏移量之间的消息会被丢失&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_4/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Kafka 提供了多种方式用来提交偏移量。&lt;/p&gt;

&lt;h2 id=&quot;61-自动提交&quot;&gt;6.1 自动提交&lt;/h2&gt;

&lt;p&gt;如果配置 enable.auto.commit=true，那么默认每隔 5 秒，&lt;strong&gt;消费者会自动把 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 返回的最大偏移量提交&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;可以设置 auto.commit.interval.ms 参数调整提交间隔&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;自动提交是在 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 中处理的&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当消费者每次轮询时，都会检查是否该提交偏移量了；如果可以提交，则将上一次 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 返回的最大偏移量进行提交&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;自动提交偏移量可能带来的影响&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;上次提交之后发生 Rebalance，导致&lt;strong&gt;消息被重复处理&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设提交间隔为 5s，如果在上次提交之后的 3s 发生 Rebalance，新的消费者会从最后一次提交的偏移量位置开始消费，那么这 3s 内的消息会被重复消费。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;&lt;em&gt;这种情况不能完全避免&lt;/em&gt;&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;自动提交时，上次轮询的消息未被处理完，如果消费者之后发生崩溃，可能会导致消息丢失&lt;/p&gt;

    &lt;p&gt;每次调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 时都会检查是否提交上次返回的最大偏移量，但是并不知道上次返回的消息是否全部被处理完成。因此，需要确保再次调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 时，之前的消息已经被处理完。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;close()&lt;/code&gt; 调用也会自动提交偏移量&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;62-提交当前偏移量&quot;&gt;6.2 提交当前偏移量&lt;/h2&gt;

&lt;p&gt;如果配置 auto.commit.offset=false，可以&lt;strong&gt;使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 方法手动提交当前偏移量&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 会提交 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 返回的最新偏移量，提交成功则返回，否则抛出异常。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;只要没有发生不可恢复的错误，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 会一直重试直到成功。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 是同步方法，在 Broker 响应之前，会一直阻塞。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;在调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 提交最新偏移量之前，需要确保 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 返回的消息被处理完成；否则，如果发生 Rebalance，仍会有消息丢失的风险。&lt;/p&gt;

&lt;p&gt;下面是处理完消息之后手动提交偏移量的代码：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset =
          %d, customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 手动提交偏移量&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CommitFailedException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;commit failed&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;63-异步提交&quot;&gt;6.3 异步提交&lt;/h2&gt;

&lt;p&gt;由于 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 方法会使得消费者被阻塞，使得整体tun tu lia&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitAsync()&lt;/code&gt; 提交之后，不会等待 Broker 的响应；并且，该方法不会重试提交&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;不过，这种方式在发生 Rebalance 之后可能会导致消息被重复消费。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s,
        offset = %d, customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitAsync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitAsync()&lt;/code&gt; 支持回调（当 Broker 响应时被触发），可以在回调方法中进行异常重试。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s,
        offset = %d, customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitAsync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OffsetCommitCallback&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onComplete&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exception&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Commit failed for offsets {}&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;64-同步与异步提交组合&quot;&gt;6.4 同步与异步提交组合&lt;/h2&gt;

&lt;p&gt;组合使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitAsync()&lt;/code&gt; ，确保在消费者关闭前提交成功。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset = %d,
            customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
			&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitAsync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Unexpected error&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;65-提交特定的偏移量&quot;&gt;6.5 提交特定的偏移量&lt;/h2&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitSync()&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;commitAsync()&lt;/code&gt; 方法只能提交 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 返回消息的最大偏移量，如果想要提交该批次中间的偏移量，可以将分区及偏移量作为参数传入。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;....&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset = %d,
            customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;no metadata&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
								&lt;span class=&quot;c1&quot;&gt;// 提交特定的偏移量&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitAsync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++;&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;7-rebalance-监听器&quot;&gt;7. Rebalance 监听器&lt;/h1&gt;

&lt;p&gt;消费者在退出或者 Rebalance 之前可能需要做一些清理工作，如关闭文件，数据库连接等。消费者在调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;subscribe()&lt;/code&gt; 监听主题时，可以传入 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConsumerRebalanceListener&lt;/code&gt; 实例对 Rebalance 操作进行监听。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConsumerRebalanceListener&lt;/code&gt; 接口有两个方法需要实现：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 该方法会在 Rebalance 之前，消费者停止读取消息之后调用&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 如果在此时提交偏移量，那么新的消费者就可以知道上一次消费的位置&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsRevoked&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 该方法会在 Rebalance 之后，消费者开始读取消息之前调用&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsAssigned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;监听示例：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HashMap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;();&lt;/span&gt;

&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HandleRebalance&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConsumerRebalanceListener&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsAssigned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt;

		&lt;span class=&quot;c1&quot;&gt;// 在失去分区所有权之前，提交已经处理过的消息偏移量，而非最大偏移量&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsRevoked&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Lost partitions in rebalance. Committing current offsets:&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 

&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;subscribe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HandleRebalance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset = %d,
             customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
             &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;
             &lt;span class=&quot;nc&quot;&gt;OffsetAndMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;no metadata&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
					&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitAsync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;WakeupException&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// ignore, we're closing&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Unexpected error&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;currentOffsets&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;finally&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;close&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Closed consumer and we are done&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;8-从特定偏移量处开始消费&quot;&gt;8. 从特定偏移量处开始消费&lt;/h1&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 方法可以从分区的最新偏移量处开始消费消息，如果想从分区的起始位置开始消费，可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seekToBeginning(TopicPartition tp)&lt;/code&gt; 方法；如果想从分区的末尾位置开始消费，可以使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seekToEnd(TopicPartition tp)&lt;/code&gt; 方法。&lt;/p&gt;

&lt;p&gt;同时，Kafka 还提供 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seek(TopicPartition partition, long offset)&lt;/code&gt; 方法从特定偏移量处开始消费。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;seek() 方法只是用来更新当前正在消费的位置&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;下面示例使用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ConsumerRebalanceLister&lt;/code&gt; 与 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;seek()&lt;/code&gt; 方法实现在分区分配时，从本地 DB 中获取特定的 Offset 并消费。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SaveOffsetsOnRebalance&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConsumerRebalanceListener&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsRevoked&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;commitDBTransaction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
			&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onPartitionsAssigned&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Collection&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;partition:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
	            &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getOffsetFromDB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
			&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;subscribe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topics&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SaveOffsetOnRebalance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;// 更新各个 Partition 的消费位点&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;partition:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;assignment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;seek&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getOffsetFromDB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;));&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;processRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;storeRecordInDB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;storeOffsetInDB&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;commitDBTransaction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;9-如何退出&quot;&gt;9. 如何退出&lt;/h1&gt;

&lt;p&gt;目前的消费者示例中，消费者都是在无限循环中，如果要退出循环，需要通过&lt;strong&gt;另一个线程&lt;/strong&gt;调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.wakeup()&lt;/code&gt; 方法。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.wakeup()&lt;/code&gt; 是消费者唯一一个可以从其他线程安全调用的方法&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.wakeup()&lt;/code&gt; 可以退出 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt;，并抛出 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WakeupException&lt;/code&gt; 异常。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果在调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.wakeup()&lt;/code&gt; 时，消费者线程并没有等待轮询，那么异常将会在下一次调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;poll()&lt;/code&gt; 时抛出&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;需要注意，在消费者退出之前，有必要调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;consumer.close()&lt;/code&gt; 方法，该方法会提交还未提交的信息，并向群组协调器发送离开群组的消息，触发 Rebalance。&lt;/p&gt;

&lt;h1 id=&quot;10-独立消费者&quot;&gt;10. 独立消费者&lt;/h1&gt;

&lt;p&gt;如果一个消费者只是想从主题的所有分区或者特定分区读取消息，并不需要消费者组和 Rebalance。这样的话就不需要订阅主题，取而代之的是&lt;strong&gt;为自己分配分区&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;订阅主题（并加入消费者群组），为自己分配分区两件事不能同时执行&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;消费者为自己分配分区并消费消息的示例：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PartitionInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitionInfos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitionInfos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partitionsFor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitionInfos&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PartitionInfo&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitionInfos&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TopicPartition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()));&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;assign&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 

	&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	    &lt;span class=&quot;nc&quot;&gt;ConsumerRecords&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;poll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConsumerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;record:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
	        &lt;span class=&quot;nc&quot;&gt;System&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;topic = %s, partition = %s, offset = %d,
	          customer = %s, country = %s\n&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
	          &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt;
	          &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
			&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
	    &lt;span class=&quot;n&quot;&gt;consumer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;commitSync&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. KafkaConsumer 概念</summary></entry><entry><title type="html">Kafka: Meet Kafka</title><link href="http://localhost:4000/kafka-in-action-1.html" rel="alternate" type="text/html" title="Kafka: Meet Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-1</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-1.html">&lt;h1 id=&quot;11-发布订阅消息系统&quot;&gt;1.1 发布订阅消息系统&lt;/h1&gt;

&lt;p&gt;发布订阅消息系统的一个特点是，消息的发送者不会直接把消息发送给接收者。&lt;strong&gt;发送者以某种方式对消息进行分类，接收者订阅它们，以便接收特定类型的消息&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;发布订阅系统一般有一个 Broker：发布消息的中心点。&lt;/p&gt;

&lt;h1 id=&quot;12-kafka-登场&quot;&gt;1.2 Kafka 登场&lt;/h1&gt;

&lt;p&gt;Kafka 一般被称为“分布式提交日志”或者“分布式流平台”。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在数据库中，提交日志用来提供事务的持久化记录，可以通过回放这些日志还重建系统状态。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。同时，Kafka 的数据分布在整个系统中，具有数据故障保护，性能伸缩的能力。&lt;/p&gt;

&lt;h2 id=&quot;121-消息与批次&quot;&gt;1.2.1 消息与批次&lt;/h2&gt;

&lt;p&gt;Kafka 的数据单元被称为“消息”。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;消息由字节数据组成，因此消息内容没有特殊的含义或格式。&lt;/li&gt;
  &lt;li&gt;消息有一个可选元数据，被称为“键”。键也是一个字节数组，没有特殊含义。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;当消息以一种可控的方式写入不同的分区时，会使用键，保证相同键的消息被写到相同的分区上。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;“批次”是一组消息，这些消息属于同一个主题与分区。将消息按照批次写入到 Kafka，可以减少网络开销，有效提高效率。不过，批次大小需要在消息延迟与吞吐量之间进行权衡：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;批次越大，单位时间内处理的消息就越多；相应的，单个消息的延迟就越大&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;批次数据会被压缩，以提升传输与存储能力，但需要更多的计算处理&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;122-模式&quot;&gt;1.2.2 模式&lt;/h2&gt;

&lt;p&gt;对 Kafka 的来说，消息只是一些字节数组，难以理解，因此希望可以结构化定义消息内容。&lt;/p&gt;

&lt;p&gt;消息模式（Schema）有多种选项，如 JSON，XML；不过它们缺乏强类型处理能力，版本之间的兼容性也不好。&lt;/p&gt;

&lt;p&gt;最常用的 Kafka 消息模式是 Apache Avro：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;紧凑的序列化格式&lt;/li&gt;
  &lt;li&gt;模式与消息体分开；当模式发生变化时，不需要重新生成代码&lt;/li&gt;
  &lt;li&gt;支持强类型与模式进化，向前向后均兼容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;数据格式的一致性，消除了消息读写操作之间的耦合性&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;123-主题与分区&quot;&gt;1.2.3 主题与分区&lt;/h2&gt;

&lt;p&gt;消息通过主题（Topic）进行分类，主题可以被分为若干个分区（Partition）。消息以追加（Append）的方式写入分区，然后以先入先出的顺序读取。&lt;/p&gt;

&lt;p&gt;一个主题通常有多个分区，因此&lt;strong&gt;无法保证在主题范围内消息的有序性，但是可以保证消息在单个分区内有序&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如下所示，消息被追加到每个分区的尾部：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很多时候，人们会把一个主题的数据看作&lt;strong&gt;流&lt;/strong&gt;，而不管主题中包含多少个分区。流可以看作一组从生产者移动到消费者的数据。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;124-生产者与消费者&quot;&gt;1.2.4 生产者与消费者&lt;/h2&gt;

&lt;p&gt;Kafka 的生产者分为两种类型：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;生产者&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;生产者创建消息：一般情况下，消息会被发送到特定的主题，默认会把消息均衡地分布到主题的各个分区上（具体被分配到哪个分区并不重要）。&lt;/p&gt;

    &lt;p&gt;不过，也可以为消息指定分区，通过消息键与分区器将其映射到指定的分区。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;消费者&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;消费者读取消息：可以订阅一个或者多个主题，并按照消息生成的顺序读取它们。&lt;/p&gt;

    &lt;p&gt;消费者通过检查消息偏移量（Offset）来判断消息是否已经被读取过。&lt;strong&gt;消费者把每个分区最后读取的消息偏移量保存在 Zookeeper 或者 Kafka 上&lt;/strong&gt;，以保证在消费者重启之后可以从之前的位置继续消费。&lt;/p&gt;

    &lt;p&gt;偏移量是消息的元数据，是一个不断递增的整数值。在 Kafka 创建消息时，会设置其偏移量。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;在给定的分区内，消息的偏移量是唯一的&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;消费者是消费者群组的一部分；消费者群组保证每个分区只会被一个消费者读取，消费者与分区之间的映射关系被称为消费者对分区的所有权关系。通过这种方式，消费者可以消费包含大量消息的主题，并且当一个消费者失效时，其他消费者可以接管失效消费者的工作。&lt;/p&gt;

&lt;p&gt;如下所示，消费者群组与分区的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;125-broker-与集群&quot;&gt;1.2.5 Broker 与集群&lt;/h2&gt;

&lt;p&gt;一个独立的 Kafka 服务器被称为 Broker。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Broker 接收生产者的消息，为消息设置偏移量，并将消息保存到磁盘&lt;/li&gt;
  &lt;li&gt;Broker 对消费者读取分区的请求，返回已经提交到磁盘上的消息&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;单个 Broker 可以处理上千个分区以及每秒百万级的消息量&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Broker 是集群的组成部分，每个集群都有一个 Broker 同时充当&lt;strong&gt;集群控制器&lt;/strong&gt;的角色。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;集群控制器自动从集群的活跃成员中选出来&lt;/li&gt;
  &lt;li&gt;集群控制器负责集群管理工作，如将分区分配给 Broker，监控 Broker 等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在集群中，一个分区从属一个 Broker，该 Broker 被称为该分区的 Leader。同时，可以对分区进行复制，分区副本可以被分配给多个 Broker。&lt;strong&gt;复制机制为分区提供了消息冗余&lt;/strong&gt;，如果 Leader 失效，其他 Broker 可以接管领导权；相关的生产者及消费者都需要迁移到新的 Leader。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Broker 中的消息可以通过一些参数设置保留时间，过期的消息会被删除。&lt;/p&gt;

&lt;h2 id=&quot;126-多集群&quot;&gt;1.2.6 多集群&lt;/h2&gt;

&lt;p&gt;有以下需求时，可以使用多集群：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据类型分离&lt;/li&gt;
  &lt;li&gt;安全需求隔离&lt;/li&gt;
  &lt;li&gt;多数据中心（容灾恢复）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在多数据中心内部署多个集群时，可以通过 MirrorMaker 工具实现集群间数据复制功能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;13-why-kafka&quot;&gt;1.3 Why Kafka?&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;多个生产者&lt;/p&gt;

    &lt;p&gt;支持多个生产者往单个主题或者多个主题发送消息，适合从多个系统中收集数据&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;多个消费者&lt;/p&gt;

    &lt;p&gt;支持多个消费者从一个消息流上读取数据，且消费者之间互不影响。同时，消费者群组内的消费者共享消息流，并且保证对于整个群组，每个消息只被处理一次。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;基于磁盘的数据存储&lt;/p&gt;

    &lt;p&gt;消息被保存到磁盘上，并且每个主题可以设置单独的保存规则，以满足不同消费者的需求。&lt;/p&gt;

    &lt;p&gt;数据持久化可以保证消息不丢失，允许消费者非实时地读取消息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;伸缩性&lt;/p&gt;

    &lt;p&gt;为了支持大量数据处理，Broker 集群支持灵活扩展。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;高性能&lt;/p&gt;

    &lt;p&gt;通过横向扩展生产者，消费者及 Broker，使得 Kafka 在处理大量消息时可以保证亚秒级延迟。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1.1 发布订阅消息系统</summary></entry><entry><title type="html">Kafka: Writing Messages to Kafka</title><link href="http://localhost:4000/kafka-in-action-3.html" rel="alternate" type="text/html" title="Kafka: Writing Messages to Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-3</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-3.html">&lt;h1 id=&quot;1-生产者概述&quot;&gt;1. 生产者概述&lt;/h1&gt;

&lt;p&gt;需要往 Kafka 写消息的场景有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;记录用户活动&lt;/li&gt;
  &lt;li&gt;记录度量指标，监控数据&lt;/li&gt;
  &lt;li&gt;保存日志消息&lt;/li&gt;
  &lt;li&gt;与其他应用程序进行异步通信&lt;/li&gt;
  &lt;li&gt;缓冲即将写入到数据库中的数据&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于这些不同的使用场景，我们需要分析：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;是否每个消息都很重要&lt;/li&gt;
  &lt;li&gt;是否允许丢失一小部分消息&lt;/li&gt;
  &lt;li&gt;是否可以接受偶尔的消息重复&lt;/li&gt;
  &lt;li&gt;对消息的延迟及吞吐量是否严格要求&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不同的使用场景对生产者 API 的使用和配置都会有直接影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_3/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图展示了向 Kafka 发送消息的主要步骤：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;消息先被放入缓冲区，之后由单独的线程发送到 Broker&lt;/strong&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;创建 ProducerRecord 对象，包含目标主题，发送的内容，还可以指定 Key，分区&lt;/li&gt;
  &lt;li&gt;数据被序列化二进制字节数组&lt;/li&gt;
  &lt;li&gt;数据被传送给分区器
    &lt;ol&gt;
      &lt;li&gt;如果提前指定了分区，那么分区器将不会做任何事情&lt;/li&gt;
      &lt;li&gt;如果没有指定分区，那么分区器就会根据 ProducerRecord 对象的 Key 选择一个分区&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;生产者已经明确应该往哪个主题与分区发送消息了，该记录会被添加到一个记录批次里，该批次里的所有消息都会被发送到同一个主题与分区上
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;存在一个独立的线程负责把这些记录批次发送到相应的 Broker 上&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;服务器收到消息后会返回一个响应
    &lt;ol&gt;
      &lt;li&gt;如果成功写入 Kafka，则返回一个 RecordMetaData 对象，包含了主题和分区信息，以及记录在分区中的偏移量（Offset）&lt;/li&gt;
      &lt;li&gt;如果写入失败，则返回一个错误消息&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;生产者在收到错误之后就会尝试重新发送消息，几次重试之后如果还是失败，则返回错误信息&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2-创建-kafka-生产者&quot;&gt;2. 创建 Kafka 生产者&lt;/h1&gt;

&lt;p&gt;创建 Kafka 生产者需要设置 3 个必要属性：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;bootstrap.servers&lt;/p&gt;

    &lt;p&gt;指定 Broker 的地址列表，格式为 host:port。（该列表不需要包含所有 Broker 地址，生产者会从给定的 Broker 中找到其他 Broker 信息）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;key.serializer&lt;/p&gt;

    &lt;p&gt;Broker 接收的消息的 key &amp;amp; value 都是字节数组。因此，生产者需要把 key 序列化成字节数组。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;key.serializer 需要实现 org.apache.kafka.common.serialization.Serializer 接口&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;value.serializer&lt;/p&gt;

    &lt;p&gt;同 key.serializer&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;创建生产者代码 Demo:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;broker1:9092,broker2:9092&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;3-发送消息到-kafka-生产者&quot;&gt;3. 发送消息到 Kafka 生产者&lt;/h1&gt;

&lt;p&gt;生产者创建完成后，可以向 Broker 发送消息。有 3 种发送消息的方式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;发送并忘记&lt;/strong&gt;（&lt;em&gt;Fire-and-forget&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;将消息发送给 Broker 服务器，但是并不关心是否正常到达。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;多数情况下，消息会成功被接收（失败后会自动重试），但是有时候会丢失一些消息。&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;同步发送&lt;/strong&gt;（&lt;em&gt;Synchronous send&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法返回一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Future&lt;/code&gt; 对象，调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Future.get()&lt;/code&gt; 方法等待，可以判断消失是否成功发送。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;异步发送&lt;/strong&gt;（&lt;em&gt;Asynchronous send&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法并指定回调函数，当接收到 Broker 的响应之后，回调函数被触发。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;简单的发送消息代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Precision Products&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;France&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// send() 方法会返回一个包含 RecordMetaData 的 Future 对象&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 但是我们直接忽略返回值，所以无法感知到消息是否发送成功&lt;/span&gt;
	  &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 我们可以忽略发送消息时可能发生的异常，或者在服务端发生的异常&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 但是发送消息之前，生产者可能发生其他异常，如序列化异常，缓冲区已满，发送线程被中断等&lt;/span&gt;
	  &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;31-同步发送消息sending-a-message-synchronously&quot;&gt;3.1 同步发送消息（&lt;strong&gt;Sending a Message Synchronously&lt;/strong&gt;）&lt;/h2&gt;

&lt;p&gt;同步发送消息代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Precision Products&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;France&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 如果服务器返回错误，get() 方法会抛出异常&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 如果没有发生错误，get() 方法会返回 RecordMetaData 对象，可以用来获取消息的偏移量&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生产者发送消息一般会发生两类异常：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;可重试异常&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;可以通过重发消息解决；常见的错误有：连接异常，无主（no leader）异常等。&lt;/p&gt;

    &lt;p&gt;KafkaProducer 可以设置成自动重试，但是如果多次重试之后仍无法解决问题，会收到一个重试异常。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;不可重试异常&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;对于这类异常，生产者不会进行任何重试，直接抛出异常；常见的错误有：消息太大（message size too large）异常。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;32-异步发送消息sending-a-message-asynchronously&quot;&gt;3.2 异步发送消息（&lt;strong&gt;Sending a Message Asynchronously&lt;/strong&gt;）&lt;/h2&gt;

&lt;p&gt;如果每个消息发送之后都需要同步等待响应，那么应用程序的吞吐量将会大大下降。虽然 Kafka 会把目标主题，分区信息，消息偏移量发送回来，但是对于很多发送端的应用程序来说并不是必需的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;多数情况下，我们不需要等待 Broker 的响应。不过，当消息发送失败时，我们可能需要对异常进行处理分析&lt;/strong&gt;，如抛出异常，记录错误日志等。&lt;/p&gt;

&lt;p&gt;为了在消息发送异常时进行处理，生产者提供了回调支持。代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 需要实现 org.apache.kafka. clients.producer.Callback 接口&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DemoProducerCallback&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callback&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onCompletion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RecordMetadata&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Biomedical Materials&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USA&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DemoProducerCallback&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;4-配置生产者&quot;&gt;4. 配置生产者&lt;/h1&gt;

&lt;p&gt;除了之前提到的 3 个必要参数，生产者还有其他可配置的参数；其中一些参数在内存使用，性能，可靠性方面对生产者影响较大。&lt;/p&gt;

&lt;h2 id=&quot;41-acks&quot;&gt;4.1 acks&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;该参数指定了必须要多少个分区副本收到消息，生产者才会认为消息写入是成功的&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;acks 参数配置影响消息丢失的可能性&lt;/p&gt;

&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 0&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;发送消息之后，生产者不会等待任何服务器的响应。&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;如果发送过程中出现了问题，导致服务器没有收到消息，生产者无从得知，消息也会丢失&lt;/li&gt;
      &lt;li&gt;由于不需要等待服务器响应，发送消息的吞吐量会很大&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 1&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;只要 Leader 副本收到消息，生产者就会收到来自 Broker 的成功响应。&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;如果消息无法成功写入 Leader 副本（如 Leader 崩溃），那么生产者就会收到一个错误响应；为避免消息丢失，生产者会重试发送。&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;如果 Leader 收到消息后崩溃，并且该消息没有来得及同步到其他副本中，那么消息仍会丢失&lt;/p&gt;

        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;此时的吞吐量取决于是采用同步发送还是异步发送&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = all&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;只有当所有同步副本（in-sync replicas）都收到消息时，生产者才会收到来自 Broker 的成功响应&lt;/strong&gt;。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;这种模式可以使得消息发送更可靠，更不易丢失&lt;/li&gt;
      &lt;li&gt;但是，消息发送的延迟更高（需要等待多个副本收到消息）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;42-buffermemory&quot;&gt;4.2 buffer.memory&lt;/h2&gt;

&lt;p&gt;该参数用来设置生产者内存缓冲区的大小；生产者用其缓存将要发送到服务器的消息。&lt;/p&gt;

&lt;p&gt;如果应用程序发送消息的速度超过将缓冲区消息发送到服务器的速度，会导致生产者空间不足。此时，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法会被阻塞或者抛出异常。&lt;/p&gt;

&lt;h2 id=&quot;43-compressiontype&quot;&gt;4.3 compression.type&lt;/h2&gt;

&lt;p&gt;默认情况下，消息发送不会被压缩。不过，可以通过该参数指定压缩算法，如 snappy, gzip, lz4。&lt;/p&gt;

&lt;h2 id=&quot;44-retries&quot;&gt;4.4 retries&lt;/h2&gt;

&lt;p&gt;消息发送时可能会遇到临时且可重试的错误，可以通过 retries 参数配置生产者可重发消息的次数。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果重试次数达到该配置，生产者就会放弃重试并返回异常&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;45-batchsize&quot;&gt;4.5 batch.size&lt;/h2&gt;

&lt;p&gt;当多个消息被发送到同一个分区时，生产者会将其放到同一个批次中。该参数指定了一个批次可用内存大小（按字节计算，而不是消息个数）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当批次被填满时，该批次里的消息被发送&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;46-lingerms&quot;&gt;4.6 linger.ms&lt;/h2&gt;

&lt;p&gt;该参数指定了生产者在发送批次前等待其他消息加入批次的时间。&lt;/p&gt;

&lt;p&gt;当批次被填满或者 linger.ms 达到上限时，将批次消息发送出去。&lt;/p&gt;

&lt;h2 id=&quot;47-maxinflightrequestsperconnection&quot;&gt;4.7 &lt;strong&gt;max.in.flight.requests.per.connection&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;该参数指定&lt;strong&gt;生产者在收到服务器响应之前，可以发送多少个消息&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果该值为 1，可以保证消息时按照发送的顺序写入服务器，即使发生重试&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;该参数值设置得较高可以增加内存使用量，同时提高吞吐量，但设置得太高可能会降低吞吐量，因为批处理效率会降低。&lt;/p&gt;

&lt;h2 id=&quot;48-maxrequestsizesh&quot;&gt;4.8 &lt;strong&gt;max.request.sizesh&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;控制生产者发送请求的大小&lt;/p&gt;

&lt;h2 id=&quot;49-顺序保证&quot;&gt;4.9 顺序保证&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Kafka 可以保证同一个分区内的消息是有序的&lt;/strong&gt;。即，如果生产者按照一定的顺序发送消息，Broker 就会按照这个顺序将消息写入分区。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reties &amp;gt; 0, max.in.flight.requests.per.connection &amp;gt; 1&lt;/code&gt;，那么如果第一个批次的消息写入失败，而第二个批次消息写入成功。Broker 会重试第一个批次的消息，如果重试成功，那么两个批次的消息就会反过来。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reties &amp;gt; 0, max.in.flight.requests.per.connection = 1&lt;/code&gt;，那么生产者在尝试发送第一批次消息时，不会有其他消息发送给 Broker。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;这种配置会严重影响生产者的吞吐量，只有在对消息顺序有严格要求时才能这么配置&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-分区&quot;&gt;5. 分区&lt;/h1&gt;

&lt;p&gt;在发送消息时，可以指定消息的 key，也可以将 key = null。key 有两个用途：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;作为消息的附加信息&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;用来决定该消息被发送到主题的哪个分区。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;拥有相同 key 的消息会被写入到同一个分区中&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果 key == null，并且使用默认的分区器，那么消息将会被随机发送到各个可用的分区上。&lt;/p&gt;

&lt;p&gt;如果 key ≠ null，并且使用默认的分区器，那么 Kafka 会先对 key 进行 hash，之后根据 hash 值将消息映射到特定的分区上，使得同一个 key 的消息总会被映射到同一个分区上。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在进行映射时，会使用所有的分区，而不是可用的分区。所以，如果分区不可用，写入将出错&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;需要注意的是，只有在主题分区数量不变的情况下，key 与分区的映射次啊会保持不变。如果分区数发生变化，那么新的消息可能别写入到其他分区上，因此在创建主题时需要把分区规划好。&lt;/p&gt;

&lt;h2 id=&quot;51-自定义分区策略&quot;&gt;5.1 自定义分区策略&lt;/h2&gt;

&lt;p&gt;默认分区器能够满足大部分需求，不过也可以使用自定义分区进行消息管理。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BananaPartitioner&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Partitioner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

	  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;configure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt;
	
	  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valueBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cluster&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PartitionInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partitionsForTopic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
				&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceOf&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;InvalidRecordException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;We expect all messages to have customer name as key&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
					
				&lt;span class=&quot;c1&quot;&gt;// Banana will always go to last partition&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Banana&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
				&lt;span class=&quot;c1&quot;&gt;// Other records will get hashed to the rest of the partitions&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;murmur2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. 生产者概述</summary></entry><entry><title type="html">Kafka: Configure Kafka</title><link href="http://localhost:4000/kafka-in-action-2.html" rel="alternate" type="text/html" title="Kafka: Configure Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-2</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-2.html">&lt;h1 id=&quot;1-broker-配置&quot;&gt;1. Broker 配置&lt;/h1&gt;

&lt;h2 id=&quot;11-numpartitions&quot;&gt;1.1 &lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;指定了主题分区数。Kafka 集群通过分区对主题进行横向扩展，当有新的 Broker 加入集群时，可以通过分区实现负载均衡。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;不过，并不强制要求分区数大于 Broker 数。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;在进行分区数量选择时，需要考虑以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主题的吞吐量&lt;/li&gt;
  &lt;li&gt;消费者从单个分区读取数据的吞吐量&lt;/li&gt;
  &lt;li&gt;生产者往单个分区写入数据的吞吐量&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个 Broker 包含的分区个数，可用的磁盘空间与网络带宽&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;单个 Broker 所承载的分区个数是有限的：分区越多，占用内存越多，分区 Leader 选举的时间越长&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;如果消息是按照 Key 写入各个分区的，那么新增分区会比较麻烦&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;11-logretentionms&quot;&gt;1.1 log.retention.ms&lt;/h2&gt;

&lt;p&gt;数据被保留的时间；对应的有 log.retention.minutes, log.retention.hours.&lt;/p&gt;

&lt;h2 id=&quot;13-logretentionbytes&quot;&gt;1.3 log.retention.bytes&lt;/h2&gt;

&lt;p&gt;数据被保留的大小；该参数作用在每个分区上&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果同时指定了数据保留的时间与大小参数，那么只要任意一个参数满足，数据就会被删除&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;14-logsegmentbytes&quot;&gt;1.4 log.segment.bytes&lt;/h2&gt;

&lt;p&gt;当消息到达 Broker 时，会被追加到分区的当前日志片段（segment）上。当日志片段大小达到了 log.segment.bytes 时，当前日志片段就会被关闭，新的日志片段会被打开。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;被关闭的日志片段，就开始等待过期&lt;/strong&gt;。如果日志片段一直没被关闭，就不会过期。上面的 log.retention.ms/bytes 日志过期参数需要在日志片段关闭之后才有效。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;该参数值越小，会导致越频繁地开启与关闭文件，降低磁盘效率&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;15-logsegmentms&quot;&gt;1.5 log.segment.ms&lt;/h2&gt;

&lt;p&gt;日志片段被关闭的时间。&lt;/p&gt;

&lt;p&gt;如果同时指定了 log.segment.ms/bytes 两个参数，那么日志片段会在大小/时间达到上限时被关闭。&lt;/p&gt;

&lt;h2 id=&quot;16-messagemaxbytes&quot;&gt;1.6 message.max.bytes&lt;/h2&gt;

&lt;p&gt;用来限制单个消息的大小。如果生产者发送的消息大于该值，那么消息不会被接收，并且 Broker 会返回错误消息。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果该值越大，那么请求处理耗时就越大。同时，会增加磁盘写入块的大小，影响 IO 吞吐量。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;2-硬件&quot;&gt;2. 硬件&lt;/h1&gt;

&lt;p&gt;Kafka 本身对硬件没什么要求，但是如果对系统性能比较关注，可以注意以下几点：&lt;/p&gt;

&lt;h2 id=&quot;21-磁盘吞吐量&quot;&gt;2.1 磁盘吞吐量&lt;/h2&gt;

&lt;p&gt;生产者客户端的性能受服务端磁盘吞吐量的影响。生产者在发送完消息之后，一般会等待服务端将消息保存在磁盘上，磁盘写入越快，客户端生成消息的延迟就越低。&lt;/p&gt;

&lt;h2 id=&quot;22-磁盘容量&quot;&gt;2.2 磁盘容量&lt;/h2&gt;

&lt;p&gt;磁盘容量大小取决于需要保存的消息数量，同时也受集群复制策略的影响。&lt;/p&gt;

&lt;h2 id=&quot;23-内存&quot;&gt;2.3 内存&lt;/h2&gt;

&lt;p&gt;除了磁盘性能，服务端可用内存容量也是影响客户端性能的主要因素。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;磁盘影响生产者，而内存影响消费者&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;一般情况下，消费者从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。此时，&lt;strong&gt;消费者读取的消息会直接放在系统的页面缓存里&lt;/strong&gt;，比磁盘上重新读取性能更高。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;运行 Kafka 的 JVM 不需要太大的缓存，剩余的系统内存可以直接用作页面缓存，或者缓存正在使用中的日志片段&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;24-网络&quot;&gt;2.4 网络&lt;/h2&gt;

&lt;p&gt;网络吞吐量决定了 Kafka 能够处理的最大数据流量。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;网络吞吐量与磁盘存储是制约 Kafka 扩展规模的主要因素&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;25-cpu&quot;&gt;2.5 CPU&lt;/h2&gt;

&lt;p&gt;Kafka 对计算处理能力要求较低，主要用在消息批量压缩与解压过程中。&lt;/p&gt;

&lt;h1 id=&quot;3-kafka-集群&quot;&gt;3. Kafka 集群&lt;/h1&gt;

&lt;p&gt;使用 Kafka 集群可以为客户端提供高性能与高可用性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以跨服务器进行负载均衡&lt;/li&gt;
  &lt;li&gt;使用复制功能避免单点故障造成的数据丢失&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_2/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;31-broker-数量&quot;&gt;3.1 Broker 数量&lt;/h2&gt;

&lt;p&gt;一个 Kafka 集群需要多少个 Broker 数量取决于下面几个因素：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;需要多少磁盘空间保存数据&lt;/p&gt;

    &lt;p&gt;单个 Broker 有多少可用空间，副本的复制系数多少&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;集群处理请求的能力&lt;/p&gt;

    &lt;p&gt;需要考虑网络吞吐量，磁盘吞吐量，系统内存容量因素&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;32-操作系统调优&quot;&gt;3.2 操作系统调优&lt;/h2&gt;

&lt;p&gt;默认操作系统配置已经能够满足大部分应用程序的运行需求，不过可以优化一些参数进一步提升性能，这些参数主要与虚拟内存，网络子系统，存储日志的磁盘挂载点有关。&lt;/p&gt;

&lt;h3 id=&quot;321-虚拟内存&quot;&gt;3.2.1 虚拟内存&lt;/h3&gt;

&lt;p&gt;为了提高系统吞吐量，应该尽量避免内存交换。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;内存页与磁盘之间的交换对 Kafka 各方面性能都有影响。Kafka 大量使用系统页面缓存，如果虚拟内存被交换到磁盘，说明没有多余的内存分配给页面缓存了。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;一种优化方式是，不设置任何交换分区，避免内存交换。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;奸笑 vm.swappiness 参数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另一种优化方式是，调整内核对脏页的处理方式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;减小 vm.dirty_background_ratio 参数，增大 vm.dirty_ratio 参数&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;322-磁盘&quot;&gt;3.2.2 磁盘&lt;/h3&gt;

&lt;p&gt;除了合适的磁盘硬件设备，文件系统是影响性能的另一个重要因素。&lt;/p&gt;

&lt;p&gt;XFS 批量磁盘写入具有更高的效率，提高整体的 IO 吞吐量，为 Kafka 提供更好的性能。&lt;/p&gt;

&lt;h3 id=&quot;323-网络&quot;&gt;3.2.3 网络&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;调整分配给 Socket 读写缓冲区的内存大小&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;参数 net.core.wmem_default, net.core.rmem_default.&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;调整 TCP Socket 读写缓冲区&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;参数 net.ipv4.tcp_wmem, net.ipv4.tcp_rmem&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. Broker 配置</summary></entry><entry><title type="html">Lion: Multi-Region Data Synchronization</title><link href="http://localhost:4000/multi-region-data-synchronization.html" rel="alternate" type="text/html" title="Lion: Multi-Region Data Synchronization" /><published>2023-03-12T00:00:00+08:00</published><updated>2023-03-12T00:00:00+08:00</updated><id>http://localhost:4000/multi-region-data-synchronization</id><content type="html" xml:base="http://localhost:4000/multi-region-data-synchronization.html">&lt;h1 id=&quot;1文档概述&quot;&gt;1、文档概述&lt;/h1&gt;

&lt;h2 id=&quot;11项目背景&quot;&gt;1.1 项目背景&lt;/h2&gt;

&lt;p&gt;Lion 目前部署在北京，上海两侧数据中心，北上两地双向同步。对于未来怀来，香港或者其他数据中心的规划，Lion 暂不支持其他数据中心的数据同步。&lt;/p&gt;

&lt;p&gt;短期内可以通过 Region 内流量闭环，数据访问仍使用北上两地数据中心的方案临时支持，长期需要探索支持多数据中心同步功能。&lt;/p&gt;

&lt;h2 id=&quot;12项目目标&quot;&gt;1.2 项目目标&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;支持多数据中心间数据同步（同步方向可自定义设置）&lt;/li&gt;
  &lt;li&gt;同一 Region 内数据和流量闭环&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;13名词解释&quot;&gt;1.3 名词解释&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;名词&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DTS&lt;/td&gt;
      &lt;td&gt;美团内部一种集数据订阅、数据同步、数据迁移于一体的数据传输服务&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DRC&lt;/td&gt;
      &lt;td&gt;饿了么数据复制中心&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MGR&lt;/td&gt;
      &lt;td&gt;MySQL 组复制&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion&lt;/td&gt;
      &lt;td&gt;美团内部配置统一管理和实时推送的平台&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Consistency&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责数据同步模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Manager（新增）&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责同步任务管理模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Meta&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责服务注册发现模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion API/Console&lt;/td&gt;
      &lt;td&gt;Lion 系统内 Open API 及管理端模块&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;2整体架构&quot;&gt;2、整体架构&lt;/h1&gt;

&lt;h2 id=&quot;21-技术调研&quot;&gt;2.1 技术调研&lt;/h2&gt;

&lt;h3 id=&quot;211-拓扑结构调研&quot;&gt;2.1.1 拓扑结构调研&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;拓扑模型&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
      &lt;th&gt;比较&lt;/th&gt;
      &lt;th&gt;结论&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;星型拓扑&lt;/td&gt;
      &lt;td&gt;一个指定的根节点将写入转发给所有其他节点&lt;/td&gt;
      &lt;td&gt;优点 1.同步链路保持一定的顺序，数据一致性可以得到提升; 2.运维相对简单。缺点：1.由于数据同步需要通过中间节点转发，中间节点可能会成为性能瓶颈，容易出现单点故障，系统容错降低;2.由于顺序同步，使得整体数据同步延迟会增大（节点数越多，延迟越大）&lt;/td&gt;
      &lt;td&gt;采用星型拓扑结构:1.超过2/3的配置变更集中在北京，后续怀来，上海可以以北京为主进行同步;2.以北京为主，在数据冲突，一致性保证方面处理相对简单，包括增量一致性检测功能实现&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;全部至全部型（网状型）&lt;/td&gt;
      &lt;td&gt;每个主节点将其写入同步到其他所有主节点&lt;/td&gt;
      &lt;td&gt;优点:1.数据同步链路更密集，数据可以沿着不同路径传播，避免了单点故障，容错性更高;2.数据变更全链路广播，整体同步延迟相对更低. 缺点:1.同步链路顺序无法得到保障，数据冲突的情况更复杂（可能所有节点都需要处理冲突）;2.运维更加复杂&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;212-同步方案调研&quot;&gt;&lt;strong&gt;2.1.2 同步方案调研&lt;/strong&gt;&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;业界方案&lt;/th&gt;
      &lt;th&gt;部署架构&lt;/th&gt;
      &lt;th&gt;整体介绍&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;美团 DTS&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;1.Reader 模块与源 DB 同地域部署，从源 DB dump Binlog，并存储在本地内存与磁盘中; 2.Writer 模块与目标 DB 同地域部署，从 Reader 中消费 Binlog，并将数据写入目标 DB 中; 3.Reader 与 Writer 之间通过私有协议实现高速传输；任务调度依赖 Lion 配置下发&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1479786749&quot;&gt;DTS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;饿了么 DRC&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;1.Replicator 模块：用于解析源 DB 的 Binlog，并缓存到一个超大的 Event Buffer 中；同时将解析结果通过 TCP 推动到目标 Applier 模块;2.Applier 模块：接收从 Replicator 推送的数据，并写入到目标 DB 中;3.Console 模块：用于控制管理&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1479723243&quot;&gt;DRC&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;DTS 与 DRC 在架构部署上比较类似，有一些共通的地方：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;读写分离&lt;/strong&gt;：Binlog 订阅与回放逻辑拆分为两个模块：Reader，Writer，进行读写分离；两个模块可分别按需扩展，提高系统扩展性&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同地域部署&lt;/strong&gt;：Reader 模块与源 DB 同地域部署，Writer 模块与目标 DB 同地域部署；Reader 与 Writer 之间通过私有协议高速传输&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;中心化管理&lt;/strong&gt;：Reader/Writer 涉及的订阅与回放任务分配都是通过中心模块统一调度，而不是由 Reader/Writer 模块分别管理&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Log 打标&lt;/strong&gt;：为了避免数据回环，对产生的 Log 进行打标，标识地域信息，在回放时进行过滤&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对上述几点 Lion 在设计过程中基本都可以借鉴，不过为了简化设计，Reader/Writer 模块不进行拆分，合并部署（不过仍然进行逻辑上角色区分）。&lt;/p&gt;

&lt;p&gt;💡 &lt;strong&gt;Q：为什么 Lion 不考虑直接接入 DTS ？&lt;/strong&gt;
A：1. DTS 目前所有运维动作、高可用强依赖 Lion，去掉 Lion 强依赖的情况下改造成本高，并且 SLA 无法保证
      2. DTS 目前在运维、宕机等场景存在数据回溯，不满 足Lion 低延迟、数据不回退（配置版本回退）要求
      3. 如果多中心之间两两互备，DTS 针对这种复杂链路，数据迁移拆分短期没有比较好的解决方&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q：DTS 与 DRC 都是通过 Binlog 订阅传输实现数据复制，Lion 是否也采取该方案？&lt;/strong&gt;
A：Lion 同步数据模型采用自定义 Log 结构。
      目前 Lion 北上数据中心间同步使用的是自定义 Log 数据，考虑到引入 MGR Binlog 订阅解析流程并不会对同步流程有显著的提升，并且会提高运维复杂度。
      同时，Lion 北上存量数据（Config, Release等表）并不完全一致，暂时无法直接采用 Binglog 进行同步。比如，由于同一条配置在北上最新版本号并不相同，如果从数据库层面强行保持一致，会触发一侧业务重新进行全量配置加载，有较大的风险。
      因此，Lion 仍保使用自定义 Log 结构。&lt;/p&gt;

&lt;h3 id=&quot;213-推拉选型&quot;&gt;2.1.3 推拉选型&lt;/h3&gt;

&lt;p&gt;这里的推拉模型指的是 Reader 与 Writer 之间传输 Log 的方式：1. Reader 主动将 Log 推送到 Writer；2. Writer 定时从 Reader 按需拉取 Log。&lt;/p&gt;

&lt;h2 id=&quot;22-设计总体思路&quot;&gt;2.2 设计总体思路&lt;/h2&gt;

&lt;h3 id=&quot;221-部署架构&quot;&gt;2.2.1 部署架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以北京，上海两个数据中心为例，每个数据中心部署了全量的 Lion 服务（部分服务未在图中展示）。通过同步配置变更到其他数据中心，使得每个数据中心拥有全量数据，能够独立提供完整的 Lion 功能。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;MGR (DB)&lt;/strong&gt;：持久化业务配置数据，同步日志，同步任务元数据等信息。MGR 有两种部署模式：
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;每中心单独部署&lt;/em&gt;&lt;/strong&gt;：存储中心内业务数据（如同步任务管理相关元数据），支持中心内流量与数据闭环。不同数据中心的 MGR 数据实时同步，最终每个数据中心拥有全量业务数据。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;特定中心部署&lt;/em&gt;&lt;/strong&gt;：存储公共数据，便于统一管理（如同步模块节点最新列表），支持不同数据中心的服务进行跨地域访问。只部署在指定数据中心（上海），供所有数据中心进行访问。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;：执行数据同步任务；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;无状态服务；逻辑上划分为 Reader，Writer 两种角色&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Reader&lt;/em&gt;&lt;/strong&gt;：对外暴露 HTTP API 接口，提供同步日志查询功能&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;功能很轻量：提供 API 接口供 Writer 访问&lt;/p&gt;

        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Writer&lt;/em&gt;&lt;/strong&gt;：调用 Reader 接口，实现同步日志在数据中心间传输逻辑；同时完成日志存储，回放等功能。
        &lt;ul&gt;
          &lt;li&gt;在访问其他数据中心的 Reader 之前，会从 Meta 查询异地数据中心内 Reader 可用节点列表（缓存在本地，定时更新）&lt;/li&gt;
          &lt;li&gt;每个 Writer 任务同步特定分区的日志，并将最新同步偏移量上报到 Manager&lt;/li&gt;
          &lt;li&gt;Writer 生命周期由 Manager 进行管理，会周期性上报自身状态&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;为了提高同步扩展性，将同步日志进行切片，每个 Writer 任务只会同步指定切片的日志。&lt;/p&gt;

    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;同步节点 : 同步任务 = 1 : N (每个同步节点上可能会运行多个同步任务)&lt;/p&gt;

    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;同步任务 : 同步分区 = 1 : 1 (每个同步任务只会同步一个分区内的日志)&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Manager (新增)&lt;/strong&gt;：用于同步元数据管理，同步任务调度；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;管理同步元数据&lt;/em&gt;&lt;/strong&gt;：1. 同步节点（Consistency）与同步分区（Partition）索引的映射关系；2. 同步分区最新同步偏移量（Offset）&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;同步任务调度&lt;/em&gt;&lt;/strong&gt;：1. 在同步节点上，根据分区索引创建对应同步任务；2. 分区索引迁移时，完成同步任务迁移；3. 与同步任务之间维持心跳，确保同步任务处于运行状态&lt;/li&gt;
      &lt;li&gt;每个数据中心内部署多个 Manager 节点，作为同步任务调度的中心模块：
        &lt;ol&gt;
          &lt;li&gt;与中心内同步节点（Consistency）周期交互：1. 下发同步任务创建/销毁的命令；2. 了解同步任务的运行状态；3. 确定同步任务最新偏移量&lt;/li&gt;
          &lt;li&gt;定时轮询 Meta 节点：查询中心内 Consistency 最新可用节点列表，在节点状态变更时进行同步分区 Rehash 及同步任务迁移&lt;/li&gt;
          &lt;li&gt;从中心内 MGR 加载同步任务元数据；将最新元数据持久化到 MGR&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;每个 Manager 节点都可以进行任务管理（并不是主从架构），为了减少多个 Manager 管理冲突，引入简单的分布式锁（Lion 内部已运行验证）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Meta&lt;/strong&gt;：提供 Lion 侧部分服务注册发现功能；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;同步节点（Consistency）上下线时，会由数据中心内的 Meta 节点维护其可用状态，并&lt;strong&gt;&lt;em&gt;将中心内最新可用节点列表存储在公共 DB 中&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;不同数据中心的 Meta 节点都可以查看所有数据中心的同步节点（Consistency）列表视图&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;API/Console&lt;/strong&gt;：Lion 管理端 / API 模块，为用户提供配置变更/查询等功能；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;每次配置变更都会产生对应的同步日志（Log），用于数据中心间配置同步&lt;/li&gt;
      &lt;li&gt;API/Console 请求的流量 + 访问的数据会在中心内实现闭环&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;222-数据模型&quot;&gt;2.2.2 数据模型&lt;/h3&gt;

&lt;h3 id=&quot;2221-同步日志&quot;&gt;2.2.2.1 同步日志&lt;/h3&gt;

&lt;p&gt;Lion 同步日志采用自定义 Log，而非 Binlog。根据同步阶段的不同，我们将 Log 拆分为两种形式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;源同步日志（source sync log）&lt;/strong&gt;：包含变更配置的详细信息。配置变更时，在本地数据中心产生一条日志，该日志会被其他数据中心加载，同步。&lt;/p&gt;

    &lt;p&gt;具体设计&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;id&lt;/th&gt;
          &lt;th&gt;release_key&lt;/th&gt;
          &lt;th&gt;timestamp&lt;/th&gt;
          &lt;th&gt;key&lt;/th&gt;
          &lt;th&gt;appkey&lt;/th&gt;
          &lt;th&gt;set/swimlane/env&lt;/th&gt;
          &lt;th&gt;old_value&lt;/th&gt;
          &lt;th&gt;new_value&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主键&lt;/td&gt;
          &lt;td&gt;变更唯一标识&lt;/td&gt;
          &lt;td&gt;变更时间戳&lt;/td&gt;
          &lt;td&gt;配置 key&lt;/td&gt;
          &lt;td&gt;配置 appkey&lt;/td&gt;
          &lt;td&gt;配置其他标识&lt;/td&gt;
          &lt;td&gt;旧值&lt;/td&gt;
          &lt;td&gt;新值&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;同步方向为&lt;strong&gt;上海 -&amp;gt; 北京&lt;/strong&gt;时，北京侧的 Consistency(Writer) 节点上的同步任务会不断从上海侧批量拉取&lt;strong&gt;&lt;em&gt;未同步&lt;/em&gt;&lt;/strong&gt;的 SourceSyncLog。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;通过 Offset 来标识已同步的 SourceSyncLog（id &amp;gt; offset : 未同步；id &amp;lt;= offset : 已同步）&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;目标同步日志（target sync log）&lt;/strong&gt;：通过回放该日志，将其他数据中心的最新配置更新到本地数据中心（目标同步日志是由源同步日志转化而来的）。&lt;/p&gt;

    &lt;p&gt;具体设计&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;id&lt;/th&gt;
          &lt;th&gt;source_idc&lt;/th&gt;
          &lt;th&gt;source_idc_log_id&lt;/th&gt;
          &lt;th&gt;status&lt;/th&gt;
          &lt;th&gt;release_key&lt;/th&gt;
          &lt;th&gt;timestamp&lt;/th&gt;
          &lt;th&gt;key&lt;/th&gt;
          &lt;th&gt;appkey&lt;/th&gt;
          &lt;th&gt;set/swimlane/env&lt;/th&gt;
          &lt;th&gt;old_value&lt;/th&gt;
          &lt;th&gt;new_value&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主键&lt;/td&gt;
          &lt;td&gt;源数据中心标识&lt;/td&gt;
          &lt;td&gt;源数据中心的 SourceSyncLog Id&lt;/td&gt;
          &lt;td&gt;同步状态&lt;/td&gt;
          &lt;td&gt;变更唯一标识&lt;/td&gt;
          &lt;td&gt;变更时间戳&lt;/td&gt;
          &lt;td&gt;配置 key&lt;/td&gt;
          &lt;td&gt;配置 appkey&lt;/td&gt;
          &lt;td&gt;配置其他标识&lt;/td&gt;
          &lt;td&gt;旧值&lt;/td&gt;
          &lt;td&gt;新值&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;同步方向为&lt;strong&gt;上海 -&amp;gt; 北京&lt;/strong&gt;时，北京侧的同步任务将从上海侧拉取到的 SourceSyncLog 转化成 TargetSyncLog，并插入本地 DB；之后会根据 TargetSyncLog 将上海侧的变更回放到本地。&lt;/p&gt;

    &lt;p&gt;💡 TargetSyncLog 比 SourceSyncLog 多了 source_idc, source_idc_log_id, status 字段，主要是为了避免数据回环，标识已同步位置等&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2222-同步任务元数据&quot;&gt;2.2.2.2 同步任务元数据&lt;/h3&gt;

&lt;p&gt;数据中心间 Log 传输简单来看就是将其他数据中心的 Log 复制到本侧数据中心，复制过程有几点需要考虑：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;同步链路控制&lt;/strong&gt;：应该明确哪些数据中心间可以进行同步，数据是单向同步还是双向同步&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步任务扩展性及性能&lt;/strong&gt;：如果集群中的单个同步节点都同步全量 Log，可能会使得同步性能较低，延迟较大；同时，集群无法水平扩容，扩展性低。我们应该将同步 Log 以切片的形式分配给各个集群节点，每个节点同步部分 Log，从而提高集群的扩展性及同步性能&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步稳定性&lt;/strong&gt;：节点状态经常变化（宕机/重启/扩容/下线），同步任务也随之不太稳定；我们应该保证在同步任务重启/迁移/销毁时，Log 同步尽量不遗漏，不重复&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;针对上面三点问题，可以通过相应的配置进行管理：&lt;/p&gt;

&lt;h3 id=&quot;22221-同步路由配置idc-routers&quot;&gt;&lt;strong&gt;2.2.2.2.1 同步路由配置（IDC Routers）&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;用于控制不同数据中心间的同步方向&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;target_idc&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;status&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;目标数据中心&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;（当前数据中心）&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步是否开启&lt;/td&gt;
      &lt;td&gt;数据同步方向：&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;source -&amp;gt; target&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：北京 -&amp;gt; 上海&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;target_idc&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;status&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;sh&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;22222-同步分区配置partitions&quot;&gt;2.2.2.2.2 同步分区配置（Partitions）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;同步节点与同步分区的映射关系&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;同步分区设计参考 Redis Cluster Slot 实现，人为提前设定分区总数，如分区总数 30，分区索引为 [0, 1, 2, 3, 4 … 29]。&lt;/p&gt;

    &lt;p&gt;每个同步节点负责一部分分区索引集合，如 node_1:[0, 2, 4, 6]，node_2:[1, 3, 5]。&lt;/p&gt;

    &lt;p&gt;在进行 Log 同步时，先对 Log Key 进行 Hash 取模，计算 Log 对应的分区索引，如果该索引值落在同步节点维护的范围内，则由该节点进行同步，否则忽略。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;通过这种方式，可以保证同一个 key 的变更会由相同的同步节点进行同步，保证同步顺序&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;node&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_indexes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;同步节点：Consistency(Writer)&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步分区索引列表&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：上海侧同步分区配置&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;node&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_indexes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;sh_node_1&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;[1, 2, 3, 4, 5]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;sh_node_2&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;[6, 7, 8, 9, 10]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;💡 该配置表示的是&lt;em&gt;本地数据&lt;/em&gt;中心同步任务的配置。通常，&lt;strong&gt;一个同步节点可能运行多个同步任务，每个同步任务负责同步特定的分区索引 Log。
分区总数提前配置好，且正常情况下保持不变；尽量保证分区索引在同步节点中均匀分配。&lt;/strong&gt;
同步节点 : 同步任务 = 1 : N (每个同步节点上可能会运行多个同步任务)
同步任务 : 同步分区 = 1 : 1 (每个同步任务只会同步一个分区)&lt;/p&gt;

&lt;h3 id=&quot;22223-日志分区偏移量配置offsets&quot;&gt;&lt;strong&gt;2.2.2.2.3 日志分区偏移量配置（Offsets）&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;记录每个分区最新同步位置&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_index&lt;/th&gt;
      &lt;th&gt;offset&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步分区索引&lt;/td&gt;
      &lt;td&gt;同步日志偏移量&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：北京分区偏移量配置&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_index&lt;/th&gt;
      &lt;th&gt;offset&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;💡 同步任务增量同步指定分区的部分 Log 之后，更新该分区的偏移量（offset），以便&lt;strong&gt;当同步任务重启/迁移后能够从上次同步的位置继续同步&lt;/strong&gt;。
每个源数据中心下的每个分区都需要维护自身的 Offset。&lt;/p&gt;

&lt;h3 id=&quot;223-manager--同步任务调度&quot;&gt;2.2.3 Manager : 同步任务调度&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前面提到，为了提高同步任务的扩展性，对同步日志进行了切片处理，&lt;strong&gt;每个同步任务只负责一个切片，每个同步节点上可运行多个同步任务&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Manager 作为同步任务管理的核心模块，主要与同数据中心内的同步节点（Consistency）节点进行交互，涉及功能有：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;初始化同步任务&lt;/strong&gt;：在新增数据中心，新增同步/集群节点，同步服务启动时，在同步节点（Consistency）上初始化同步任务&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步任务维护&lt;/strong&gt;：主动检测同步节点上各个任务的执行状态；在同步任务不可用时，及时销毁旧任务，创建新任务；当同步分区迁移时，主动在同步节点间迁移同步任务&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;日志分区分配&lt;/strong&gt;：当同步节点变更时，需要对分区进行分配，保证不同节点间同步负载尽可能均衡（&lt;em&gt;同步分区的变更会触发同步任务的迁移&lt;/em&gt;）&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;系统初始化时，由人工手动进行分区配置&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步节点监听&lt;/strong&gt;：Manager 会定时从 Meta 查询最新的同步节点列表，当发生节点变更时，触发分区重新分配&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分区偏移量维护&lt;/strong&gt;：同步任务在完成增量日志同步时，会上报当前分区最新偏移量并持久化，以便后续同步任务重启时能够从最新 Offset 处重新同步&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Manager 管理流程细节如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Manager 从 DB 中加载 IDC Routers，Partitions 原数据，用于明确数据同步方向（source-&amp;gt;target），同步节点维护的分区列表&lt;/li&gt;
  &lt;li&gt;Manager &lt;strong&gt;定时与同步节点通信&lt;/strong&gt;，获取节点上分区同步任务的执行状态：{partition_index: task_status}
    &lt;ol&gt;
      &lt;li&gt;如果同步节点维护的分区列表没有对应的同步任务执行，则在该同步节点上&lt;strong&gt;初始化对应分区同步任务&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;如果同步节点维护的部分分区任务执行状态异常，则在该同步节点上&lt;strong&gt;新建对应分区同步任务，并销毁旧同步任务&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;在同步任务正常执行期间，会上报最新已同步分区日志偏移量至 Manager，并持久化到 Offsets 表中&lt;/li&gt;
  &lt;li&gt;Manager 定时从 Meta 查询同步模块最新可用节点列表
    &lt;ol&gt;
      &lt;li&gt;如果新增/摘除同步节点，则 &lt;strong&gt;Manager 会对同步分区进行重新分配&lt;/strong&gt;，尽量保证分区均匀分配&lt;/li&gt;
      &lt;li&gt;分区重新分配之后，需要对同步任务进行迁移，确保&lt;strong&gt;同步节点维护的分区列表与同步任务一一对应&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面流程我们可以看到：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Offset 只会由同步任务上报并更新&lt;/strong&gt;； Offset 与 Partition 绑定&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partition 配置只在同步节点发生变更的时候才会变更&lt;/strong&gt;；Partition 与同步节点绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;💡 Q：数据中心初始化阶段，同步分区如何分配的？
A：初始阶段由人工手动为同步节点进行分区分配，并且分区总数需要大于节点数。如同步节点数为 5，分区总数为 30.&lt;/p&gt;

&lt;p&gt;Q：多个 Manager 会同时进行任务管理吗？
A：会的，同一数据中心内会有多个 Manager 节点进行管理，为了减少冲突，可以更新前使用简单的分布式锁（已在 Lion 当前实现中得到验证）.&lt;/p&gt;

&lt;h3 id=&quot;224-consistency--实时同步数据&quot;&gt;2.2.4 Consistency : 实时同步数据&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Manager 在同步节点（Consistency）上创建的同步任务用于实现不同数据中心间数据同步功能&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用户在北京侧变更配置，北京侧 DB 会插入一条 SourceSyncLog，该 Log 包含了配置变更的详细信息&lt;/li&gt;
  &lt;li&gt;上海侧同步任务（Writer）在运行时，会从 Manager &lt;strong&gt;加载对应分区的偏移量&lt;/strong&gt;，同时从 Meta 获取&lt;strong&gt;北京侧 Consistency 最新可用节点列表&lt;/strong&gt;，用于后续日志拉取&lt;/li&gt;
  &lt;li&gt;同步任务（Writer）&lt;strong&gt;随机访问&lt;/strong&gt;北京侧 Consistency（Reader）节点，根据 Offset 批量加载 SourceSyncLog
    &lt;ol&gt;
      &lt;li&gt;对北京侧返回的日志进行过滤，&lt;strong&gt;过滤出属于当前分区索引的部分日志&lt;/strong&gt;（对配置 key 取 hash）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;过滤完成后，同步任务首先将&lt;strong&gt;过滤结果日志批量保存在本地 DB&lt;/strong&gt;（TargetSyncLog）中
    &lt;ol&gt;
      &lt;li&gt;此时，保存在本地的 TargetSyncLog 的 Status 字段默认为&lt;em&gt;未同步状态&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;随后，同步任务（Writer）将日志依次回放，将北京侧的最新配置同步本地
    &lt;ol&gt;
      &lt;li&gt;同步成功之后，将 TargetSyncLog 的 Status 字段置为&lt;em&gt;同步成功状态&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;如果同步失败，则应将 Status 字段置为&lt;em&gt;同步失败状态&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;将回放完成的日志 &lt;strong&gt;LogId 作为最新分区 Offset&lt;/strong&gt; 上报给 Manager
    &lt;ol&gt;
      &lt;li&gt;不管回放成功还是失败，都需要上报 Offset，优先保证不阻塞后续日志同步 =&amp;gt; 对于失败的日志，由后续补扫任务继续同步&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;本批次同步完成之后，将以最新的 Offset 进行下一次同步流程&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;每个同步任务只会同步属于自身分区的日志，正常情况下，不同节点上的不同同步任务不会重复同步同一条日志（即使有少量重复同步也没影响）&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;💡 Q：日志同步流程是否可以将 Log 持久化到 DB 步骤移除？
A：日志回放过程可能会失败，通过将 Log 持久化，并标识状态，可以方便后续重新同步，保证不遗漏&lt;/p&gt;

&lt;p&gt;Q：整个流程基本为同步执行，是否会存在性能问题？
A：通过设置适当大小的分区（如 256），并考虑代码层面优化（如热点 key 聚合，分区内部再 hash），基本能够满足 Lion 需求&lt;/p&gt;

&lt;h3 id=&quot;225-同步集群节点变更与任务迁移&quot;&gt;2.2.5 同步集群节点变更与任务迁移&lt;/h3&gt;

&lt;p&gt;在日常运维中，集群节点变更是经常发生的，如服务发布，宿主机宕机，新增机器等。我们需要保证集群节点变化时，数据同步功能仍稳定执行。针对这类问题，进一步进行讨论。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个节点维护一部分分区，每个分区对应一个同步任务。当其中一个节点不可用时，该节点维护的分区集合就会被迁移到其他节点上，同时在其他节点上创建对应的分区同步任务。&lt;/p&gt;

&lt;p&gt;那么，在同步任务迁移（分区迁移）过程中，能否保证同步流程稳定执行？&lt;/p&gt;

&lt;p&gt;回看下同步任务的执行步骤，进一步分析：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在日志从异地加载过滤之后，将会持久化到 DB。之后会逐条顺序回放日志，回放完成后上报最新 Offset&lt;/p&gt;

&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;任务迁移时机&lt;/th&gt;
      &lt;th&gt;直接影响&lt;/th&gt;
      &lt;th&gt;同步稳定性影响&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 1: 日志加载&lt;/td&gt;
      &lt;td&gt;当前批次拉取失败&lt;/td&gt;
      &lt;td&gt;无影响：由于 Offset 未变化，迁移后的新任务会重新从当前位置拉取&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 2: 日志过滤，保存&lt;/td&gt;
      &lt;td&gt;拉取的日志保存失败&lt;/td&gt;
      &lt;td&gt;无影响：由于 Offset 未变化，迁移后的新任务会重新从当前位置拉取，过滤，保存&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 3: 逐条回放日志&lt;/td&gt;
      &lt;td&gt;该批次 logId &amp;gt; offset 的日志回放失败&lt;/td&gt;
      &lt;td&gt;少量日志重复同步：该批次 logId &amp;gt; offset 的日志会被新任务重新同步&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 4: 上报 Offset&lt;/td&gt;
      &lt;td&gt;该条回放完成的日志 logId 未上报&lt;/td&gt;
      &lt;td&gt;少量日志重复同步：该批次 logId &amp;gt; offset 的日志会被新任务重新同步&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;可以看出，在同步任务执行阶段的任何时机迁移，&lt;strong&gt;最坏的情况是该批次日志被重复同步&lt;/strong&gt;。而我们的同步流程支持幂等，且日志批次大小可控，因此，对同步流程的稳定性基本没有影响。&lt;/p&gt;

&lt;h3 id=&quot;226-补扫任务重新同步&quot;&gt;2.2.6 补扫任务：重新同步&lt;/h3&gt;

&lt;p&gt;在 Log 复制并同步到本地流程中，可能会因为 DB 异常/代码逻辑 Bug 等原因导致同步失败，为了不阻塞后续变更同步，在重试一定次数之后，应该放弃。&lt;/p&gt;

&lt;p&gt;但是，为了保证配置最终同步成功，应该对同步失败的 Log 进行重新同步。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;补扫任务定时从 TargetSyncLog 中加载未同步成功（可能是同步失败，也可能是未同步）的日志，同样按照分区进行过滤&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;为了避免扫描到刚复制过来，但还未同步完成中的日志，补扫任务需要扫描一定时间范围内的日志，如 1 分钟范围外&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对扫描到的日志进行重新同步，如果成功，则更新 Status 字段为同步成功状态；否则仍放弃，等待下次补扫任务同步&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;多次补扫同步仍可能失败，因此需要设置一个同步阈值，超过该阈值仍未成功，则触发告警，人工介入排查原因&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;补扫任务与同步节点是 1 : 1 的关系，即&lt;strong&gt;一个同步节点上只有一个补扫任务，并且该补扫任务负责多个日志分区&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假如同步节点负责的分区索引为 [1, 2, 3]，那么会有三个实时同步任务，每个实时同步任务分别负责一个分区；但是只有一个补扫任务，同时负责 [1, 2, 3] 分区&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;227-一致性检测&quot;&gt;2.2.7 一致性检测&lt;/h3&gt;

&lt;p&gt;实时同步与补扫同步流程能够保证大部分情况下配置一致性（&amp;gt;99.99%），仍有小概率会出现配置不一致的情况。&lt;/p&gt;

&lt;p&gt;因此除了实时同步，补扫同步，还需要增加增量一致性检测任务，对于不一致的配置进行再次检测与修复。&lt;/p&gt;

&lt;p&gt;理想情况下，增量一致性检测任务执行步骤如下：1. 每个数据中心的同步节点按照 IDC Router 配置，从目标 IDC 中查询指定配置的最新值；2. 将目标 IDC 返回的最新值进行比较（timestamp 比较），如果多个数据中心的配置值不同，则选择最新的配置值作为目标值，并更新本地。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;举例，北京侧有个配置 key = lion-test.demo，北京侧同步节点查询 lion-test.demo 在上海/怀来/香港侧的最新值，如果这几个数据中心的值都不同，则以最新值为主，将其更新本地&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;考虑到已知需要支撑的数据中心有北京/上海/怀来/香港，如果按照上面执行步骤，那么检测链路为 4*3，每两个数据中心间都需要进行一次比较，对于不一致冲突情况处理比较复杂。后续如果需要再新增数据中心，冲突处理情况将会更加复杂，不利于维护。&lt;/p&gt;

&lt;p&gt;现在 Lion 已经有北京/上海两个数据中心，上海侧的变更请求只有北京侧的一半，大部分变更触发源都在北京，即大部分数据同步方向为：北京 -&amp;gt; 上海。&lt;/p&gt;

&lt;p&gt;因此，为了简化不一致冲突处理，我们人为&lt;strong&gt;给数据中心设置优先级：北京 &amp;gt; 怀来 &amp;gt; 上海 &amp;gt; 香港&lt;/strong&gt;。&lt;strong&gt;北京数据中心作为主数据中心&lt;/strong&gt;，其他数据中心以北京侧为主进行增量一致性检测。&lt;/p&gt;

&lt;p&gt;但是，如果其他数据中心的数据比北京要新，则需要反哺北京，更新北京侧数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上海数据中心增量检测为例，基本流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;上海侧 Consistency 增量一致性检测任务查询本地指定时间范围内配置变更列表&lt;/li&gt;
  &lt;li&gt;通过 HTTP 请求查询北京侧对应配置的最新值，并进行比较时间戳
    &lt;ol&gt;
      &lt;li&gt;反哺：如果上海 Timestamp &amp;gt; 北京 Timestamp，则回调北京，在北京侧插入一条 TargetSyncLog，等待后续补扫任务重新同步&lt;/li&gt;
      &lt;li&gt;修复：如果上海 Timestamp &amp;lt;= 北京 Timestamp，则在上海侧插入一条 TargetSyncLog，等待后续补扫任务重新同步，完成修复&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;💡 Q：为什么日志同步时未对数据中心进行优先级划分，简化同步流程呢？
A：如果日志同步也按照这种方式处理，那么优先级低的数据中心的变更就不会同步到其他数据中心，不能满足多数据中心一致性的目标。
      从 Lion 现状来看，经过实时同步，补扫同步之后，北上数据一致性的比例 &amp;gt; 99.99%。而增量一致性检测是对实时同步，补扫同步的兜底处理，对一些极少数配置不一致的情况进行检测修复。&lt;/p&gt;

&lt;p&gt;Q：为什么只考虑增量一致性检测，不考虑全量检测？
A：全量一致性检测成本太高，且从 Lion 现状来看，实时同步 &amp;amp; 补扫同步 &amp;amp; 增量一致性检测能够满足 Lion 对数据一致性要求。&lt;/p&gt;

&lt;h3 id=&quot;228-数据同步可用性保障&quot;&gt;2.2.8 数据同步可用性保障&lt;/h3&gt;

&lt;h3 id=&quot;2281-冲突解决&quot;&gt;2.2.8.1 冲突解决&lt;/h3&gt;

&lt;p&gt;每次配置变更都会记录变更时间戳（timestamp），默认冲突解决为比较时间戳进行覆盖。&lt;/p&gt;

&lt;p&gt;如果时间戳相同，则根据 IDC 优先级进行覆盖：BJ &amp;gt; HL &amp;gt; SH &amp;gt; HK。&lt;/p&gt;

&lt;h3 id=&quot;2282-一致性保证&quot;&gt;2.2.8.2 一致性保证&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;同步日志持久化到本地 DB，同步失败后会进行多次重试（实时同步与补扫同步均会重试）&lt;/li&gt;
  &lt;li&gt;每批次从其他数据中心成功复制日志之后，会持久化最新分区 Log 偏移量。即使节点重启，或者分区迁移，都能保证从上次同步位置重新同步&lt;/li&gt;
  &lt;li&gt;根据同步日志同步变更的配置流程是幂等的，支持重复同步&lt;/li&gt;
  &lt;li&gt;增量一致性检测任务进行兜底检测&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2283-数据回环解决&quot;&gt;2.2.8.3 数据回环解决&lt;/h3&gt;

&lt;p&gt;同步日志在复制传输时，只会从目标 IDC 的 SourceSyncLog 表中查询，并保存在本地的 TargetSyncLog 表中，而根据 TargetSyncLog 执行数据同步的过程不会产生新的 SourceSyncLog，避免了数据回环的条件。即 &lt;strong&gt;&lt;em&gt;异地配置变更 -&amp;gt; SourceSyncLog -&amp;gt; TargetSyncLog -&amp;gt; 本地配置&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;23-上线方案&quot;&gt;2.3 上线方案&lt;/h1&gt;

&lt;h3 id=&quot;231-前期准备&quot;&gt;2.3.1 前期准备&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;BJ，SH 侧创建同步元数据表：IDC Router, Partitions, Offsets；同步日志表：SourceSyncLog, TargetSyncLog&lt;/li&gt;
  &lt;li&gt;BJ，SH 侧配置同步相关元数据&lt;/li&gt;
  &lt;li&gt;BJ，SH 侧添加同步开关配置，用于新旧版本数据同步方案切换（默认关闭，使用旧方式进行同步）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;232-上线步骤&quot;&gt;2.3.2 上线步骤&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;BJ，SH 服务发布：Manager, Consistency, Meta；此时配置变更会插入 Log 至 SourceSyncLog，但不通过该日志进行同步&lt;/li&gt;
  &lt;li&gt;开启 SH 侧同步开关：此时 BJ -&amp;gt; SH 采取新方案同步，SH -&amp;gt; BJ 仍采用旧方案同步
    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;记录下时间戳 T1，用于异常修复&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;观察监控：
    &lt;ol&gt;
      &lt;li&gt;同步流程正确性，同步日志堆积情况，同步延迟，北上数据一致性，增量一致性检测任务是否正常执行等&lt;/li&gt;
      &lt;li&gt;通过全链路监控查看配置变更推送是否正常&lt;/li&gt;
      &lt;li&gt;同时，观察 SH 侧 Offsets 是否持续增长&lt;/li&gt;
      &lt;li&gt;手动调整 SH 侧 Consistency 节点状态，观察 Partitions 是否正常调整，同步任务是否正常迁移，同步延迟/堆积是否符合预期&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;开启 BJ 侧同步开关：此时 BJ &amp;lt;-&amp;gt; SH 双向同步均采用新方案
    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;记录下当前时间戳 T2，用于异常修复&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;持续观察 SH，BJ 侧同步监控&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;233-回滚步骤&quot;&gt;2.3.3 回滚步骤&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;关闭 SH，BJ 侧同步开关：切回旧同步方案&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;调整 SH 侧增量一致性检测时间戳为 T1，BJ 侧时间戳调整为 T2&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;prefix = lion.instance.last.check.timestamp&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;持续观察监控：北上数据一致性，变更推送延迟等&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;24-非功能性设计&quot;&gt;2.4 非功能性设计&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;同步任务执行状态监控&lt;/li&gt;
  &lt;li&gt;同步分区变更周知&lt;/li&gt;
  &lt;li&gt;数据不一致告警&lt;/li&gt;
  &lt;li&gt;同步延迟监控，告警&lt;/li&gt;
  &lt;li&gt;同步堆积告警&lt;/li&gt;
  &lt;li&gt;多次同步失败告警&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3项目风险点&quot;&gt;3、项目风险点&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;同步任务的管理
    &lt;ol&gt;
      &lt;li&gt;能否准确判断同步任务的执行状态&lt;/li&gt;
      &lt;li&gt;Manager 能否准确完成同步任务的迁移，能否及时 Kill 不可用任务并新建任务&lt;/li&gt;
      &lt;li&gt;在 Manager 管理不符合预期的情况下，需要人为介入，手动执行任务的删除与创建&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Offset 上报时机
    &lt;ol&gt;
      &lt;li&gt;每回放一条 Log 就上报 Offset 可以保证可靠性，但是性能会有所损耗&lt;/li&gt;
      &lt;li&gt;是否可以调整 Offset 上报时机，如周期上报，这样可以提高部分性能，但是在任务迁移时可能会有 Log 重复同步，需要进行权衡&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;同步一致性保证
    &lt;ol&gt;
      &lt;li&gt;在新方案上线期间，如果数据不一致概率较高，需要及时切换旧方案&lt;/li&gt;
      &lt;li&gt;新方案在北上数据中心得到验证，并且长时间运行一段时间后，才能推广到多数据中心&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;4faq&quot;&gt;4、FAQ&lt;/h1&gt;

&lt;p&gt;Q：Writer 任务调度管理比较复杂，如果只有一个 Writer 任务同步全量数据，是否可行？&lt;/p&gt;

&lt;p&gt;A：如果只有一个 Writer 任务进行同步，那么 Writer 同步性能需要尽可能高，最低要支持 2000QPS。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;按照当前的同步逻辑，单个同步任务肯定无法支撑：单条日志顺序同步耗时 TP999 48.4ms&lt;/li&gt;
  &lt;li&gt;优化单条日志顺序同步 -&amp;gt; 批量同步：简单测试了下，性能大概提升 20% 左右，不太能满足要求（可能仍存在优化空间；单批次日志数量不能过多，可能会引发大事务）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们将同步任务进行切片处理，&lt;strong&gt;除了性能因素，还有服务扩展性考虑&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;随着业务配置增加，数据中心逐步建设，同步任务要支持水平扩展以保证 SLA&lt;/li&gt;
  &lt;li&gt;同步任务调度管理虽然比较复杂，但是部分逻辑（如分区迁移）已经经过线上验证，其稳定性及扩展性能够得到保障&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，我们仍倾向继续采用任务切片的形式。&lt;/p&gt;

&lt;p&gt;Q：能否灵活调整数据中心同步方向？如将香港 -&amp;gt; 北京的同步链路切断，或者香港侧数据中心不与其他数据中心同步&lt;/p&gt;

&lt;p&gt;A：通过更新 IDC Router 配置即可调整数据中心间的同步方向（source_idc -&amp;gt; target_idc）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更新 IDC Router 的 status 字段可以调整同步方向开启与否&lt;/li&gt;
  &lt;li&gt;新增 IDC Router 记录可以新增同步链路&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Q：能否支持 Appkey 粒度同步方向控制？如 lion-demo 项目只可以从北京同步到上海&lt;/p&gt;

&lt;p&gt;A：可以支持。不过只按照前面的描述还不能满足，需要额外的配置，如每个数据中心新增一个表 IDCFilter，在该表中配置哪些 IDC 中的 Appkey, Key 不需要进行同步。&lt;/p&gt;

&lt;p&gt;在同步任务进行日志过滤时直接忽略对应的 IDC, Appkey, Key 即可实现。&lt;/p&gt;

&lt;p&gt;Q：能够支持部分业务同步流程隔离？如数据库相关配置与普通业务配置同步隔离&lt;/p&gt;

&lt;p&gt;A：可以支持；将特定范围的分区（如 1000 ～ 1024）单独划分出来给指定业务使用。&lt;/p&gt;

&lt;p&gt;在分区索引计算时进行设计，保证指定的 Appkey 列表只会路由到特定的分区，而其他业务 Appkey 路由到其他分区。&lt;/p&gt;

&lt;p&gt;Q：Lion 短期内仍不能完全下掉 Redis，对 Redis 同步如何处理？&lt;/p&gt;

&lt;p&gt;A：同步任务在回放日志时，先同步 DB，之后再同步 Redis。现有监控来看，Redis 数据同步耗时 TP999 71.3ms，平均 4.2ms，对同步延迟影响有限，可以直接同步。&lt;/p&gt;

&lt;p&gt;等 Redis 完全下掉之后，在通过开关移除 Redis 同步流程。&lt;/p&gt;

&lt;p&gt;Q：目前针对北上两个数据中心，Lion 文件配置在更新时会将文件内容同时更新到北上两个 S3 集群，在同步时只同步文件 SHA Key。如果扩展到多个集群，针对文件配置如何处理？&lt;/p&gt;

&lt;p&gt;A：对于文件配置，在同步 SHA Key 后，通过单独的线程，从源数据中心 S3 集群进行文件加载，同步到本地 S3 集群。&lt;/p&gt;

&lt;p&gt;如果从源数据中心的 S3 集群加载失败，则按照顺序（BJ &amp;gt; HL &amp;gt; SH &amp;gt; HK）降级进行重新拉取。&lt;/p&gt;

&lt;h1 id=&quot;5其他补充&quot;&gt;5、其他补充&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/28131829#id-%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D&quot;&gt;https://km.sankuai.com/page/28131829#id-%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/600429548&quot;&gt;https://km.sankuai.com/page/600429548&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dbaplus.cn/news-11-1399-1.html&quot;&gt;https://dbaplus.cn/news-11-1399-1.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1407987923&quot;&gt;https://km.sankuai.com/collabpage/1407987923&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/1476581664&quot;&gt;https://km.sankuai.com/page/1476581664&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/617657890&quot;&gt;https://km.sankuai.com/page/617657890&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1532367225&quot;&gt;https://km.sankuai.com/collabpage/1532367225&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1、文档概述</summary></entry><entry><title type="html">Google Dapper</title><link href="http://localhost:4000/dapper.html" rel="alternate" type="text/html" title="Google Dapper" /><published>2023-01-17T00:00:00+08:00</published><updated>2023-01-17T00:00:00+08:00</updated><id>http://localhost:4000/dapper</id><content type="html" xml:base="http://localhost:4000/dapper.html">&lt;h1 id=&quot;1-abstract&quot;&gt;1-Abstract&lt;/h1&gt;

&lt;p&gt;现代互联网服务通常是用&lt;strong&gt;复杂的，大规模的分布式集群&lt;/strong&gt;来实现的。这些服务通常由不同的软件模块组成，而这些模块可能由不同的团队开发，使用不同的编程语言，也有可能分布在数千台机器上，横跨多个数据中心。因此，需要一些可以帮助&lt;strong&gt;理解系统行为，用于分析性能问题&lt;/strong&gt;的工具。&lt;/p&gt;

&lt;p&gt;Dapper 是 Google 生产环境下分布式跟踪系统，满足了&lt;strong&gt;低消耗&lt;/strong&gt;（low overhead），&lt;strong&gt;应用层透明&lt;/strong&gt;（application-level transparency），&lt;strong&gt;大范围部署&lt;/strong&gt;（ubiquitous deployment on a very large scale system）三个需求。&lt;/p&gt;

&lt;h1 id=&quot;2-introduction&quot;&gt;2-Introduction&lt;/h1&gt;

&lt;p&gt;构建 Dapper 的目的是为了给开发者提供更多&lt;em&gt;关于复杂分布式系统的行为信息&lt;/em&gt;。这类系统特别受关注，因为那些大规模的低端服务器，作为互联网服务的载体，是一个特殊的经济划算的平台。为了在上下文中理解分布式系统的行为，就需要监控那些横跨了不同的应用、不同服务器之间的操作。&lt;/p&gt;

&lt;p&gt;网络搜索的例子将会说明此类监控系统需要解决的一些挑战。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个前端服务可能会将一次网络查询分发给数百个查询服务器，每一个查询都有自己的 Index。查询请求也可能被发送到多个子系统中，这些子系统也许用来处理广告，拼写检查，或者查询图片，视频，新闻等特殊结果。对这些服务的返回结果选择性地组合到结果页面；这种搜索模型被称为&lt;strong&gt;全局搜索&lt;/strong&gt;（universal search）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总的来说，一次全局搜索查询可能需要数千台机器，多个不同的服务参与处理。同时，用户对搜索延迟是比较敏感的，任何子系统的低性能都可能会导致延迟增大。&lt;/p&gt;

&lt;p&gt;只看整体的延迟，工程师可能会知道全局搜索流程存在问题，但是可能&lt;em&gt;无法判断哪个服务存在问题，或者为什么性能较差&lt;/em&gt;。原因可能有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无法准确知道此次全局搜索涉及哪些服务&lt;/li&gt;
  &lt;li&gt;工程师对涉及的服务并不总是很了解&lt;/li&gt;
  &lt;li&gt;涉及的服务或者机器可能同时被其他客户端访问，所以性能问题可能是由于其他应用的影响&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述描述的案例给出了 Dapper 的两个基本要求：&lt;strong&gt;1. 无处不在的部署；2. 持续的监控&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无处不在的特性是很重要的，因为如果某个系统的很小一部分没有被监控到，那么追踪系统的可用性就会被严重影响&lt;/li&gt;
  &lt;li&gt;另外，监控需要一直开启，因为经常会遇到很难或不可能重现异常或值得注意的系统行为&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些要求产生了三个具体的设计目标：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;低消耗&lt;/strong&gt;（low overhead）：追踪系统应该对正在运行的服务产生可以忽略不计的性能影响。对于某些高度优化后的服务来说，即使很小的监控负载也能被察觉到，有可能会迫使业务团队将监控系统关闭。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;应用层透明&lt;/strong&gt;（application-level transparency）：开发人员不需要感知到追踪系统的存在；一个依赖应用层开发人员积极合作才能有序运行的追踪系统会变得很脆弱（不可靠），可能会由于机器的问题或者代码的疏忽导致整个系统中断，从而违反普遍存在的要求。在像我们这样的快节奏开发环境中，这一点尤其重要。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;（scalability）：该系统必须能够处理 Google 接下来几年的服务和集群的规模。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个额外的设计目标是，&lt;strong&gt;对于用于分析的数据，在其生成之后需要尽可能快地可以得到&lt;/strong&gt;，理想的时间是一分钟内。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;尽管基于数小时数据的追踪分析系统也是有一定的价值，但是最新数据的可用性能够使得对产生的异常有更快的反应。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;真正的应用级透明设计目标也许是最大的挑战：通过把&lt;em&gt;核心跟踪代码做的很轻巧，然后把它植入到那些无所不在的公共组件中&lt;/em&gt;，比如线程调用、控制流以及 RPC 库来实现该目标。通过使用&lt;strong&gt;&lt;em&gt;自适应采样&lt;/em&gt;&lt;/strong&gt;来使系统更具可扩展性，同时降低性能开销。结果展示的相关系统也包含一些用来收集跟踪数据的代码，用来图形化的工具，以及用来分析大规模跟踪数据的库和 API。&lt;/p&gt;

&lt;h1 id=&quot;3-distributed-tracing-in-dapper&quot;&gt;3-Distributed Tracing in Dapper&lt;/h1&gt;

&lt;p&gt;分布式服务的追踪系统需要记录一次特定请求后系统中所有完成的工作信息。&lt;/p&gt;

&lt;p&gt;下图给出了一个示例，一个与五台服务器相关的服务，包括一个前端（A），两个中间层（B，C），两个后端（D，E）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个用户请求到达前端时，发送两个 RPC 请求到 B，C。B 可以立即响应，但是 C 需要与后端的 D，E 交互之后再响应 A，最后由 A 来相应最初的请求。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对这样的请求，一个简单实用的分布式追踪系统的实现，就是为服务器上&lt;em&gt;每一次发送和接收动作&lt;/em&gt;收集&lt;strong&gt;信息标识符&lt;/strong&gt;（message identifier）和&lt;strong&gt;事件时间戳&lt;/strong&gt;（timestamped event）。&lt;/p&gt;

&lt;p&gt;为了&lt;em&gt;将所有记录条目与特定的请求发起者关联起来并记录所有信息&lt;/em&gt;，有两种解决方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;黑盒&lt;/strong&gt;（black-box）模型
    &lt;ul&gt;
      &lt;li&gt;假设除了上述消息记录外没有其他额外信息，使用统计回归技术推断两者之间的关系&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/strong&gt;：由于依赖统计推断，为了获得更高的准确性，就需要更多的数据&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;优点&lt;/em&gt;&lt;/strong&gt;：比基于标注的模型更加轻便&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于标注&lt;/strong&gt;（annotation-based）的模型
    &lt;ul&gt;
      &lt;li&gt;依赖应用或者中间件明确标记一个全局 ID，从而将每条消息记录与原始请求连接起来&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/strong&gt;：需要代码植入&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在 Google 的开发环境中，所有的应用程序都是用同一种线程模型，控制流与 RPC 系统，因此可以&lt;strong&gt;&lt;em&gt;把代码植入限制在一个很小的通用组件库中，实现一套对开发人员有效透明的监控系统&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我们倾向于将 Dapper 追踪系统看作类似嵌套在 RPC 调用的树形结构。 然而，我们的核心数据模型并不局限于特定的 RPC 框架，还需要追踪其他活动，如 Gmail 中的 SMTP 会话、来自外部的 HTTP 请求以及 SQL 查询。 &lt;strong&gt;形式上，我们使用 Trees, Spans &amp;amp; Annotations 对 Dapper 追踪系统进行建模&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-1-trace-trees-and-spans&quot;&gt;3-1 Trace trees and spans&lt;/h2&gt;

&lt;p&gt;在 Dapper 追踪树中，树节点是 Span 的基本工作单元。&lt;strong&gt;节点之间的连线表示一个 Span 与其父 Span 之间的因果关系&lt;/strong&gt;。不过，Span 在更大的树形结构中是相对独立的，&lt;strong&gt;一个 Span 就是简单的时间戳日志，记录了 Span 的开始时间与结束时间&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;下图说明了多个 Span 如何组成更大的追踪树。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dapper 记录了每个 Span 的 &lt;em&gt;Name，ID，Parent ID&lt;/em&gt;，以便在单个分布式追踪链路中重建各个 Span 的因果关系。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;没有 Parent ID 的 Span 被称为 Root Span&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;一个追踪链路上的所有 Span 共享一个公共 Trace ID&lt;/strong&gt;（全局唯一的 64 位整数；图中并未展示）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在一个典型的 Dapper 追踪链路中，期望将每一个 RPC 调用对应一个单一的 Span，每一个额外的组件层都对应一个额外的树形结构的层级。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充，即每个 Span 看作一次 RPC 调用；每一层看作一个额外的组件&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;下图给出了典型 Dapper Trace Span 中记录事件（log event）更详细的视图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;该图描述了图 2 中两个 RPC（Helper.Call）调用中跨度较长 Span&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Span 的开始时间（start time），结束时间（end time）以及任何 RPC 调用中的计时信息（timing information）都是由 Dapper 的 RPC 组件库记录的。&lt;/p&gt;

&lt;p&gt;如果应用程序开发者想要在 Trace 中添加自定义的注释（annotation, 如图中的 “foo”）以记录业务信息，这些信息也会和其他 Span 数据一样被记录下来。&lt;/p&gt;

&lt;p&gt;值得注意的是，&lt;strong&gt;&lt;em&gt;一个 Span 可以包含来自多个主机（host）的信息&lt;/em&gt;&lt;/strong&gt;。事实上，每个 RPC Span 都包含来自客户端与服务端进程的信息，这使得链接两个主机（two-host）的 Span 成为最常见的类型。&lt;/p&gt;

&lt;p&gt;由于客户端进程与服务端进程的时间戳（timestamp）来自不同的主机，因此我们必须要注意&lt;strong&gt;时钟漂移&lt;/strong&gt;（clock skew）。在我们的分析工具中，我们利用了这样一个事实，即 &lt;em&gt;RPC 客户端总是在服务端接收请求之前发送请求&lt;/em&gt;，反过来对服务端响应流程也是一样。 这样，我们可以得出 &lt;strong&gt;RPC 服务器端 Span 时间戳的下限和上限&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-2-instrumentation-points&quot;&gt;3-2 &lt;strong&gt;Instrumentation points&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 可以通过&lt;strong&gt;几乎零侵入成本&lt;/strong&gt;来实现对分布式路径的追踪（基本完全依赖于少量组件库的改造）常见的植入点有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个线程处理一个被追踪的路径时，Dapper 会将&lt;em&gt;追踪上下文&lt;/em&gt;（context）附加到线程本地（thread local）存储。追踪上下文是一个轻量且易于复制的 Span 属性容器，这些属性包括 Span ID, Trace ID&lt;/li&gt;
  &lt;li&gt;当计算过程是延迟调用或是异步的，大多数 Google 开发者通过线程池或其他执行器，使用一个通用的控制流库来回调。Dapper 确保所有这样的回调可以存储这次跟踪的上下文，而当回调函数被触发时，这次跟踪的上下文会与适当的线程关联上。在这种方式下，Dapper 可以使用 Trace ID 和 Span ID 来辅助构建异步调用的路径&lt;/li&gt;
  &lt;li&gt;几乎所有的 Google 进程间通信都是建立在一个 RPC 调用框架上，支持 C++ 与 Java。我们已经使用该框架来定义所有 RPC Span。对于被追踪的 RPC，Span ID 与 Trace ID 会从客户端发送到服务端。像这样在 Google 内部被广泛使用的，以 RPC 通信为基础的系统，这是一个重要的植入点。我们计划在非 RPC 通信框架中找到用户群并对其进行植入&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dapper 的追踪数据是&lt;strong&gt;语言无关的&lt;/strong&gt;（language-independent），许多追踪数据同时包含了来自 C++ 与 Java 编写的进程。&lt;/p&gt;

&lt;h2 id=&quot;3-3--annotations&quot;&gt;3-3  &lt;strong&gt;Annotations&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;上述植入点足以推导出复杂分布式系统的追踪细节，使得 Dapper 核心功能可以应用于未经改造的 Google 应用。然而，&lt;strong&gt;Dapper 还允许用户添加额外的信息来丰富 Dapper 追踪数据&lt;/strong&gt;，这些被添加的信息可以用来监控更高级别的系统行为或者用于问题调试。&lt;/p&gt;

&lt;p&gt;我们允许用户通过简单的 API 定义&lt;strong&gt;带时间戳的 Annotation&lt;/strong&gt;（timestamped annotations），核心用法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Annotation 中可以包含任意内容&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;为了避免用户过度添加 Annotation 记录，&lt;em&gt;每个 Dapper Span 都有一个可配置的 Annotation 总量上限&lt;/em&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意，不管应用程序行为如何，应用层面的 Annotation 都不能代替用于表示 Span 结构的信息或者 RPC 信息&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;除了简单的文本 Annotation，Dapper 还支持 &lt;strong&gt;Key-Value 型 Annotation&lt;/strong&gt;，可以为用户提供更多的追踪能力，如维护计数器，记录二进制信息，在进程内传输任意用户定义数据以及跟踪请求。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key-Value 型 Annotation 用来在分布式追踪的上下文中&lt;strong&gt;&lt;em&gt;定义某个特定应用程序的相关类型&lt;/em&gt;&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-4-sampling&quot;&gt;3-4 &lt;strong&gt;Sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;低负载（low overhead）是 Dapper 的一个关键设计目标。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果对服务性能有重大影响，那么用户是不愿意部署使用的。&lt;/li&gt;
  &lt;li&gt;我们希望允许用户使用 Annotation API 而不用担心额外的性能开销。&lt;/li&gt;
  &lt;li&gt;我们也发现有些 Web 服务确实对植入带来的性能开销比较敏感。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，除了使 Dapper 收集的基本植入性能开销尽可能小之外，我们还通过&lt;strong&gt;仅记录所有追踪的一小部分来进一步控制性能开销&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-5-trace-collection&quot;&gt;3-5 &lt;strong&gt;Trace Collection&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 追踪记录和收集是三阶段（three-stage）处理流程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Span 数据被写入本地日志文件&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dapper 守护进程及收集组件把这些数据从所有主机中拉取出来&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;收集到的数据被写入 BigTable 仓库中&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一次 Trace 被设计成 Bigtable 中的一行，每一列相当于一个 Span。Bigtable 支持稀疏表格的布局正适合这种情况，因为每一次跟踪可以有任意多个 Span。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Trace 数据收集（即从应用中的二进制数据传输到中央仓库所花费的时间）的延迟中位数少于 15 秒。TP98 延迟往往随着时间的推移呈现双峰型；大约 75% 的时间，TP98 延迟时间小于 2 分钟，但是另外大约 25% 的时间，可以增涨到几个小时。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Dapper 还提供了一个 API 来简化访问 BigTable 仓库中的 Trace 数据。 用户通过该 API，可以构建通用和特定应用程序的分析工具。&lt;/p&gt;

&lt;h3 id=&quot;3-5-1-out-of-band-trace-collection&quot;&gt;3-5-1 &lt;strong&gt;Out-of-band trace collection&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Dapper 通过请求树实现 Trace 数据（in-band）及带外数据（out-of-band）收集。这么做是出于两个不相关的原因：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;带内数据（in-band）收集方案会影响应用程序的网络动态：Trace 数据会在 RPC 响应头中携带。在 Google 的许多大型系统中，一次 Trace 中包含数千个 Span 是很常见的。然而，RPC 响应仍可能相对比较小，经常小于 10KB。这样， Dapper 带内的 Trace 数据会让应用程序数据和倾向于使用后续分析结果的数据量相形见绌，并使后续分析的结果产生偏差。&lt;/li&gt;
  &lt;li&gt;带内数据收集方案假设所有 RPC 调用都是完美嵌套的。我们发现，在所有后端系统返回最终结果之前，有许多中间件会把结果返回给他们的调用者。&lt;em&gt;带内收集系统是无法解释这种非嵌套的分布式执行模式的&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;带外数据：传输层协议使用带外数据(out-of-band，OOB)来发送一些重要的数据,如果通信一方有重要的数据需要通知对方时,协议能够将这些数据快速地发送到对方。为了发送这些数据，协议一般不使用与普通数据相同的通道,而是使用另外的通道。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里指的 in-band 策略是把跟踪数据随着调用链进行传送，out-of-band 是通过其他的链路进行跟踪数据的收集，Dapper 的写日志然后进行日志采集的方式就属于 out-of-band 策略&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;4-managing-tracing-overhead&quot;&gt;4-&lt;strong&gt;Managing Tracing Overhead&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;追踪系统的成本被认为包含：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;由于追踪数据生成和收集开销而导致的被监视系统的性能下降&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;存储和分析跟踪数据所需的资源量&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;尽管有人会说有价值的追踪系统值得性能损耗，但是我们仍相信如果基线开销可以忽略不计，那么将会极大的促进业务使用率&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;接下来将主要介绍 &lt;strong&gt;Dapper 植入操作的开销&lt;/strong&gt;，&lt;strong&gt;Trace 数据收集的开销&lt;/strong&gt;，以及 Dapper 对业务负载的影响。同时，还会介绍 Dapper 自适应采样机制如何平衡低性能损耗的需求与对代表性 Trace 追踪的需求。&lt;/p&gt;

&lt;h2 id=&quot;4-1-trace-generation-overhead&quot;&gt;4-1 &lt;strong&gt;Trace generation overhead&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Trace 生成开销是 Dapper 性能损耗中最关键的部份，因为 Trace 数据收集及分析可以在紧急情况下被关掉。&lt;/p&gt;

&lt;p&gt;Trace 生成开销主要来源有以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Span 的创建及销毁&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;将 Span 信息记录到本地磁盘，以便后续收集&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Root Span 创建及销毁平均需要 204 ns，非 Root Span 创建及销毁需要 176 ns；差别的原因是 需要给 Root Span 分配一个全局唯一的 Trace ID&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;如果不对 Span 进行追踪采样，那么额外的 Span Annotation 成本几乎可以忽略不计，包括 Dapper 运行时线程本地查找（平均耗时 9ns）。如果对 Span 进行追踪采样，那么会用字符串文本进行注释追踪 ???。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If it is sampled, annotating the trace with a string literal&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;将 Span 数据写入本地磁盘时 Dapper 运行时库最昂贵的操作，但是这部分损耗被大大减少，因为日志写入操作相对于被追踪的应用程序时异步执行的。然而，日志写入操作会对高吞吐量应用程序性能产生明显影响，尤其是在所有请求都被追踪的情况下。&lt;/p&gt;

&lt;h2 id=&quot;4-2-trace-collection-overhead&quot;&gt;4-2 &lt;strong&gt;Trace collection overhead&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;读取本地 Trace 数据也会对被追踪的前台应用负载有影响。下表展示了压力测试情况下 Dapper 守护进程的 CPU 使用率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dapper 守护进程在数据收集期间 CPU 使用率不超过 0.3%，并且内存占用非常小。同时我们也会将 Dapper 守护进程的内核调度优先级设置的尽可能低，以防止在高负载的主机中出现 CPU 争用的情况&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Dapper 也是一个轻量级的带宽资源消费者，每个 Span 平均为 426 Byte；Dapper 数据收集流量仅占 Google 生产环境网络流量的不到 0.01%。&lt;/p&gt;

&lt;h2 id=&quot;4-3-effect-on-production-workloads&quot;&gt;4-3 &lt;strong&gt;Effect on production workloads&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;有些请求都会涉及到大量高吞吐量的线上服务，这是对有效追踪最主要的需求之一；这些请求往往会生成大量的追踪数据，同时它们对性能干扰也最敏感。在下表中，我们使用网络搜索集群作为这类服务的一个示例，当我们改变 Trace 采样率时，评估 Dapper 对平均延迟与吞吐量的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，虽然对吞吐量的影响不是很明显，但是为了避免明显的延迟增加，Trace 采样确实很有必要。在实践中我们发现，即使使用 1/1024 的采样率，对于请求量大的服务仍然能够产生足够的 Trace 数据。&lt;/p&gt;

&lt;p&gt;将 Dapper 的基线开销降低很重要，因为用户可以使用全部范围的 Annotation API，而不必担心性能损耗。使用低采样率还有一个额外的好处，Trace 数据可以在主机被回收之前在磁盘上保存更长的时间，这为数据 Trace 数据收集设施提供了更大的灵活性。&lt;/p&gt;

&lt;h2 id=&quot;4-4-adaptive-sampling&quot;&gt;4-4 &lt;strong&gt;Adaptive sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 进程开销与单位时间处理 Trace 数据量成正比。Dapper 第一版对 Google 内所有进程使用统一的采样率 (1/1024)，这个简单的方案对高吞吐量的在线服务很有效，因为绝大多数我们感兴趣的事件可能经常会出现，足以被捕获。&lt;/p&gt;

&lt;p&gt;然而，有些低吞吐量（低负载）的服务可能会在低采样率的情况下错过一些重要的事件；同时，这类服务可以容忍高采样率带来的性能损耗。对于这类系统，解决方案是覆盖默认的采样率；对于这种需要手动干预的情况是我们在 Dapper 中力求避免的。&lt;/p&gt;

&lt;p&gt;我们正在部署一种自适应采样模型，该方案不是采用统一的采样率参数，而是使用一个采样期望率来标识单位时间内的采样。这样，&lt;strong&gt;低流量的服务会自动提高采样率，而高流量的服务会自动降低采样率，从而使采样开销保持在可控的范围内&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;4-5-coping-with-aggressive-sampling&quot;&gt;4-5 &lt;strong&gt;Coping with aggressive sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;新的 Dapper 用户经常想知道低采样率是否会干扰他们的分析（在高吞吐量的服务下经常低至 0.01％）。Google 的经验让我们相信，激进的采样（aggressive sampling）并不会妨碍重要的分析：如果一个值得注意的时间在一个系统中出现一次，那么它将会出现很多次。对于流量比较小的服务（每秒处理几十个请求，而不是几万个请求），可以接受对每个请求进行监控。这就是我们决定采用自适应采样率的原因。&lt;/p&gt;

&lt;h1 id=&quot;5-experiences&quot;&gt;5-&lt;strong&gt;Experiences&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Dapper 在 Google 内部被广泛应用，一部分直接通过 Dapper 的用户界面，另一部分间接地通过对 Dapper API 的二次开发或者建立在基于 API 的应用上。在本节中，我们并不打算罗列出每一种已知的 Dapper 使用方式，而是试图覆盖 Dapper 使用方式的“基本向量”，并努力来说明什么样的应用是最成功的。&lt;/p&gt;

&lt;h2 id=&quot;5-1-using-dapper-during-development&quot;&gt;5-1 &lt;strong&gt;Using Dapper during development&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Google AdWords 系统是围绕一个关键词定位准则和相关文字广告的大型数据库搭建的。当新的关键字或广告被插入或修改时，它们必须通过服务策略术语的检查（如检查不恰当的语言）；这个过程如果使用自动复查系统来做的话会更加有效。&lt;/p&gt;

&lt;p&gt;当设计一个 Ads Review 服务时，这个团队迭代的从第一个系统原型开始使用 Dapper，并且最终用 Dapper 一直维护着他们的系统。Dapper 帮助他们从以下几个方面改进了他们的服务：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;性能（performance）&lt;/strong&gt;：开发人员针对请求延迟的目标进行跟踪，并对容易优化的地方进行定位。Dapper 也被用来确定在关键路径上不必要的串行请求（通常来源于不是开发者自己开发的子系统）并促使相关团队持续修复。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;正确性（correctness）&lt;/strong&gt;：Ads Review 服务围绕大型数据库系统搭建。系统同时具有只读副本（访问成本低）和读写主节点（访问成本高）两种方式。Dapper 用于识别一些不必要地向主节点而不是副本发出查询的情况。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;理解性（understanding）&lt;/strong&gt;：Ads Review 查询跨越了各种类型的系统，包括 BigTable，以及其他各种 C++，Java 后端服务。Dapper 数据追踪可以用来评估总查询成本，促进重新对业务的设计，从而减少系统依赖性负载。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;测试（testing）&lt;/strong&gt;：新代码发布通过 Dapper 跟踪 QA 流程，验证系统行为的正确性和性能，在这个过程中发现了许多问题，包括 Ads Review 服务代码本身和依赖库中的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-2-addressing-long-tail-latency&quot;&gt;5-2 &lt;strong&gt;Addressing long tail latency&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;由于移动部件（moving parts）的数量，代码库的大小，部署的范围，使得调试类似通用搜索这样的服务具有非常大的挑战性。接下来，我们将描述为了降低通用搜索延迟分布的长尾效应所做出的努力。&lt;/p&gt;

&lt;p&gt;Dapper 能够验证关于端到端延迟的假设，更具体来说，能够验证通用搜索请求的关键路径。当系统不仅涉及数十个子系统，而且涉及数十个开发团队时，即使最优秀，最有经验的工程师也不能准确判断导致端到端性能较差的根本原因。在这种情况下，Dapper 可以提供急需的数据，并且能够对许多重要的性能问题的出结论。&lt;/p&gt;

&lt;h2 id=&quot;5-3-inferring-service-dependencies&quot;&gt;5-3 &lt;strong&gt;Inferring service dependencies&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;在任何给定的时间内，Google 内部的一个典型的计算集群是一个汇集了成千上万个逻辑“任务”的主机，一套的处理器在执行一个通用的方法。Google 维护着许多这样的集群，事实上，我们发现在一个集群上计算着的这些任务通常依赖于其他的集群上的任务。由于任务之间的依赖是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。同时，在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及计划服务的迁移。&lt;/p&gt;

&lt;p&gt;Google 内部被称为 “Service Dependencies” 的项目是通过使用 Trace Annotation 和 Dapper API MapReduce 接口来实现自动化确定服务依赖。&lt;/p&gt;

&lt;p&gt;Dapper 核心组件与 Dapper  Trace Annotation 一起使用的情况下，“Service Dependencies” 项目能够推算出任务各自之间的依赖，以及任务和其他组件之间的依赖。&lt;/p&gt;

&lt;h2 id=&quot;5-4-layered-and-shared-storage-systems&quot;&gt;5-4 &lt;strong&gt;Layered and Shared Storage Systems&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Google 的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google 的 App Engine 就是搭建在一个可扩展的实体存储系统上的。该实体存储系统基于 BigTable 上公开某些RDBMS 功能。BigTable 同时使用Chubby 及 GFS。而且，像 BigTable 这样的系统简化了部署，并更好的利用了计算资源。&lt;/p&gt;

&lt;p&gt;在这种分层的系统，并不总是很容易确定最终用户资源的消费模式。例如，来自给定 BigTable 单元的大量 GFS 流量可能主要来自一个用户或多个用户，而在 GFS 层面，这两种不同使用模式之间的差异是模糊的。而且，如果缺乏像 Dapper 这样的工具，对此类共享服务的竞争可能会同样难以调试。&lt;/p&gt;

&lt;p&gt;Dapper 的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息，这就很容易让提供这些服务的源从多个维度给他们的用户排名（例如，入站的网络负载，出站的网络负载，或服务请求的总时间）。&lt;/p&gt;

&lt;h1 id=&quot;6-conclusions&quot;&gt;6-&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;在本文中，我们介绍 Dapper 这个 Google 生产环境下的分布式系统跟踪平台，并汇报了我们开发和使用它的相关经验。&lt;/p&gt;

&lt;p&gt;Dapper 几乎在部署在 Google 所有系统上，并可以在&lt;strong&gt;不需要应用级修改的情况下进行跟踪，而且没有明显的性能影响&lt;/strong&gt;。Dapper 对于开发人员和运维团队带来的好处，可以从我们主要的跟踪用户界面的广泛使用上看出来，另外我们还列举了一些 Dapper 使用用例来说明 Dapper 的作用，这些用例有些甚至都没有 Dapper 开发团队参与，而是被应用的开发者开发出来的。&lt;/p&gt;

&lt;p&gt;我们相信，&lt;strong&gt;Dapper 比以前基于 Annotation 的分布式跟踪达到更高的应用透明度&lt;/strong&gt;，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。&lt;/p&gt;

&lt;p&gt;最后，通过开放 Dapper 仓库给内部开发者，促使了更多基于 Dapper 的分析工具的产生。&lt;/p&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1-Abstract</summary></entry><entry><title type="html">2022 Summary</title><link href="http://localhost:4000/summary-2022.html" rel="alternate" type="text/html" title="2022 Summary" /><published>2023-01-15T00:00:00+08:00</published><updated>2023-01-15T00:00:00+08:00</updated><id>http://localhost:4000/summary_2022</id><content type="html" xml:base="http://localhost:4000/summary-2022.html">&lt;blockquote&gt;
  &lt;p&gt;来上海三年多，第一次（2023-01-15）见到那么大的雪&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;如果用一个词表达今年的状态，那就是”&lt;strong&gt;焦虑&lt;/strong&gt;“。&lt;/p&gt;

&lt;p&gt;每个时间段焦虑的原因不同，持续的时间也不一样；但是接连不断的焦虑感让自己感觉压力不小。好在所有的事情最终都有一个比较满意的结果，也算苦尽甘来。&lt;/p&gt;

&lt;p&gt;今年比较跌宕，但收获也很多，个别比较重要的事情也都按照自己的预期有所进展，整体还是比较知足的。&lt;/p&gt;

&lt;h2 id=&quot;晋升&quot;&gt;晋升&lt;/h2&gt;

&lt;p&gt;晋升带给自己的焦虑算是最大的了，毕竟直接影响自己接下来的职业规划。从晋升准备到晋升答辩，整个过程冗长繁琐，令人疲惫，中途甚至想放弃，还好最终晋升成功，而且答辩排名在所有候选人中处于前列。&lt;/p&gt;

&lt;p&gt;在美团两年多，职级体系，晋升政策一直在变化，导致自己今年才有晋升机会。&lt;/p&gt;

&lt;p&gt;按照去年的政策，今年晋升应该安排在 5，6 月份（2022 年上半年绩效评估前），那么自己上半年理论上需要投入更多的精力在准备晋升材料，答辩等；对上半年绩效结果可以不那么在意，工作方面就可以投入较少的精力；但是再一次出现了晋升政策调整：晋升时间调整到下半年（7，8，9月份）。&lt;/p&gt;

&lt;p&gt;对自己来说，之前的规划就出现偏差：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2021 年绩效整体还行，如果只看 2021 年两次绩效结果，对晋升概率还是有一定把握。&lt;/li&gt;
  &lt;li&gt;调整为 2022 年下半年晋升，那就会将 2022 H1 的绩效纳入评估范围。如果 2022 H1 的绩效一般，那么自己的竞争力会有所下降；因此，之前制定的划水策略行不通了，需要在 2022 H1 拿到一个不错的绩效才行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是，在 202204 跟 Leader 的一次 1 on 1 中规划了下接下来的工作重点，为了在 2022H1 拿到一个满意的绩效结果，自己需要承担一项重要紧急且困难的推动工作，如果该工作交付结果达成预期，那么自己的绩效也会达到自己的目标；反之只能拿到一个一般的绩效。所以，在沟通之后，自己准备放手一搏了。经过两个多月的推动，基本投入了 100% 的人力，克服各种未知困难，最终工作进展超出预期，绩效也超出了预期。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;没想到这个工作在下半年还在推动，只是方向有所调整&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;至此，绩效方面可以成为比较强有力的晋升支撑，晋升成功看起来也许是水到渠成了。不过，晋升政策再次出现调整，晋升流程，比例，答辩策略等都发生了变化，每个步骤都需要严格卡控比例。在见识到一个绩效优秀的同事提前被卡掉之后，自己对晋升结果也保持了悲观态度，开始积极寻求其他机会了。政策的多次调整，让自己对整个晋升体系感到失望，对接下来的工作也表现出比较消极的态度。在美团两年多，主 R 了多个重点工作，也都拿到了超出预期的结果与绩效，如果最终晋升失败，我大概率不会反思自己能力不够，毕竟我做到了自己能做的最优解。&lt;/p&gt;

&lt;p&gt;持续两个多月的晋升材料准备，答辩，结果等待，最终晋升成功了，并且排名 Top。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实答辩刚结束的时候，Leader 基本可以判断出我晋升没问题，只是一直没说；反而从其他几个 Leader 中得到令人满意的反馈&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;晋升结果公布之后，就是晋升调薪了。不出意外，在互联网整体不景气的情况下，调薪比例不是特别高，不过自己也拿到了应该是最高档的比例，还算满意吧。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;晋升通过只给了现金调整，并没有给股票，反而在晋升前的 4，5 月份给了聊胜于无的股票，让我对美团的激励政策的理解又不清楚了&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;回顾来看，焦虑多半是由公司晋升政策调整 + 不稳重的心态引发的，自己执迷于晋升最初是想给两年多的努力工作一个交代；但是，这个所谓的交代重要吗，如果自己晋升失败，大不了明年再来或者直接换一家公司，薪资涨幅肯定要比晋升带来的多。在与 Leader  1 on 1 中也提到了自己应该更加稳重，对于这一点还是比较认同。不管是工作还是生活，自己很容易情绪化，不利于后续的发展提升，在接下来的工作中需要努力改变。&lt;/p&gt;

&lt;h2 id=&quot;工作&quot;&gt;工作&lt;/h2&gt;

&lt;p&gt;为了在 2022H1 拿到满意的绩效，自己承担了一个重要任务，没想到竟然占据了我一年 50% 以上的人力投入，并且还将要在 2023 年继续投入。&lt;/p&gt;

&lt;p&gt;这个工作简单来说就是因为各种原因需要下线一个老系统，虽然目标比较明确，但是其中的各种问题没有一个成熟的经验，只能不断摸索调整。&lt;/p&gt;

&lt;p&gt;在上半年的时候，主要以 A 方向去推动，需要与公司内部大部分业务进行沟通。为了降低业务风险及成本，需要做很多前期准备工作，人力投入非常大。好在中后期与一些平台方建立了合作关系，多方一起去推动，最终拿到一个满意的结果。&lt;/p&gt;

&lt;p&gt;在下半年的时候，意识到 A 方向对最终目标达成影响较小，经过多次讨论，最终调整为 B 方向。此时涉及的业务基本是公司所有业务了，其中的业务风险更大。为了降低风险，制定了多阶段策略，先解决低风险业务，再推动高风险业务。虽然最终结果与既定目标有所偏差，但是整体还是有了长足的进步，拿到一定的成果。&lt;/p&gt;

&lt;p&gt;这个老系统下线工作之前持续了1，2 年，但是进展缓慢，并且后续如何下线一直没有明确的方案。自己接手之后，也是抱着死马当活马医的态度，做得了就做，做不了就算了。由于下线风险高，历史包袱重，涉及业务面广，业务情况复杂等各种原因，自己在推动前做了很多准备工作，但是对真正的实施方案并没有把握，只能走一步看一步，随时调整策略。在那段时间里，自己也是睡眠不足，总是想着如何尽快拿到结果。好在最终进展得到多方面的认可，努力付出也得到了回报。&lt;/p&gt;

&lt;p&gt;回想一下，这个工作很难，让自己身心疲惫，但是也确实因此收获颇丰：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;中长期任务规划能力提升&lt;/li&gt;
  &lt;li&gt;业务沟通能力提升&lt;/li&gt;
  &lt;li&gt;满意的绩效结果&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;生活&quot;&gt;生活&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;疫情&lt;/p&gt;

    &lt;p&gt;2022 年初，上海因为疫情封控了 3 个多月，自己一个人在出租屋里封闭了 3 个多月。回想这段时间，真是煎熬，每天吃着相同且味道寡淡的饭菜，还要担心明天能不能吃饱，详细规划每天的食物量，每天早晨准时抢菜，切身体会到粮食的重要性。一粒米真的能饿死一个国家。&lt;/p&gt;

    &lt;p&gt;解封之后，由于各地政策限制，无法自由出入，一些事情并没有按照预期在发展。&lt;/p&gt;

    &lt;p&gt;2022 年尾，全国疫情管控放开，不出意外地感染了，幸运的是症状不是很严重，大概三天就恢复了。&lt;/p&gt;

    &lt;p&gt;因为疫情，2022 年变得很魔幻。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女朋友&lt;/p&gt;

    &lt;p&gt;女朋友今年毕业，一直在准备考编。期间有希望，有挫败，她这一年比我更焦虑，压力也更大。好在最终考上了相对比较满意的单位，也要开始下一段人生旅程。&lt;/p&gt;

    &lt;p&gt;今年我们都再次见了双方父母，感情也更进了一步，一切都在稳步前进。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;学习&lt;/p&gt;

    &lt;p&gt;今年专业知识学习主要集中在上半年，主要集中在分布式系统及 Linux 内核，看的论文比预期少。下半年更专注工作与生活，基本没有专业知识的学习。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;上半年翻译了一篇课程，并在公司内分享了&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;锻炼&lt;/p&gt;

    &lt;p&gt;在 2022 年尾感染新冠之前，一直保持锻炼，身材也比较稳定。阳康之后，再也没有重新锻炼了，预计等过年回来重新开始。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;投资&lt;/p&gt;

    &lt;p&gt;以基金为主，暂时少量投入，长期持有，整体不亏不盈。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="annual-summary" /><summary type="html">来上海三年多，第一次（2023-01-15）见到那么大的雪</summary></entry></feed>