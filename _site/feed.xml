<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-05-07T23:23:07+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Find a needle in haystack</title><subtitle></subtitle><author><name>kkzhang</name></author><entry><title type="html">Kafka: Configure Kafka</title><link href="http://localhost:4000/kafka-in-action-2.html" rel="alternate" type="text/html" title="Kafka: Configure Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-2</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-2.html">&lt;h1 id=&quot;1-broker-配置&quot;&gt;1. Broker 配置&lt;/h1&gt;

&lt;h2 id=&quot;11-numpartitions&quot;&gt;1.1 &lt;strong&gt;num.partitions&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;指定了主题分区数。Kafka 集群通过分区对主题进行横向扩展，当有新的 Broker 加入集群时，可以通过分区实现负载均衡。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;不过，并不强制要求分区数大于 Broker 数。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;在进行分区数量选择时，需要考虑以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;主题的吞吐量&lt;/li&gt;
  &lt;li&gt;消费者从单个分区读取数据的吞吐量&lt;/li&gt;
  &lt;li&gt;生产者往单个分区写入数据的吞吐量&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;每个 Broker 包含的分区个数，可用的磁盘空间与网络带宽&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;单个 Broker 所承载的分区个数是有限的：分区越多，占用内存越多，分区 Leader 选举的时间越长&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;如果消息是按照 Key 写入各个分区的，那么新增分区会比较麻烦&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;11-logretentionms&quot;&gt;1.1 log.retention.ms&lt;/h2&gt;

&lt;p&gt;数据被保留的时间；对应的有 log.retention.minutes, log.retention.hours.&lt;/p&gt;

&lt;h2 id=&quot;13-logretentionbytes&quot;&gt;1.3 log.retention.bytes&lt;/h2&gt;

&lt;p&gt;数据被保留的大小；该参数作用在每个分区上&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果同时指定了数据保留的时间与大小参数，那么只要任意一个参数满足，数据就会被删除&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;14-logsegmentbytes&quot;&gt;1.4 log.segment.bytes&lt;/h2&gt;

&lt;p&gt;当消息到达 Broker 时，会被追加到分区的当前日志片段（segment）上。当日志片段大小达到了 log.segment.bytes 时，当前日志片段就会被关闭，新的日志片段会被打开。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;被关闭的日志片段，就开始等待过期&lt;/strong&gt;。如果日志片段一直没被关闭，就不会过期。上面的 log.retention.ms/bytes 日志过期参数需要在日志片段关闭之后才有效。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;该参数值越小，会导致越频繁地开启与关闭文件，降低磁盘效率&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;15-logsegmentms&quot;&gt;1.5 log.segment.ms&lt;/h2&gt;

&lt;p&gt;日志片段被关闭的时间。&lt;/p&gt;

&lt;p&gt;如果同时指定了 log.segment.ms/bytes 两个参数，那么日志片段会在大小/时间达到上限时被关闭。&lt;/p&gt;

&lt;h2 id=&quot;16-messagemaxbytes&quot;&gt;1.6 message.max.bytes&lt;/h2&gt;

&lt;p&gt;用来限制单个消息的大小。如果生产者发送的消息大于该值，那么消息不会被接收，并且 Broker 会返回错误消息。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果该值越大，那么请求处理耗时就越大。同时，会增加磁盘写入块的大小，影响 IO 吞吐量。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;2-硬件&quot;&gt;2. 硬件&lt;/h1&gt;

&lt;p&gt;Kafka 本身对硬件没什么要求，但是如果对系统性能比较关注，可以注意以下几点：&lt;/p&gt;

&lt;h2 id=&quot;21-磁盘吞吐量&quot;&gt;2.1 磁盘吞吐量&lt;/h2&gt;

&lt;p&gt;生产者客户端的性能受服务端磁盘吞吐量的影响。生产者在发送完消息之后，一般会等待服务端将消息保存在磁盘上，磁盘写入越快，客户端生成消息的延迟就越低。&lt;/p&gt;

&lt;h2 id=&quot;22-磁盘容量&quot;&gt;2.2 磁盘容量&lt;/h2&gt;

&lt;p&gt;磁盘容量大小取决于需要保存的消息数量，同时也受集群复制策略的影响。&lt;/p&gt;

&lt;h2 id=&quot;23-内存&quot;&gt;2.3 内存&lt;/h2&gt;

&lt;p&gt;除了磁盘性能，服务端可用内存容量也是影响客户端性能的主要因素。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;磁盘影响生产者，而内存影响消费者&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;一般情况下，消费者从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。此时，&lt;strong&gt;消费者读取的消息会直接放在系统的页面缓存里&lt;/strong&gt;，比磁盘上重新读取性能更高。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;运行 Kafka 的 JVM 不需要太大的缓存，剩余的系统内存可以直接用作页面缓存，或者缓存正在使用中的日志片段&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;24-网络&quot;&gt;2.4 网络&lt;/h2&gt;

&lt;p&gt;网络吞吐量决定了 Kafka 能够处理的最大数据流量。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;网络吞吐量与磁盘存储是制约 Kafka 扩展规模的主要因素&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;25-cpu&quot;&gt;2.5 CPU&lt;/h2&gt;

&lt;p&gt;Kafka 对计算处理能力要求较低，主要用在消息批量压缩与解压过程中。&lt;/p&gt;

&lt;h1 id=&quot;3-kafka-集群&quot;&gt;3. Kafka 集群&lt;/h1&gt;

&lt;p&gt;使用 Kafka 集群可以为客户端提供高性能与高可用性：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;可以跨服务器进行负载均衡&lt;/li&gt;
  &lt;li&gt;使用复制功能避免单点故障造成的数据丢失&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_2/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;31-broker-数量&quot;&gt;3.1 Broker 数量&lt;/h2&gt;

&lt;p&gt;一个 Kafka 集群需要多少个 Broker 数量取决于下面几个因素：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;需要多少磁盘空间保存数据&lt;/p&gt;

    &lt;p&gt;单个 Broker 有多少可用空间，副本的复制系数多少&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;集群处理请求的能力&lt;/p&gt;

    &lt;p&gt;需要考虑网络吞吐量，磁盘吞吐量，系统内存容量因素&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;32-操作系统调优&quot;&gt;3.2 操作系统调优&lt;/h2&gt;

&lt;p&gt;默认操作系统配置已经能够满足大部分应用程序的运行需求，不过可以优化一些参数进一步提升性能，这些参数主要与虚拟内存，网络子系统，存储日志的磁盘挂载点有关。&lt;/p&gt;

&lt;h3 id=&quot;321-虚拟内存&quot;&gt;3.2.1 虚拟内存&lt;/h3&gt;

&lt;p&gt;为了提高系统吞吐量，应该尽量避免内存交换。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;内存页与磁盘之间的交换对 Kafka 各方面性能都有影响。Kafka 大量使用系统页面缓存，如果虚拟内存被交换到磁盘，说明没有多余的内存分配给页面缓存了。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;一种优化方式是，不设置任何交换分区，避免内存交换。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;奸笑 vm.swappiness 参数&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另一种优化方式是，调整内核对脏页的处理方式。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;减小 vm.dirty_background_ratio 参数，增大 vm.dirty_ratio 参数&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;322-磁盘&quot;&gt;3.2.2 磁盘&lt;/h3&gt;

&lt;p&gt;除了合适的磁盘硬件设备，文件系统是影响性能的另一个重要因素。&lt;/p&gt;

&lt;p&gt;XFS 批量磁盘写入具有更高的效率，提高整体的 IO 吞吐量，为 Kafka 提供更好的性能。&lt;/p&gt;

&lt;h3 id=&quot;323-网络&quot;&gt;3.2.3 网络&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;调整分配给 Socket 读写缓冲区的内存大小&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;参数 net.core.wmem_default, net.core.rmem_default.&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;调整 TCP Socket 读写缓冲区&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;参数 net.ipv4.tcp_wmem, net.ipv4.tcp_rmem&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. Broker 配置</summary></entry><entry><title type="html">Kafka: Meet Kafka</title><link href="http://localhost:4000/kafka-in-action-1.html" rel="alternate" type="text/html" title="Kafka: Meet Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-1</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-1.html">&lt;h1 id=&quot;11-发布订阅消息系统&quot;&gt;1.1 发布订阅消息系统&lt;/h1&gt;

&lt;p&gt;发布订阅消息系统的一个特点是，消息的发送者不会直接把消息发送给接收者。&lt;strong&gt;发送者以某种方式对消息进行分类，接收者订阅它们，以便接收特定类型的消息&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;发布订阅系统一般有一个 Broker：发布消息的中心点。&lt;/p&gt;

&lt;h1 id=&quot;12-kafka-登场&quot;&gt;1.2 Kafka 登场&lt;/h1&gt;

&lt;p&gt;Kafka 一般被称为“分布式提交日志”或者“分布式流平台”。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在数据库中，提交日志用来提供事务的持久化记录，可以通过回放这些日志还重建系统状态。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。同时，Kafka 的数据分布在整个系统中，具有数据故障保护，性能伸缩的能力。&lt;/p&gt;

&lt;h2 id=&quot;121-消息与批次&quot;&gt;1.2.1 消息与批次&lt;/h2&gt;

&lt;p&gt;Kafka 的数据单元被称为“消息”。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;消息由字节数据组成，因此消息内容没有特殊的含义或格式。&lt;/li&gt;
  &lt;li&gt;消息有一个可选元数据，被称为“键”。键也是一个字节数组，没有特殊含义。&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;当消息以一种可控的方式写入不同的分区时，会使用键，保证相同键的消息被写到相同的分区上。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;“批次”是一组消息，这些消息属于同一个主题与分区。将消息按照批次写入到 Kafka，可以减少网络开销，有效提高效率。不过，批次大小需要在消息延迟与吞吐量之间进行权衡：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;批次越大，单位时间内处理的消息就越多；相应的，单个消息的延迟就越大&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;批次数据会被压缩，以提升传输与存储能力，但需要更多的计算处理&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;122-模式&quot;&gt;1.2.2 模式&lt;/h2&gt;

&lt;p&gt;对 Kafka 的来说，消息只是一些字节数组，难以理解，因此希望可以结构化定义消息内容。&lt;/p&gt;

&lt;p&gt;消息模式（Schema）有多种选项，如 JSON，XML；不过它们缺乏强类型处理能力，版本之间的兼容性也不好。&lt;/p&gt;

&lt;p&gt;最常用的 Kafka 消息模式是 Apache Avro：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;紧凑的序列化格式&lt;/li&gt;
  &lt;li&gt;模式与消息体分开；当模式发生变化时，不需要重新生成代码&lt;/li&gt;
  &lt;li&gt;支持强类型与模式进化，向前向后均兼容&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;数据格式的一致性，消除了消息读写操作之间的耦合性&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;123-主题与分区&quot;&gt;1.2.3 主题与分区&lt;/h2&gt;

&lt;p&gt;消息通过主题（Topic）进行分类，主题可以被分为若干个分区（Partition）。消息以追加（Append）的方式写入分区，然后以先入先出的顺序读取。&lt;/p&gt;

&lt;p&gt;一个主题通常有多个分区，因此&lt;strong&gt;无法保证在主题范围内消息的有序性，但是可以保证消息在单个分区内有序&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;如下所示，消息被追加到每个分区的尾部：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;很多时候，人们会把一个主题的数据看作&lt;strong&gt;流&lt;/strong&gt;，而不管主题中包含多少个分区。流可以看作一组从生产者移动到消费者的数据。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;124-生产者与消费者&quot;&gt;1.2.4 生产者与消费者&lt;/h2&gt;

&lt;p&gt;Kafka 的生产者分为两种类型：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;生产者&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;生产者创建消息：一般情况下，消息会被发送到特定的主题，默认会把消息均衡地分布到主题的各个分区上（具体被分配到哪个分区并不重要）。&lt;/p&gt;

    &lt;p&gt;不过，也可以为消息指定分区，通过消息键与分区器将其映射到指定的分区。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;消费者&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;消费者读取消息：可以订阅一个或者多个主题，并按照消息生成的顺序读取它们。&lt;/p&gt;

    &lt;p&gt;消费者通过检查消息偏移量（Offset）来判断消息是否已经被读取过。&lt;strong&gt;消费者把每个分区最后读取的消息偏移量保存在 Zookeeper 或者 Kafka 上&lt;/strong&gt;，以保证在消费者重启之后可以从之前的位置继续消费。&lt;/p&gt;

    &lt;p&gt;偏移量是消息的元数据，是一个不断递增的整数值。在 Kafka 创建消息时，会设置其偏移量。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;在给定的分区内，消息的偏移量是唯一的&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;消费者是消费者群组的一部分；消费者群组保证每个分区只会被一个消费者读取，消费者与分区之间的映射关系被称为消费者对分区的所有权关系。通过这种方式，消费者可以消费包含大量消息的主题，并且当一个消费者失效时，其他消费者可以接管失效消费者的工作。&lt;/p&gt;

&lt;p&gt;如下所示，消费者群组与分区的关系：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;125-broker-与集群&quot;&gt;1.2.5 Broker 与集群&lt;/h2&gt;

&lt;p&gt;一个独立的 Kafka 服务器被称为 Broker。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Broker 接收生产者的消息，为消息设置偏移量，并将消息保存到磁盘&lt;/li&gt;
  &lt;li&gt;Broker 对消费者读取分区的请求，返回已经提交到磁盘上的消息&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;单个 Broker 可以处理上千个分区以及每秒百万级的消息量&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Broker 是集群的组成部分，每个集群都有一个 Broker 同时充当&lt;strong&gt;集群控制器&lt;/strong&gt;的角色。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;集群控制器自动从集群的活跃成员中选出来&lt;/li&gt;
  &lt;li&gt;集群控制器负责集群管理工作，如将分区分配给 Broker，监控 Broker 等&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在集群中，一个分区从属一个 Broker，该 Broker 被称为该分区的 Leader。同时，可以对分区进行复制，分区副本可以被分配给多个 Broker。&lt;strong&gt;复制机制为分区提供了消息冗余&lt;/strong&gt;，如果 Leader 失效，其他 Broker 可以接管领导权；相关的生产者及消费者都需要迁移到新的 Leader。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Broker 中的消息可以通过一些参数设置保留时间，过期的消息会被删除。&lt;/p&gt;

&lt;h2 id=&quot;126-多集群&quot;&gt;1.2.6 多集群&lt;/h2&gt;

&lt;p&gt;有以下需求时，可以使用多集群：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;数据类型分离&lt;/li&gt;
  &lt;li&gt;安全需求隔离&lt;/li&gt;
  &lt;li&gt;多数据中心（容灾恢复）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在多数据中心内部署多个集群时，可以通过 MirrorMaker 工具实现集群间数据复制功能。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_1/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;13-why-kafka&quot;&gt;1.3 Why Kafka?&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;多个生产者&lt;/p&gt;

    &lt;p&gt;支持多个生产者往单个主题或者多个主题发送消息，适合从多个系统中收集数据&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;多个消费者&lt;/p&gt;

    &lt;p&gt;支持多个消费者从一个消息流上读取数据，且消费者之间互不影响。同时，消费者群组内的消费者共享消息流，并且保证对于整个群组，每个消息只被处理一次。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;基于磁盘的数据存储&lt;/p&gt;

    &lt;p&gt;消息被保存到磁盘上，并且每个主题可以设置单独的保存规则，以满足不同消费者的需求。&lt;/p&gt;

    &lt;p&gt;数据持久化可以保证消息不丢失，允许消费者非实时地读取消息。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;伸缩性&lt;/p&gt;

    &lt;p&gt;为了支持大量数据处理，Broker 集群支持灵活扩展。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;高性能&lt;/p&gt;

    &lt;p&gt;通过横向扩展生产者，消费者及 Broker，使得 Kafka 在处理大量消息时可以保证亚秒级延迟。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1.1 发布订阅消息系统</summary></entry><entry><title type="html">Kafka: Writing Messages to Kafka</title><link href="http://localhost:4000/kafka-in-action-3.html" rel="alternate" type="text/html" title="Kafka: Writing Messages to Kafka" /><published>2023-05-07T00:00:00+08:00</published><updated>2023-05-07T00:00:00+08:00</updated><id>http://localhost:4000/kafka-in-action-3</id><content type="html" xml:base="http://localhost:4000/kafka-in-action-3.html">&lt;h1 id=&quot;1-生产者概述&quot;&gt;1. 生产者概述&lt;/h1&gt;

&lt;p&gt;需要往 Kafka 写消息的场景有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;记录用户活动&lt;/li&gt;
  &lt;li&gt;记录度量指标，监控数据&lt;/li&gt;
  &lt;li&gt;保存日志消息&lt;/li&gt;
  &lt;li&gt;与其他应用程序进行异步通信&lt;/li&gt;
  &lt;li&gt;缓冲即将写入到数据库中的数据&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对于这些不同的使用场景，我们需要分析：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;是否每个消息都很重要&lt;/li&gt;
  &lt;li&gt;是否允许丢失一小部分消息&lt;/li&gt;
  &lt;li&gt;是否可以接受偶尔的消息重复&lt;/li&gt;
  &lt;li&gt;对消息的延迟及吞吐量是否严格要求&lt;/li&gt;
  &lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不同的使用场景对生产者 API 的使用和配置都会有直接影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/kafka/chapter_2/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上图展示了向 Kafka 发送消息的主要步骤：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;消息先被放入缓冲区，之后由单独的线程发送到 Broker&lt;/strong&gt;&lt;/p&gt;

&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;创建 ProducerRecord 对象，包含目标主题，发送的内容，还可以指定 Key，分区&lt;/li&gt;
  &lt;li&gt;数据被序列化二进制字节数组&lt;/li&gt;
  &lt;li&gt;数据被传送给分区器
    &lt;ol&gt;
      &lt;li&gt;如果提前指定了分区，那么分区器将不会做任何事情&lt;/li&gt;
      &lt;li&gt;如果没有指定分区，那么分区器就会根据 ProducerRecord 对象的 Key 选择一个分区&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;生产者已经明确应该往哪个主题与分区发送消息了，该记录会被添加到一个记录批次里，该批次里的所有消息都会被发送到同一个主题与分区上
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;存在一个独立的线程负责把这些记录批次发送到相应的 Broker 上&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;服务器收到消息后会返回一个响应
    &lt;ol&gt;
      &lt;li&gt;如果成功写入 Kafka，则返回一个 RecordMetaData 对象，包含了主题和分区信息，以及记录在分区中的偏移量（Offset）&lt;/li&gt;
      &lt;li&gt;如果写入失败，则返回一个错误消息&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;生产者在收到错误之后就会尝试重新发送消息，几次重试之后如果还是失败，则返回错误信息&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2-创建-kafka-生产者&quot;&gt;2. 创建 Kafka 生产者&lt;/h1&gt;

&lt;p&gt;创建 Kafka 生产者需要设置 3 个必要属性：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;bootstrap.servers&lt;/p&gt;

    &lt;p&gt;指定 Broker 的地址列表，格式为 host:port。（该列表不需要包含所有 Broker 地址，生产者会从给定的 Broker 中找到其他 Broker 信息）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;key.serializer&lt;/p&gt;

    &lt;p&gt;Broker 接收的消息的 key &amp;amp; value 都是字节数组。因此，生产者需要把 key 序列化成字节数组。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;key.serializer 需要实现 org.apache.kafka.common.serialization.Serializer 接口&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;value.serializer&lt;/p&gt;

    &lt;p&gt;同 key.serializer&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;创建生产者代码 Demo:&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Properties&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bootstrap.servers&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;broker1:9092,broker2:9092&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;key.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;value.serializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;org.apache.kafka.common.serialization.StringSerializer&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kafkaProps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;3-发送消息到-kafka-生产者&quot;&gt;3. 发送消息到 Kafka 生产者&lt;/h1&gt;

&lt;p&gt;生产者创建完成后，可以向 Broker 发送消息。有 3 种发送消息的方式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;发送并忘记&lt;/strong&gt;（&lt;em&gt;Fire-and-forget&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;将消息发送给 Broker 服务器，但是并不关心是否正常到达。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;多数情况下，消息会成功被接收（失败后会自动重试），但是有时候会丢失一些消息。&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;同步发送&lt;/strong&gt;（&lt;em&gt;Synchronous send&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法返回一个 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Future&lt;/code&gt; 对象，调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Future.get()&lt;/code&gt; 方法等待，可以判断消失是否成功发送。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;异步发送&lt;/strong&gt;（&lt;em&gt;Asynchronous send&lt;/em&gt;）&lt;/p&gt;

    &lt;p&gt;调用 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法并指定回调函数，当接收到 Broker 的响应之后，回调函数被触发。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;简单的发送消息代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Precision Products&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&quot;France&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// send() 方法会返回一个包含 RecordMetaData 的 Future 对象&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 但是我们直接忽略返回值，所以无法感知到消息是否发送成功&lt;/span&gt;
	  &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 我们可以忽略发送消息时可能发生的异常，或者在服务端发生的异常&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 但是发送消息之前，生产者可能发生其他异常，如序列化异常，缓冲区已满，发送线程被中断等&lt;/span&gt;
	  &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;31-同步发送消息sending-a-message-synchronously&quot;&gt;3.1 同步发送消息（&lt;strong&gt;Sending a Message Synchronously&lt;/strong&gt;）&lt;/h2&gt;

&lt;p&gt;同步发送消息代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Precision Products&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;France&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;try&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 如果服务器返回错误，get() 方法会抛出异常&lt;/span&gt;
		&lt;span class=&quot;c1&quot;&gt;// 如果没有发生错误，get() 方法会返回 RecordMetaData 对象，可以用来获取消息的偏移量&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;生产者发送消息一般会发生两类异常：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;可重试异常&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;可以通过重发消息解决；常见的错误有：连接异常，无主（no leader）异常等。&lt;/p&gt;

    &lt;p&gt;KafkaProducer 可以设置成自动重试，但是如果多次重试之后仍无法解决问题，会收到一个重试异常。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;不可重试异常&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;对于这类异常，生产者不会进行任何重试，直接抛出异常；常见的错误有：消息太大（message size too large）异常。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;32-异步发送消息sending-a-message-asynchronously&quot;&gt;3.2 异步发送消息（&lt;strong&gt;Sending a Message Asynchronously&lt;/strong&gt;）&lt;/h2&gt;

&lt;p&gt;如果每个消息发送之后都需要同步等待响应，那么应用程序的吞吐量将会大大下降。虽然 Kafka 会把目标主题，分区信息，消息偏移量发送回来，但是对于很多发送端的应用程序来说并不是必需的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;多数情况下，我们不需要等待 Broker 的响应。不过，当消息发送失败时，我们可能需要对异常进行处理分析&lt;/strong&gt;，如抛出异常，记录错误日志等。&lt;/p&gt;

&lt;p&gt;为了在消息发送异常时进行处理，生产者提供了回调支持。代码如下：&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// 需要实现 org.apache.kafka. clients.producer.Callback 接口&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DemoProducerCallback&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Callback&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@Override&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;onCompletion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RecordMetadata&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recordMetadata&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Exception&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
     &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;printStackTrace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;record&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ProducerRecord&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;CustomerCountry&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Biomedical Materials&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;USA&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;producer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;send&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;record&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DemoProducerCallback&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;4-配置生产者&quot;&gt;4. 配置生产者&lt;/h1&gt;

&lt;p&gt;除了之前提到的 3 个必要参数，生产者还有其他可配置的参数；其中一些参数在内存使用，性能，可靠性方面对生产者影响较大。&lt;/p&gt;

&lt;h2 id=&quot;41-acks&quot;&gt;4.1 acks&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;该参数指定了必须要多少个分区副本收到消息，生产者才会认为消息写入是成功的&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;acks 参数配置影响消息丢失的可能性&lt;/p&gt;

&lt;/blockquote&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 0&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;发送消息之后，生产者不会等待任何服务器的响应。&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;如果发送过程中出现了问题，导致服务器没有收到消息，生产者无从得知，消息也会丢失&lt;/li&gt;
      &lt;li&gt;由于不需要等待服务器响应，发送消息的吞吐量会很大&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = 1&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;只要 Leader 副本收到消息，生产者就会收到来自 Broker 的成功响应。&lt;/strong&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;如果消息无法成功写入 Leader 副本（如 Leader 崩溃），那么生产者就会收到一个错误响应；为避免消息丢失，生产者会重试发送。&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;如果 Leader 收到消息后崩溃，并且该消息没有来得及同步到其他副本中，那么消息仍会丢失&lt;/p&gt;

        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;此时的吞吐量取决于是采用同步发送还是异步发送&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;acks = all&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;只有当所有同步副本（in-sync replicas）都收到消息时，生产者才会收到来自 Broker 的成功响应&lt;/strong&gt;。&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;这种模式可以使得消息发送更可靠，更不易丢失&lt;/li&gt;
      &lt;li&gt;但是，消息发送的延迟更高（需要等待多个副本收到消息）&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;42-buffermemory&quot;&gt;4.2 buffer.memory&lt;/h2&gt;

&lt;p&gt;该参数用来设置生产者内存缓冲区的大小；生产者用其缓存将要发送到服务器的消息。&lt;/p&gt;

&lt;p&gt;如果应用程序发送消息的速度超过将缓冲区消息发送到服务器的速度，会导致生产者空间不足。此时，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;send()&lt;/code&gt; 方法会被阻塞或者抛出异常。&lt;/p&gt;

&lt;h2 id=&quot;43-compressiontype&quot;&gt;4.3 compression.type&lt;/h2&gt;

&lt;p&gt;默认情况下，消息发送不会被压缩。不过，可以通过该参数指定压缩算法，如 snappy, gzip, lz4。&lt;/p&gt;

&lt;h2 id=&quot;44-retries&quot;&gt;4.4 retries&lt;/h2&gt;

&lt;p&gt;消息发送时可能会遇到临时且可重试的错误，可以通过 retries 参数配置生产者可重发消息的次数。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果重试次数达到该配置，生产者就会放弃重试并返回异常&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;45-batchsize&quot;&gt;4.5 batch.size&lt;/h2&gt;

&lt;p&gt;当多个消息被发送到同一个分区时，生产者会将其放到同一个批次中。该参数指定了一个批次可用内存大小（按字节计算，而不是消息个数）。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;当批次被填满时，该批次里的消息被发送&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;46-lingerms&quot;&gt;4.6 linger.ms&lt;/h2&gt;

&lt;p&gt;该参数指定了生产者在发送批次前等待其他消息加入批次的时间。&lt;/p&gt;

&lt;p&gt;当批次被填满或者 linger.ms 达到上限时，将批次消息发送出去。&lt;/p&gt;

&lt;h2 id=&quot;47-maxinflightrequestsperconnection&quot;&gt;4.7 &lt;strong&gt;max.in.flight.requests.per.connection&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;该参数指定&lt;strong&gt;生产者在收到服务器响应之前，可以发送多少个消息&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;如果该值为 1，可以保证消息时按照发送的顺序写入服务器，即使发生重试&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;该参数值设置得较高可以增加内存使用量，同时提高吞吐量，但设置得太高可能会降低吞吐量，因为批处理效率会降低。&lt;/p&gt;

&lt;h2 id=&quot;48-maxrequestsizesh&quot;&gt;4.8 &lt;strong&gt;max.request.sizesh&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;控制生产者发送请求的大小&lt;/p&gt;

&lt;h2 id=&quot;49-顺序保证&quot;&gt;4.9 顺序保证&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Kafka 可以保证同一个分区内的消息是有序的&lt;/strong&gt;。即，如果生产者按照一定的顺序发送消息，Broker 就会按照这个顺序将消息写入分区。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reties &amp;gt; 0, max.in.flight.requests.per.connection &amp;gt; 1&lt;/code&gt;，那么如果第一个批次的消息写入失败，而第二个批次消息写入成功。Broker 会重试第一个批次的消息，如果重试成功，那么两个批次的消息就会反过来。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;如果 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;reties &amp;gt; 0, max.in.flight.requests.per.connection = 1&lt;/code&gt;，那么生产者在尝试发送第一批次消息时，不会有其他消息发送给 Broker。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;这种配置会严重影响生产者的吞吐量，只有在对消息顺序有严格要求时才能这么配置&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;5-分区&quot;&gt;5. 分区&lt;/h1&gt;

&lt;p&gt;在发送消息时，可以指定消息的 key，也可以将 key = null。key 有两个用途：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;作为消息的附加信息&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;用来决定该消息被发送到主题的哪个分区。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;拥有相同 key 的消息会被写入到同一个分区中&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;如果 key == null，并且使用默认的分区器，那么消息将会被随机发送到各个可用的分区上。&lt;/p&gt;

&lt;p&gt;如果 key ≠ null，并且使用默认的分区器，那么 Kafka 会先对 key 进行 hash，之后根据 hash 值将消息映射到特定的分区上，使得同一个 key 的消息总会被映射到同一个分区上。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在进行映射时，会使用所有的分区，而不是可用的分区。所以，如果分区不可用，写入将出错&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;需要注意的是，只有在主题分区数量不变的情况下，key 与分区的映射次啊会保持不变。如果分区数发生变化，那么新的消息可能别写入到其他分区上，因此在创建主题时需要把分区规划好。&lt;/p&gt;

&lt;h2 id=&quot;51-自定义分区策略&quot;&gt;5.1 自定义分区策略&lt;/h2&gt;

&lt;p&gt;默认分区器能够满足大部分需求，不过也可以使用自定义分区进行消息管理。&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BananaPartitioner&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;implements&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Partitioner&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;

	  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;configure&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;configs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{}&lt;/span&gt;
	
	  &lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;byte&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;valueBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Cluster&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
				&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;PartitionInfo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cluster&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;partitionsForTopic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;topic&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
				&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(!(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;instanceOf&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)))&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;throw&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;InvalidRecordException&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;We expect all messages to have customer name as key&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
					
				&lt;span class=&quot;c1&quot;&gt;// Banana will always go to last partition&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(((&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;equals&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Banana&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
						&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt; 
				&lt;span class=&quot;c1&quot;&gt;// Other records will get hashed to the rest of the partitions&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Math&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Utils&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;murmur2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numPartitions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1. 生产者概述</summary></entry><entry><title type="html">Lion: Multi-Region Data Synchronization</title><link href="http://localhost:4000/multi-region-data-synchronization.html" rel="alternate" type="text/html" title="Lion: Multi-Region Data Synchronization" /><published>2023-03-12T00:00:00+08:00</published><updated>2023-03-12T00:00:00+08:00</updated><id>http://localhost:4000/multi-region-data-synchronization</id><content type="html" xml:base="http://localhost:4000/multi-region-data-synchronization.html">&lt;h1 id=&quot;1文档概述&quot;&gt;1、文档概述&lt;/h1&gt;

&lt;h2 id=&quot;11项目背景&quot;&gt;1.1 项目背景&lt;/h2&gt;

&lt;p&gt;Lion 目前部署在北京，上海两侧数据中心，北上两地双向同步。对于未来怀来，香港或者其他数据中心的规划，Lion 暂不支持其他数据中心的数据同步。&lt;/p&gt;

&lt;p&gt;短期内可以通过 Region 内流量闭环，数据访问仍使用北上两地数据中心的方案临时支持，长期需要探索支持多数据中心同步功能。&lt;/p&gt;

&lt;h2 id=&quot;12项目目标&quot;&gt;1.2 项目目标&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;支持多数据中心间数据同步（同步方向可自定义设置）&lt;/li&gt;
  &lt;li&gt;同一 Region 内数据和流量闭环&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;13名词解释&quot;&gt;1.3 名词解释&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;名词&lt;/th&gt;
      &lt;th&gt;解释&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;DTS&lt;/td&gt;
      &lt;td&gt;美团内部一种集数据订阅、数据同步、数据迁移于一体的数据传输服务&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;DRC&lt;/td&gt;
      &lt;td&gt;饿了么数据复制中心&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;MGR&lt;/td&gt;
      &lt;td&gt;MySQL 组复制&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion&lt;/td&gt;
      &lt;td&gt;美团内部配置统一管理和实时推送的平台&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Consistency&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责数据同步模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Manager（新增）&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责同步任务管理模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion Meta&lt;/td&gt;
      &lt;td&gt;Lion 系统内负责服务注册发现模块&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lion API/Console&lt;/td&gt;
      &lt;td&gt;Lion 系统内 Open API 及管理端模块&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;2整体架构&quot;&gt;2、整体架构&lt;/h1&gt;

&lt;h2 id=&quot;21-技术调研&quot;&gt;2.1 技术调研&lt;/h2&gt;

&lt;h3 id=&quot;211-拓扑结构调研&quot;&gt;2.1.1 拓扑结构调研&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;拓扑模型&lt;/th&gt;
      &lt;th&gt;描述&lt;/th&gt;
      &lt;th&gt;比较&lt;/th&gt;
      &lt;th&gt;结论&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;星型拓扑&lt;/td&gt;
      &lt;td&gt;一个指定的根节点将写入转发给所有其他节点&lt;/td&gt;
      &lt;td&gt;优点 1.同步链路保持一定的顺序，数据一致性可以得到提升; 2.运维相对简单。缺点：1.由于数据同步需要通过中间节点转发，中间节点可能会成为性能瓶颈，容易出现单点故障，系统容错降低;2.由于顺序同步，使得整体数据同步延迟会增大（节点数越多，延迟越大）&lt;/td&gt;
      &lt;td&gt;采用星型拓扑结构:1.超过2/3的配置变更集中在北京，后续怀来，上海可以以北京为主进行同步;2.以北京为主，在数据冲突，一致性保证方面处理相对简单，包括增量一致性检测功能实现&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;全部至全部型（网状型）&lt;/td&gt;
      &lt;td&gt;每个主节点将其写入同步到其他所有主节点&lt;/td&gt;
      &lt;td&gt;优点:1.数据同步链路更密集，数据可以沿着不同路径传播，避免了单点故障，容错性更高;2.数据变更全链路广播，整体同步延迟相对更低. 缺点:1.同步链路顺序无法得到保障，数据冲突的情况更复杂（可能所有节点都需要处理冲突）;2.运维更加复杂&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;212-同步方案调研&quot;&gt;&lt;strong&gt;2.1.2 同步方案调研&lt;/strong&gt;&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;业界方案&lt;/th&gt;
      &lt;th&gt;部署架构&lt;/th&gt;
      &lt;th&gt;整体介绍&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;美团 DTS&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;1.Reader 模块与源 DB 同地域部署，从源 DB dump Binlog，并存储在本地内存与磁盘中; 2.Writer 模块与目标 DB 同地域部署，从 Reader 中消费 Binlog，并将数据写入目标 DB 中; 3.Reader 与 Writer 之间通过私有协议实现高速传输；任务调度依赖 Lion 配置下发&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1479786749&quot;&gt;DTS&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;饿了么 DRC&lt;/td&gt;
      &lt;td&gt;-&lt;/td&gt;
      &lt;td&gt;1.Replicator 模块：用于解析源 DB 的 Binlog，并缓存到一个超大的 Event Buffer 中；同时将解析结果通过 TCP 推动到目标 Applier 模块;2.Applier 模块：接收从 Replicator 推送的数据，并写入到目标 DB 中;3.Console 模块：用于控制管理&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1479723243&quot;&gt;DRC&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;DTS 与 DRC 在架构部署上比较类似，有一些共通的地方：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;读写分离&lt;/strong&gt;：Binlog 订阅与回放逻辑拆分为两个模块：Reader，Writer，进行读写分离；两个模块可分别按需扩展，提高系统扩展性&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同地域部署&lt;/strong&gt;：Reader 模块与源 DB 同地域部署，Writer 模块与目标 DB 同地域部署；Reader 与 Writer 之间通过私有协议高速传输&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;中心化管理&lt;/strong&gt;：Reader/Writer 涉及的订阅与回放任务分配都是通过中心模块统一调度，而不是由 Reader/Writer 模块分别管理&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Log 打标&lt;/strong&gt;：为了避免数据回环，对产生的 Log 进行打标，标识地域信息，在回放时进行过滤&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对上述几点 Lion 在设计过程中基本都可以借鉴，不过为了简化设计，Reader/Writer 模块不进行拆分，合并部署（不过仍然进行逻辑上角色区分）。&lt;/p&gt;

&lt;p&gt;💡 &lt;strong&gt;Q：为什么 Lion 不考虑直接接入 DTS ？&lt;/strong&gt;
A：1. DTS 目前所有运维动作、高可用强依赖 Lion，去掉 Lion 强依赖的情况下改造成本高，并且 SLA 无法保证
      2. DTS 目前在运维、宕机等场景存在数据回溯，不满 足Lion 低延迟、数据不回退（配置版本回退）要求
      3. 如果多中心之间两两互备，DTS 针对这种复杂链路，数据迁移拆分短期没有比较好的解决方&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Q：DTS 与 DRC 都是通过 Binlog 订阅传输实现数据复制，Lion 是否也采取该方案？&lt;/strong&gt;
A：Lion 同步数据模型采用自定义 Log 结构。
      目前 Lion 北上数据中心间同步使用的是自定义 Log 数据，考虑到引入 MGR Binlog 订阅解析流程并不会对同步流程有显著的提升，并且会提高运维复杂度。
      同时，Lion 北上存量数据（Config, Release等表）并不完全一致，暂时无法直接采用 Binglog 进行同步。比如，由于同一条配置在北上最新版本号并不相同，如果从数据库层面强行保持一致，会触发一侧业务重新进行全量配置加载，有较大的风险。
      因此，Lion 仍保使用自定义 Log 结构。&lt;/p&gt;

&lt;h3 id=&quot;213-推拉选型&quot;&gt;2.1.3 推拉选型&lt;/h3&gt;

&lt;p&gt;这里的推拉模型指的是 Reader 与 Writer 之间传输 Log 的方式：1. Reader 主动将 Log 推送到 Writer；2. Writer 定时从 Reader 按需拉取 Log。&lt;/p&gt;

&lt;h2 id=&quot;22-设计总体思路&quot;&gt;2.2 设计总体思路&lt;/h2&gt;

&lt;h3 id=&quot;221-部署架构&quot;&gt;2.2.1 部署架构&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以北京，上海两个数据中心为例，每个数据中心部署了全量的 Lion 服务（部分服务未在图中展示）。通过同步配置变更到其他数据中心，使得每个数据中心拥有全量数据，能够独立提供完整的 Lion 功能。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;MGR (DB)&lt;/strong&gt;：持久化业务配置数据，同步日志，同步任务元数据等信息。MGR 有两种部署模式：
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;每中心单独部署&lt;/em&gt;&lt;/strong&gt;：存储中心内业务数据（如同步任务管理相关元数据），支持中心内流量与数据闭环。不同数据中心的 MGR 数据实时同步，最终每个数据中心拥有全量业务数据。&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;特定中心部署&lt;/em&gt;&lt;/strong&gt;：存储公共数据，便于统一管理（如同步模块节点最新列表），支持不同数据中心的服务进行跨地域访问。只部署在指定数据中心（上海），供所有数据中心进行访问。&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;：执行数据同步任务；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;无状态服务；逻辑上划分为 Reader，Writer 两种角色&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;&lt;strong&gt;&lt;em&gt;Reader&lt;/em&gt;&lt;/strong&gt;：对外暴露 HTTP API 接口，提供同步日志查询功能&lt;/p&gt;

        &lt;blockquote&gt;
          &lt;p&gt;功能很轻量：提供 API 接口供 Writer 访问&lt;/p&gt;

        &lt;/blockquote&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;Writer&lt;/em&gt;&lt;/strong&gt;：调用 Reader 接口，实现同步日志在数据中心间传输逻辑；同时完成日志存储，回放等功能。
        &lt;ul&gt;
          &lt;li&gt;在访问其他数据中心的 Reader 之前，会从 Meta 查询异地数据中心内 Reader 可用节点列表（缓存在本地，定时更新）&lt;/li&gt;
          &lt;li&gt;每个 Writer 任务同步特定分区的日志，并将最新同步偏移量上报到 Manager&lt;/li&gt;
          &lt;li&gt;Writer 生命周期由 Manager 进行管理，会周期性上报自身状态&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;为了提高同步扩展性，将同步日志进行切片，每个 Writer 任务只会同步指定切片的日志。&lt;/p&gt;

    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;同步节点 : 同步任务 = 1 : N (每个同步节点上可能会运行多个同步任务)&lt;/p&gt;

    &lt;/blockquote&gt;

    &lt;blockquote&gt;
      &lt;p&gt;同步任务 : 同步分区 = 1 : 1 (每个同步任务只会同步一个分区内的日志)&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Manager (新增)&lt;/strong&gt;：用于同步元数据管理，同步任务调度；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;管理同步元数据&lt;/em&gt;&lt;/strong&gt;：1. 同步节点（Consistency）与同步分区（Partition）索引的映射关系；2. 同步分区最新同步偏移量（Offset）&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;同步任务调度&lt;/em&gt;&lt;/strong&gt;：1. 在同步节点上，根据分区索引创建对应同步任务；2. 分区索引迁移时，完成同步任务迁移；3. 与同步任务之间维持心跳，确保同步任务处于运行状态&lt;/li&gt;
      &lt;li&gt;每个数据中心内部署多个 Manager 节点，作为同步任务调度的中心模块：
        &lt;ol&gt;
          &lt;li&gt;与中心内同步节点（Consistency）周期交互：1. 下发同步任务创建/销毁的命令；2. 了解同步任务的运行状态；3. 确定同步任务最新偏移量&lt;/li&gt;
          &lt;li&gt;定时轮询 Meta 节点：查询中心内 Consistency 最新可用节点列表，在节点状态变更时进行同步分区 Rehash 及同步任务迁移&lt;/li&gt;
          &lt;li&gt;从中心内 MGR 加载同步任务元数据；将最新元数据持久化到 MGR&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;每个 Manager 节点都可以进行任务管理（并不是主从架构），为了减少多个 Manager 管理冲突，引入简单的分布式锁（Lion 内部已运行验证）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Meta&lt;/strong&gt;：提供 Lion 侧部分服务注册发现功能；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;同步节点（Consistency）上下线时，会由数据中心内的 Meta 节点维护其可用状态，并&lt;strong&gt;&lt;em&gt;将中心内最新可用节点列表存储在公共 DB 中&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;不同数据中心的 Meta 节点都可以查看所有数据中心的同步节点（Consistency）列表视图&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;API/Console&lt;/strong&gt;：Lion 管理端 / API 模块，为用户提供配置变更/查询等功能；每中心单独部署
    &lt;ul&gt;
      &lt;li&gt;每次配置变更都会产生对应的同步日志（Log），用于数据中心间配置同步&lt;/li&gt;
      &lt;li&gt;API/Console 请求的流量 + 访问的数据会在中心内实现闭环&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;222-数据模型&quot;&gt;2.2.2 数据模型&lt;/h3&gt;

&lt;h3 id=&quot;2221-同步日志&quot;&gt;2.2.2.1 同步日志&lt;/h3&gt;

&lt;p&gt;Lion 同步日志采用自定义 Log，而非 Binlog。根据同步阶段的不同，我们将 Log 拆分为两种形式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;源同步日志（source sync log）&lt;/strong&gt;：包含变更配置的详细信息。配置变更时，在本地数据中心产生一条日志，该日志会被其他数据中心加载，同步。&lt;/p&gt;

    &lt;p&gt;具体设计&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;id&lt;/th&gt;
          &lt;th&gt;release_key&lt;/th&gt;
          &lt;th&gt;timestamp&lt;/th&gt;
          &lt;th&gt;key&lt;/th&gt;
          &lt;th&gt;appkey&lt;/th&gt;
          &lt;th&gt;set/swimlane/env&lt;/th&gt;
          &lt;th&gt;old_value&lt;/th&gt;
          &lt;th&gt;new_value&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主键&lt;/td&gt;
          &lt;td&gt;变更唯一标识&lt;/td&gt;
          &lt;td&gt;变更时间戳&lt;/td&gt;
          &lt;td&gt;配置 key&lt;/td&gt;
          &lt;td&gt;配置 appkey&lt;/td&gt;
          &lt;td&gt;配置其他标识&lt;/td&gt;
          &lt;td&gt;旧值&lt;/td&gt;
          &lt;td&gt;新值&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;同步方向为&lt;strong&gt;上海 -&amp;gt; 北京&lt;/strong&gt;时，北京侧的 Consistency(Writer) 节点上的同步任务会不断从上海侧批量拉取&lt;strong&gt;&lt;em&gt;未同步&lt;/em&gt;&lt;/strong&gt;的 SourceSyncLog。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;通过 Offset 来标识已同步的 SourceSyncLog（id &amp;gt; offset : 未同步；id &amp;lt;= offset : 已同步）&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;目标同步日志（target sync log）&lt;/strong&gt;：通过回放该日志，将其他数据中心的最新配置更新到本地数据中心（目标同步日志是由源同步日志转化而来的）。&lt;/p&gt;

    &lt;p&gt;具体设计&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;id&lt;/th&gt;
          &lt;th&gt;source_idc&lt;/th&gt;
          &lt;th&gt;source_idc_log_id&lt;/th&gt;
          &lt;th&gt;status&lt;/th&gt;
          &lt;th&gt;release_key&lt;/th&gt;
          &lt;th&gt;timestamp&lt;/th&gt;
          &lt;th&gt;key&lt;/th&gt;
          &lt;th&gt;appkey&lt;/th&gt;
          &lt;th&gt;set/swimlane/env&lt;/th&gt;
          &lt;th&gt;old_value&lt;/th&gt;
          &lt;th&gt;new_value&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;主键&lt;/td&gt;
          &lt;td&gt;源数据中心标识&lt;/td&gt;
          &lt;td&gt;源数据中心的 SourceSyncLog Id&lt;/td&gt;
          &lt;td&gt;同步状态&lt;/td&gt;
          &lt;td&gt;变更唯一标识&lt;/td&gt;
          &lt;td&gt;变更时间戳&lt;/td&gt;
          &lt;td&gt;配置 key&lt;/td&gt;
          &lt;td&gt;配置 appkey&lt;/td&gt;
          &lt;td&gt;配置其他标识&lt;/td&gt;
          &lt;td&gt;旧值&lt;/td&gt;
          &lt;td&gt;新值&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;

    &lt;p&gt;同步方向为&lt;strong&gt;上海 -&amp;gt; 北京&lt;/strong&gt;时，北京侧的同步任务将从上海侧拉取到的 SourceSyncLog 转化成 TargetSyncLog，并插入本地 DB；之后会根据 TargetSyncLog 将上海侧的变更回放到本地。&lt;/p&gt;

    &lt;p&gt;💡 TargetSyncLog 比 SourceSyncLog 多了 source_idc, source_idc_log_id, status 字段，主要是为了避免数据回环，标识已同步位置等&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2222-同步任务元数据&quot;&gt;2.2.2.2 同步任务元数据&lt;/h3&gt;

&lt;p&gt;数据中心间 Log 传输简单来看就是将其他数据中心的 Log 复制到本侧数据中心，复制过程有几点需要考虑：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;同步链路控制&lt;/strong&gt;：应该明确哪些数据中心间可以进行同步，数据是单向同步还是双向同步&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步任务扩展性及性能&lt;/strong&gt;：如果集群中的单个同步节点都同步全量 Log，可能会使得同步性能较低，延迟较大；同时，集群无法水平扩容，扩展性低。我们应该将同步 Log 以切片的形式分配给各个集群节点，每个节点同步部分 Log，从而提高集群的扩展性及同步性能&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步稳定性&lt;/strong&gt;：节点状态经常变化（宕机/重启/扩容/下线），同步任务也随之不太稳定；我们应该保证在同步任务重启/迁移/销毁时，Log 同步尽量不遗漏，不重复&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;针对上面三点问题，可以通过相应的配置进行管理：&lt;/p&gt;

&lt;h3 id=&quot;22221-同步路由配置idc-routers&quot;&gt;&lt;strong&gt;2.2.2.2.1 同步路由配置（IDC Routers）&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;用于控制不同数据中心间的同步方向&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;target_idc&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;status&lt;/th&gt;
      &lt;th&gt;备注&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;目标数据中心&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;（当前数据中心）&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步是否开启&lt;/td&gt;
      &lt;td&gt;数据同步方向：&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;source -&amp;gt; target&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：北京 -&amp;gt; 上海&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;target_idc&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;status&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;sh&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;true&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;22222-同步分区配置partitions&quot;&gt;2.2.2.2.2 同步分区配置（Partitions）&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;同步节点与同步分区的映射关系&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;同步分区设计参考 Redis Cluster Slot 实现，人为提前设定分区总数，如分区总数 30，分区索引为 [0, 1, 2, 3, 4 … 29]。&lt;/p&gt;

    &lt;p&gt;每个同步节点负责一部分分区索引集合，如 node_1:[0, 2, 4, 6]，node_2:[1, 3, 5]。&lt;/p&gt;

    &lt;p&gt;在进行 Log 同步时，先对 Log Key 进行 Hash 取模，计算 Log 对应的分区索引，如果该索引值落在同步节点维护的范围内，则由该节点进行同步，否则忽略。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;通过这种方式，可以保证同一个 key 的变更会由相同的同步节点进行同步，保证同步顺序&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;node&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_indexes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;同步节点：Consistency(Writer)&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步分区索引列表&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：上海侧同步分区配置&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;node&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_indexes&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;sh_node_1&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;[1, 2, 3, 4, 5]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;sh_node_2&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;[6, 7, 8, 9, 10]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;💡 该配置表示的是&lt;em&gt;本地数据&lt;/em&gt;中心同步任务的配置。通常，&lt;strong&gt;一个同步节点可能运行多个同步任务，每个同步任务负责同步特定的分区索引 Log。
分区总数提前配置好，且正常情况下保持不变；尽量保证分区索引在同步节点中均匀分配。&lt;/strong&gt;
同步节点 : 同步任务 = 1 : N (每个同步节点上可能会运行多个同步任务)
同步任务 : 同步分区 = 1 : 1 (每个同步任务只会同步一个分区)&lt;/p&gt;

&lt;h3 id=&quot;22223-日志分区偏移量配置offsets&quot;&gt;&lt;strong&gt;2.2.2.2.3 日志分区偏移量配置（Offsets）&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;记录每个分区最新同步位置&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_index&lt;/th&gt;
      &lt;th&gt;offset&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主键&lt;/td&gt;
      &lt;td&gt;源数据中心&lt;/td&gt;
      &lt;td&gt;同步分区索引&lt;/td&gt;
      &lt;td&gt;同步日志偏移量&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;示例：北京分区偏移量配置&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;id&lt;/th&gt;
      &lt;th&gt;source_idc&lt;/th&gt;
      &lt;th&gt;partition_index&lt;/th&gt;
      &lt;th&gt;offset&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;bj&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;💡 同步任务增量同步指定分区的部分 Log 之后，更新该分区的偏移量（offset），以便&lt;strong&gt;当同步任务重启/迁移后能够从上次同步的位置继续同步&lt;/strong&gt;。
每个源数据中心下的每个分区都需要维护自身的 Offset。&lt;/p&gt;

&lt;h3 id=&quot;223-manager--同步任务调度&quot;&gt;2.2.3 Manager : 同步任务调度&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前面提到，为了提高同步任务的扩展性，对同步日志进行了切片处理，&lt;strong&gt;每个同步任务只负责一个切片，每个同步节点上可运行多个同步任务&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Manager 作为同步任务管理的核心模块，主要与同数据中心内的同步节点（Consistency）节点进行交互，涉及功能有：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;初始化同步任务&lt;/strong&gt;：在新增数据中心，新增同步/集群节点，同步服务启动时，在同步节点（Consistency）上初始化同步任务&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步任务维护&lt;/strong&gt;：主动检测同步节点上各个任务的执行状态；在同步任务不可用时，及时销毁旧任务，创建新任务；当同步分区迁移时，主动在同步节点间迁移同步任务&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;日志分区分配&lt;/strong&gt;：当同步节点变更时，需要对分区进行分配，保证不同节点间同步负载尽可能均衡（&lt;em&gt;同步分区的变更会触发同步任务的迁移&lt;/em&gt;）&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;系统初始化时，由人工手动进行分区配置&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;同步节点监听&lt;/strong&gt;：Manager 会定时从 Meta 查询最新的同步节点列表，当发生节点变更时，触发分区重新分配&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;分区偏移量维护&lt;/strong&gt;：同步任务在完成增量日志同步时，会上报当前分区最新偏移量并持久化，以便后续同步任务重启时能够从最新 Offset 处重新同步&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Manager 管理流程细节如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Manager 从 DB 中加载 IDC Routers，Partitions 原数据，用于明确数据同步方向（source-&amp;gt;target），同步节点维护的分区列表&lt;/li&gt;
  &lt;li&gt;Manager &lt;strong&gt;定时与同步节点通信&lt;/strong&gt;，获取节点上分区同步任务的执行状态：{partition_index: task_status}
    &lt;ol&gt;
      &lt;li&gt;如果同步节点维护的分区列表没有对应的同步任务执行，则在该同步节点上&lt;strong&gt;初始化对应分区同步任务&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;如果同步节点维护的部分分区任务执行状态异常，则在该同步节点上&lt;strong&gt;新建对应分区同步任务，并销毁旧同步任务&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;在同步任务正常执行期间，会上报最新已同步分区日志偏移量至 Manager，并持久化到 Offsets 表中&lt;/li&gt;
  &lt;li&gt;Manager 定时从 Meta 查询同步模块最新可用节点列表
    &lt;ol&gt;
      &lt;li&gt;如果新增/摘除同步节点，则 &lt;strong&gt;Manager 会对同步分区进行重新分配&lt;/strong&gt;，尽量保证分区均匀分配&lt;/li&gt;
      &lt;li&gt;分区重新分配之后，需要对同步任务进行迁移，确保&lt;strong&gt;同步节点维护的分区列表与同步任务一一对应&lt;/strong&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从上面流程我们可以看到：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Offset 只会由同步任务上报并更新&lt;/strong&gt;； Offset 与 Partition 绑定&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Partition 配置只在同步节点发生变更的时候才会变更&lt;/strong&gt;；Partition 与同步节点绑定&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;💡 Q：数据中心初始化阶段，同步分区如何分配的？
A：初始阶段由人工手动为同步节点进行分区分配，并且分区总数需要大于节点数。如同步节点数为 5，分区总数为 30.&lt;/p&gt;

&lt;p&gt;Q：多个 Manager 会同时进行任务管理吗？
A：会的，同一数据中心内会有多个 Manager 节点进行管理，为了减少冲突，可以更新前使用简单的分布式锁（已在 Lion 当前实现中得到验证）.&lt;/p&gt;

&lt;h3 id=&quot;224-consistency--实时同步数据&quot;&gt;2.2.4 Consistency : 实时同步数据&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Manager 在同步节点（Consistency）上创建的同步任务用于实现不同数据中心间数据同步功能&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用户在北京侧变更配置，北京侧 DB 会插入一条 SourceSyncLog，该 Log 包含了配置变更的详细信息&lt;/li&gt;
  &lt;li&gt;上海侧同步任务（Writer）在运行时，会从 Manager &lt;strong&gt;加载对应分区的偏移量&lt;/strong&gt;，同时从 Meta 获取&lt;strong&gt;北京侧 Consistency 最新可用节点列表&lt;/strong&gt;，用于后续日志拉取&lt;/li&gt;
  &lt;li&gt;同步任务（Writer）&lt;strong&gt;随机访问&lt;/strong&gt;北京侧 Consistency（Reader）节点，根据 Offset 批量加载 SourceSyncLog
    &lt;ol&gt;
      &lt;li&gt;对北京侧返回的日志进行过滤，&lt;strong&gt;过滤出属于当前分区索引的部分日志&lt;/strong&gt;（对配置 key 取 hash）&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;过滤完成后，同步任务首先将&lt;strong&gt;过滤结果日志批量保存在本地 DB&lt;/strong&gt;（TargetSyncLog）中
    &lt;ol&gt;
      &lt;li&gt;此时，保存在本地的 TargetSyncLog 的 Status 字段默认为&lt;em&gt;未同步状态&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;随后，同步任务（Writer）将日志依次回放，将北京侧的最新配置同步本地
    &lt;ol&gt;
      &lt;li&gt;同步成功之后，将 TargetSyncLog 的 Status 字段置为&lt;em&gt;同步成功状态&lt;/em&gt;&lt;/li&gt;
      &lt;li&gt;如果同步失败，则应将 Status 字段置为&lt;em&gt;同步失败状态&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;将回放完成的日志 &lt;strong&gt;LogId 作为最新分区 Offset&lt;/strong&gt; 上报给 Manager
    &lt;ol&gt;
      &lt;li&gt;不管回放成功还是失败，都需要上报 Offset，优先保证不阻塞后续日志同步 =&amp;gt; 对于失败的日志，由后续补扫任务继续同步&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;本批次同步完成之后，将以最新的 Offset 进行下一次同步流程&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;每个同步任务只会同步属于自身分区的日志，正常情况下，不同节点上的不同同步任务不会重复同步同一条日志（即使有少量重复同步也没影响）&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;💡 Q：日志同步流程是否可以将 Log 持久化到 DB 步骤移除？
A：日志回放过程可能会失败，通过将 Log 持久化，并标识状态，可以方便后续重新同步，保证不遗漏&lt;/p&gt;

&lt;p&gt;Q：整个流程基本为同步执行，是否会存在性能问题？
A：通过设置适当大小的分区（如 256），并考虑代码层面优化（如热点 key 聚合，分区内部再 hash），基本能够满足 Lion 需求&lt;/p&gt;

&lt;h3 id=&quot;225-同步集群节点变更与任务迁移&quot;&gt;2.2.5 同步集群节点变更与任务迁移&lt;/h3&gt;

&lt;p&gt;在日常运维中，集群节点变更是经常发生的，如服务发布，宿主机宕机，新增机器等。我们需要保证集群节点变化时，数据同步功能仍稳定执行。针对这类问题，进一步进行讨论。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;每个节点维护一部分分区，每个分区对应一个同步任务。当其中一个节点不可用时，该节点维护的分区集合就会被迁移到其他节点上，同时在其他节点上创建对应的分区同步任务。&lt;/p&gt;

&lt;p&gt;那么，在同步任务迁移（分区迁移）过程中，能否保证同步流程稳定执行？&lt;/p&gt;

&lt;p&gt;回看下同步任务的执行步骤，进一步分析：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在日志从异地加载过滤之后，将会持久化到 DB。之后会逐条顺序回放日志，回放完成后上报最新 Offset&lt;/p&gt;

&lt;/blockquote&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;任务迁移时机&lt;/th&gt;
      &lt;th&gt;直接影响&lt;/th&gt;
      &lt;th&gt;同步稳定性影响&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 1: 日志加载&lt;/td&gt;
      &lt;td&gt;当前批次拉取失败&lt;/td&gt;
      &lt;td&gt;无影响：由于 Offset 未变化，迁移后的新任务会重新从当前位置拉取&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 2: 日志过滤，保存&lt;/td&gt;
      &lt;td&gt;拉取的日志保存失败&lt;/td&gt;
      &lt;td&gt;无影响：由于 Offset 未变化，迁移后的新任务会重新从当前位置拉取，过滤，保存&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 3: 逐条回放日志&lt;/td&gt;
      &lt;td&gt;该批次 logId &amp;gt; offset 的日志回放失败&lt;/td&gt;
      &lt;td&gt;少量日志重复同步：该批次 logId &amp;gt; offset 的日志会被新任务重新同步&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Step 4: 上报 Offset&lt;/td&gt;
      &lt;td&gt;该条回放完成的日志 logId 未上报&lt;/td&gt;
      &lt;td&gt;少量日志重复同步：该批次 logId &amp;gt; offset 的日志会被新任务重新同步&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;可以看出，在同步任务执行阶段的任何时机迁移，&lt;strong&gt;最坏的情况是该批次日志被重复同步&lt;/strong&gt;。而我们的同步流程支持幂等，且日志批次大小可控，因此，对同步流程的稳定性基本没有影响。&lt;/p&gt;

&lt;h3 id=&quot;226-补扫任务重新同步&quot;&gt;2.2.6 补扫任务：重新同步&lt;/h3&gt;

&lt;p&gt;在 Log 复制并同步到本地流程中，可能会因为 DB 异常/代码逻辑 Bug 等原因导致同步失败，为了不阻塞后续变更同步，在重试一定次数之后，应该放弃。&lt;/p&gt;

&lt;p&gt;但是，为了保证配置最终同步成功，应该对同步失败的 Log 进行重新同步。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;补扫任务定时从 TargetSyncLog 中加载未同步成功（可能是同步失败，也可能是未同步）的日志，同样按照分区进行过滤&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;为了避免扫描到刚复制过来，但还未同步完成中的日志，补扫任务需要扫描一定时间范围内的日志，如 1 分钟范围外&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;对扫描到的日志进行重新同步，如果成功，则更新 Status 字段为同步成功状态；否则仍放弃，等待下次补扫任务同步&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;多次补扫同步仍可能失败，因此需要设置一个同步阈值，超过该阈值仍未成功，则触发告警，人工介入排查原因&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;补扫任务与同步节点是 1 : 1 的关系，即&lt;strong&gt;一个同步节点上只有一个补扫任务，并且该补扫任务负责多个日志分区&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;假如同步节点负责的分区索引为 [1, 2, 3]，那么会有三个实时同步任务，每个实时同步任务分别负责一个分区；但是只有一个补扫任务，同时负责 [1, 2, 3] 分区&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h3 id=&quot;227-一致性检测&quot;&gt;2.2.7 一致性检测&lt;/h3&gt;

&lt;p&gt;实时同步与补扫同步流程能够保证大部分情况下配置一致性（&amp;gt;99.99%），仍有小概率会出现配置不一致的情况。&lt;/p&gt;

&lt;p&gt;因此除了实时同步，补扫同步，还需要增加增量一致性检测任务，对于不一致的配置进行再次检测与修复。&lt;/p&gt;

&lt;p&gt;理想情况下，增量一致性检测任务执行步骤如下：1. 每个数据中心的同步节点按照 IDC Router 配置，从目标 IDC 中查询指定配置的最新值；2. 将目标 IDC 返回的最新值进行比较（timestamp 比较），如果多个数据中心的配置值不同，则选择最新的配置值作为目标值，并更新本地。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;举例，北京侧有个配置 key = lion-test.demo，北京侧同步节点查询 lion-test.demo 在上海/怀来/香港侧的最新值，如果这几个数据中心的值都不同，则以最新值为主，将其更新本地&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;考虑到已知需要支撑的数据中心有北京/上海/怀来/香港，如果按照上面执行步骤，那么检测链路为 4*3，每两个数据中心间都需要进行一次比较，对于不一致冲突情况处理比较复杂。后续如果需要再新增数据中心，冲突处理情况将会更加复杂，不利于维护。&lt;/p&gt;

&lt;p&gt;现在 Lion 已经有北京/上海两个数据中心，上海侧的变更请求只有北京侧的一半，大部分变更触发源都在北京，即大部分数据同步方向为：北京 -&amp;gt; 上海。&lt;/p&gt;

&lt;p&gt;因此，为了简化不一致冲突处理，我们人为&lt;strong&gt;给数据中心设置优先级：北京 &amp;gt; 怀来 &amp;gt; 上海 &amp;gt; 香港&lt;/strong&gt;。&lt;strong&gt;北京数据中心作为主数据中心&lt;/strong&gt;，其他数据中心以北京侧为主进行增量一致性检测。&lt;/p&gt;

&lt;p&gt;但是，如果其他数据中心的数据比北京要新，则需要反哺北京，更新北京侧数据。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/lion_data_synchronization/8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;以上海数据中心增量检测为例，基本流程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;上海侧 Consistency 增量一致性检测任务查询本地指定时间范围内配置变更列表&lt;/li&gt;
  &lt;li&gt;通过 HTTP 请求查询北京侧对应配置的最新值，并进行比较时间戳
    &lt;ol&gt;
      &lt;li&gt;反哺：如果上海 Timestamp &amp;gt; 北京 Timestamp，则回调北京，在北京侧插入一条 TargetSyncLog，等待后续补扫任务重新同步&lt;/li&gt;
      &lt;li&gt;修复：如果上海 Timestamp &amp;lt;= 北京 Timestamp，则在上海侧插入一条 TargetSyncLog，等待后续补扫任务重新同步，完成修复&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;💡 Q：为什么日志同步时未对数据中心进行优先级划分，简化同步流程呢？
A：如果日志同步也按照这种方式处理，那么优先级低的数据中心的变更就不会同步到其他数据中心，不能满足多数据中心一致性的目标。
      从 Lion 现状来看，经过实时同步，补扫同步之后，北上数据一致性的比例 &amp;gt; 99.99%。而增量一致性检测是对实时同步，补扫同步的兜底处理，对一些极少数配置不一致的情况进行检测修复。&lt;/p&gt;

&lt;p&gt;Q：为什么只考虑增量一致性检测，不考虑全量检测？
A：全量一致性检测成本太高，且从 Lion 现状来看，实时同步 &amp;amp; 补扫同步 &amp;amp; 增量一致性检测能够满足 Lion 对数据一致性要求。&lt;/p&gt;

&lt;h3 id=&quot;228-数据同步可用性保障&quot;&gt;2.2.8 数据同步可用性保障&lt;/h3&gt;

&lt;h3 id=&quot;2281-冲突解决&quot;&gt;2.2.8.1 冲突解决&lt;/h3&gt;

&lt;p&gt;每次配置变更都会记录变更时间戳（timestamp），默认冲突解决为比较时间戳进行覆盖。&lt;/p&gt;

&lt;p&gt;如果时间戳相同，则根据 IDC 优先级进行覆盖：BJ &amp;gt; HL &amp;gt; SH &amp;gt; HK。&lt;/p&gt;

&lt;h3 id=&quot;2282-一致性保证&quot;&gt;2.2.8.2 一致性保证&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;同步日志持久化到本地 DB，同步失败后会进行多次重试（实时同步与补扫同步均会重试）&lt;/li&gt;
  &lt;li&gt;每批次从其他数据中心成功复制日志之后，会持久化最新分区 Log 偏移量。即使节点重启，或者分区迁移，都能保证从上次同步位置重新同步&lt;/li&gt;
  &lt;li&gt;根据同步日志同步变更的配置流程是幂等的，支持重复同步&lt;/li&gt;
  &lt;li&gt;增量一致性检测任务进行兜底检测&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;2283-数据回环解决&quot;&gt;2.2.8.3 数据回环解决&lt;/h3&gt;

&lt;p&gt;同步日志在复制传输时，只会从目标 IDC 的 SourceSyncLog 表中查询，并保存在本地的 TargetSyncLog 表中，而根据 TargetSyncLog 执行数据同步的过程不会产生新的 SourceSyncLog，避免了数据回环的条件。即 &lt;strong&gt;&lt;em&gt;异地配置变更 -&amp;gt; SourceSyncLog -&amp;gt; TargetSyncLog -&amp;gt; 本地配置&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;h1 id=&quot;23-上线方案&quot;&gt;2.3 上线方案&lt;/h1&gt;

&lt;h3 id=&quot;231-前期准备&quot;&gt;2.3.1 前期准备&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;BJ，SH 侧创建同步元数据表：IDC Router, Partitions, Offsets；同步日志表：SourceSyncLog, TargetSyncLog&lt;/li&gt;
  &lt;li&gt;BJ，SH 侧配置同步相关元数据&lt;/li&gt;
  &lt;li&gt;BJ，SH 侧添加同步开关配置，用于新旧版本数据同步方案切换（默认关闭，使用旧方式进行同步）&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;232-上线步骤&quot;&gt;2.3.2 上线步骤&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;BJ，SH 服务发布：Manager, Consistency, Meta；此时配置变更会插入 Log 至 SourceSyncLog，但不通过该日志进行同步&lt;/li&gt;
  &lt;li&gt;开启 SH 侧同步开关：此时 BJ -&amp;gt; SH 采取新方案同步，SH -&amp;gt; BJ 仍采用旧方案同步
    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;记录下时间戳 T1，用于异常修复&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;观察监控：
    &lt;ol&gt;
      &lt;li&gt;同步流程正确性，同步日志堆积情况，同步延迟，北上数据一致性，增量一致性检测任务是否正常执行等&lt;/li&gt;
      &lt;li&gt;通过全链路监控查看配置变更推送是否正常&lt;/li&gt;
      &lt;li&gt;同时，观察 SH 侧 Offsets 是否持续增长&lt;/li&gt;
      &lt;li&gt;手动调整 SH 侧 Consistency 节点状态，观察 Partitions 是否正常调整，同步任务是否正常迁移，同步延迟/堆积是否符合预期&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;开启 BJ 侧同步开关：此时 BJ &amp;lt;-&amp;gt; SH 双向同步均采用新方案
    &lt;ol&gt;
      &lt;li&gt;&lt;em&gt;记录下当前时间戳 T2，用于异常修复&lt;/em&gt;&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;持续观察 SH，BJ 侧同步监控&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;233-回滚步骤&quot;&gt;2.3.3 回滚步骤&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;关闭 SH，BJ 侧同步开关：切回旧同步方案&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;调整 SH 侧增量一致性检测时间戳为 T1，BJ 侧时间戳调整为 T2&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;prefix = lion.instance.last.check.timestamp&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;持续观察监控：北上数据一致性，变更推送延迟等&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;24-非功能性设计&quot;&gt;2.4 非功能性设计&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;同步任务执行状态监控&lt;/li&gt;
  &lt;li&gt;同步分区变更周知&lt;/li&gt;
  &lt;li&gt;数据不一致告警&lt;/li&gt;
  &lt;li&gt;同步延迟监控，告警&lt;/li&gt;
  &lt;li&gt;同步堆积告警&lt;/li&gt;
  &lt;li&gt;多次同步失败告警&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;3项目风险点&quot;&gt;3、项目风险点&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;同步任务的管理
    &lt;ol&gt;
      &lt;li&gt;能否准确判断同步任务的执行状态&lt;/li&gt;
      &lt;li&gt;Manager 能否准确完成同步任务的迁移，能否及时 Kill 不可用任务并新建任务&lt;/li&gt;
      &lt;li&gt;在 Manager 管理不符合预期的情况下，需要人为介入，手动执行任务的删除与创建&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Offset 上报时机
    &lt;ol&gt;
      &lt;li&gt;每回放一条 Log 就上报 Offset 可以保证可靠性，但是性能会有所损耗&lt;/li&gt;
      &lt;li&gt;是否可以调整 Offset 上报时机，如周期上报，这样可以提高部分性能，但是在任务迁移时可能会有 Log 重复同步，需要进行权衡&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;同步一致性保证
    &lt;ol&gt;
      &lt;li&gt;在新方案上线期间，如果数据不一致概率较高，需要及时切换旧方案&lt;/li&gt;
      &lt;li&gt;新方案在北上数据中心得到验证，并且长时间运行一段时间后，才能推广到多数据中心&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;4faq&quot;&gt;4、FAQ&lt;/h1&gt;

&lt;p&gt;Q：Writer 任务调度管理比较复杂，如果只有一个 Writer 任务同步全量数据，是否可行？&lt;/p&gt;

&lt;p&gt;A：如果只有一个 Writer 任务进行同步，那么 Writer 同步性能需要尽可能高，最低要支持 2000QPS。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;按照当前的同步逻辑，单个同步任务肯定无法支撑：单条日志顺序同步耗时 TP999 48.4ms&lt;/li&gt;
  &lt;li&gt;优化单条日志顺序同步 -&amp;gt; 批量同步：简单测试了下，性能大概提升 20% 左右，不太能满足要求（可能仍存在优化空间；单批次日志数量不能过多，可能会引发大事务）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们将同步任务进行切片处理，&lt;strong&gt;除了性能因素，还有服务扩展性考虑&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;随着业务配置增加，数据中心逐步建设，同步任务要支持水平扩展以保证 SLA&lt;/li&gt;
  &lt;li&gt;同步任务调度管理虽然比较复杂，但是部分逻辑（如分区迁移）已经经过线上验证，其稳定性及扩展性能够得到保障&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，我们仍倾向继续采用任务切片的形式。&lt;/p&gt;

&lt;p&gt;Q：能否灵活调整数据中心同步方向？如将香港 -&amp;gt; 北京的同步链路切断，或者香港侧数据中心不与其他数据中心同步&lt;/p&gt;

&lt;p&gt;A：通过更新 IDC Router 配置即可调整数据中心间的同步方向（source_idc -&amp;gt; target_idc）&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;更新 IDC Router 的 status 字段可以调整同步方向开启与否&lt;/li&gt;
  &lt;li&gt;新增 IDC Router 记录可以新增同步链路&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Q：能否支持 Appkey 粒度同步方向控制？如 lion-demo 项目只可以从北京同步到上海&lt;/p&gt;

&lt;p&gt;A：可以支持。不过只按照前面的描述还不能满足，需要额外的配置，如每个数据中心新增一个表 IDCFilter，在该表中配置哪些 IDC 中的 Appkey, Key 不需要进行同步。&lt;/p&gt;

&lt;p&gt;在同步任务进行日志过滤时直接忽略对应的 IDC, Appkey, Key 即可实现。&lt;/p&gt;

&lt;p&gt;Q：能够支持部分业务同步流程隔离？如数据库相关配置与普通业务配置同步隔离&lt;/p&gt;

&lt;p&gt;A：可以支持；将特定范围的分区（如 1000 ～ 1024）单独划分出来给指定业务使用。&lt;/p&gt;

&lt;p&gt;在分区索引计算时进行设计，保证指定的 Appkey 列表只会路由到特定的分区，而其他业务 Appkey 路由到其他分区。&lt;/p&gt;

&lt;p&gt;Q：Lion 短期内仍不能完全下掉 Redis，对 Redis 同步如何处理？&lt;/p&gt;

&lt;p&gt;A：同步任务在回放日志时，先同步 DB，之后再同步 Redis。现有监控来看，Redis 数据同步耗时 TP999 71.3ms，平均 4.2ms，对同步延迟影响有限，可以直接同步。&lt;/p&gt;

&lt;p&gt;等 Redis 完全下掉之后，在通过开关移除 Redis 同步流程。&lt;/p&gt;

&lt;p&gt;Q：目前针对北上两个数据中心，Lion 文件配置在更新时会将文件内容同时更新到北上两个 S3 集群，在同步时只同步文件 SHA Key。如果扩展到多个集群，针对文件配置如何处理？&lt;/p&gt;

&lt;p&gt;A：对于文件配置，在同步 SHA Key 后，通过单独的线程，从源数据中心 S3 集群进行文件加载，同步到本地 S3 集群。&lt;/p&gt;

&lt;p&gt;如果从源数据中心的 S3 集群加载失败，则按照顺序（BJ &amp;gt; HL &amp;gt; SH &amp;gt; HK）降级进行重新拉取。&lt;/p&gt;

&lt;h1 id=&quot;5其他补充&quot;&gt;5、其他补充&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/28131829#id-%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D&quot;&gt;https://km.sankuai.com/page/28131829#id-%E6%9E%B6%E6%9E%84%E4%BB%8B%E7%BB%8D&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/600429548&quot;&gt;https://km.sankuai.com/page/600429548&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://dbaplus.cn/news-11-1399-1.html&quot;&gt;https://dbaplus.cn/news-11-1399-1.html&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1407987923&quot;&gt;https://km.sankuai.com/collabpage/1407987923&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/1476581664&quot;&gt;https://km.sankuai.com/page/1476581664&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/page/617657890&quot;&gt;https://km.sankuai.com/page/617657890&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://km.sankuai.com/collabpage/1532367225&quot;&gt;https://km.sankuai.com/collabpage/1532367225&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1、文档概述</summary></entry><entry><title type="html">Google Dapper</title><link href="http://localhost:4000/dapper.html" rel="alternate" type="text/html" title="Google Dapper" /><published>2023-01-17T00:00:00+08:00</published><updated>2023-01-17T00:00:00+08:00</updated><id>http://localhost:4000/dapper</id><content type="html" xml:base="http://localhost:4000/dapper.html">&lt;h1 id=&quot;1-abstract&quot;&gt;1-Abstract&lt;/h1&gt;

&lt;p&gt;现代互联网服务通常是用&lt;strong&gt;复杂的，大规模的分布式集群&lt;/strong&gt;来实现的。这些服务通常由不同的软件模块组成，而这些模块可能由不同的团队开发，使用不同的编程语言，也有可能分布在数千台机器上，横跨多个数据中心。因此，需要一些可以帮助&lt;strong&gt;理解系统行为，用于分析性能问题&lt;/strong&gt;的工具。&lt;/p&gt;

&lt;p&gt;Dapper 是 Google 生产环境下分布式跟踪系统，满足了&lt;strong&gt;低消耗&lt;/strong&gt;（low overhead），&lt;strong&gt;应用层透明&lt;/strong&gt;（application-level transparency），&lt;strong&gt;大范围部署&lt;/strong&gt;（ubiquitous deployment on a very large scale system）三个需求。&lt;/p&gt;

&lt;h1 id=&quot;2-introduction&quot;&gt;2-Introduction&lt;/h1&gt;

&lt;p&gt;构建 Dapper 的目的是为了给开发者提供更多&lt;em&gt;关于复杂分布式系统的行为信息&lt;/em&gt;。这类系统特别受关注，因为那些大规模的低端服务器，作为互联网服务的载体，是一个特殊的经济划算的平台。为了在上下文中理解分布式系统的行为，就需要监控那些横跨了不同的应用、不同服务器之间的操作。&lt;/p&gt;

&lt;p&gt;网络搜索的例子将会说明此类监控系统需要解决的一些挑战。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一个前端服务可能会将一次网络查询分发给数百个查询服务器，每一个查询都有自己的 Index。查询请求也可能被发送到多个子系统中，这些子系统也许用来处理广告，拼写检查，或者查询图片，视频，新闻等特殊结果。对这些服务的返回结果选择性地组合到结果页面；这种搜索模型被称为&lt;strong&gt;全局搜索&lt;/strong&gt;（universal search）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总的来说，一次全局搜索查询可能需要数千台机器，多个不同的服务参与处理。同时，用户对搜索延迟是比较敏感的，任何子系统的低性能都可能会导致延迟增大。&lt;/p&gt;

&lt;p&gt;只看整体的延迟，工程师可能会知道全局搜索流程存在问题，但是可能&lt;em&gt;无法判断哪个服务存在问题，或者为什么性能较差&lt;/em&gt;。原因可能有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无法准确知道此次全局搜索涉及哪些服务&lt;/li&gt;
  &lt;li&gt;工程师对涉及的服务并不总是很了解&lt;/li&gt;
  &lt;li&gt;涉及的服务或者机器可能同时被其他客户端访问，所以性能问题可能是由于其他应用的影响&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;上述描述的案例给出了 Dapper 的两个基本要求：&lt;strong&gt;1. 无处不在的部署；2. 持续的监控&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;无处不在的特性是很重要的，因为如果某个系统的很小一部分没有被监控到，那么追踪系统的可用性就会被严重影响&lt;/li&gt;
  &lt;li&gt;另外，监控需要一直开启，因为经常会遇到很难或不可能重现异常或值得注意的系统行为&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这些要求产生了三个具体的设计目标：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;低消耗&lt;/strong&gt;（low overhead）：追踪系统应该对正在运行的服务产生可以忽略不计的性能影响。对于某些高度优化后的服务来说，即使很小的监控负载也能被察觉到，有可能会迫使业务团队将监控系统关闭。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;应用层透明&lt;/strong&gt;（application-level transparency）：开发人员不需要感知到追踪系统的存在；一个依赖应用层开发人员积极合作才能有序运行的追踪系统会变得很脆弱（不可靠），可能会由于机器的问题或者代码的疏忽导致整个系统中断，从而违反普遍存在的要求。在像我们这样的快节奏开发环境中，这一点尤其重要。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;（scalability）：该系统必须能够处理 Google 接下来几年的服务和集群的规模。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一个额外的设计目标是，&lt;strong&gt;对于用于分析的数据，在其生成之后需要尽可能快地可以得到&lt;/strong&gt;，理想的时间是一分钟内。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;尽管基于数小时数据的追踪分析系统也是有一定的价值，但是最新数据的可用性能够使得对产生的异常有更快的反应。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;真正的应用级透明设计目标也许是最大的挑战：通过把&lt;em&gt;核心跟踪代码做的很轻巧，然后把它植入到那些无所不在的公共组件中&lt;/em&gt;，比如线程调用、控制流以及 RPC 库来实现该目标。通过使用&lt;strong&gt;&lt;em&gt;自适应采样&lt;/em&gt;&lt;/strong&gt;来使系统更具可扩展性，同时降低性能开销。结果展示的相关系统也包含一些用来收集跟踪数据的代码，用来图形化的工具，以及用来分析大规模跟踪数据的库和 API。&lt;/p&gt;

&lt;h1 id=&quot;3-distributed-tracing-in-dapper&quot;&gt;3-Distributed Tracing in Dapper&lt;/h1&gt;

&lt;p&gt;分布式服务的追踪系统需要记录一次特定请求后系统中所有完成的工作信息。&lt;/p&gt;

&lt;p&gt;下图给出了一个示例，一个与五台服务器相关的服务，包括一个前端（A），两个中间层（B，C），两个后端（D，E）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个用户请求到达前端时，发送两个 RPC 请求到 B，C。B 可以立即响应，但是 C 需要与后端的 D，E 交互之后再响应 A，最后由 A 来相应最初的请求。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;对这样的请求，一个简单实用的分布式追踪系统的实现，就是为服务器上&lt;em&gt;每一次发送和接收动作&lt;/em&gt;收集&lt;strong&gt;信息标识符&lt;/strong&gt;（message identifier）和&lt;strong&gt;事件时间戳&lt;/strong&gt;（timestamped event）。&lt;/p&gt;

&lt;p&gt;为了&lt;em&gt;将所有记录条目与特定的请求发起者关联起来并记录所有信息&lt;/em&gt;，有两种解决方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;黑盒&lt;/strong&gt;（black-box）模型
    &lt;ul&gt;
      &lt;li&gt;假设除了上述消息记录外没有其他额外信息，使用统计回归技术推断两者之间的关系&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/strong&gt;：由于依赖统计推断，为了获得更高的准确性，就需要更多的数据&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;优点&lt;/em&gt;&lt;/strong&gt;：比基于标注的模型更加轻便&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;基于标注&lt;/strong&gt;（annotation-based）的模型
    &lt;ul&gt;
      &lt;li&gt;依赖应用或者中间件明确标记一个全局 ID，从而将每条消息记录与原始请求连接起来&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;&lt;em&gt;缺点&lt;/em&gt;&lt;/strong&gt;：需要代码植入&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在 Google 的开发环境中，所有的应用程序都是用同一种线程模型，控制流与 RPC 系统，因此可以&lt;strong&gt;&lt;em&gt;把代码植入限制在一个很小的通用组件库中，实现一套对开发人员有效透明的监控系统&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;我们倾向于将 Dapper 追踪系统看作类似嵌套在 RPC 调用的树形结构。 然而，我们的核心数据模型并不局限于特定的 RPC 框架，还需要追踪其他活动，如 Gmail 中的 SMTP 会话、来自外部的 HTTP 请求以及 SQL 查询。 &lt;strong&gt;形式上，我们使用 Trees, Spans &amp;amp; Annotations 对 Dapper 追踪系统进行建模&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-1-trace-trees-and-spans&quot;&gt;3-1 Trace trees and spans&lt;/h2&gt;

&lt;p&gt;在 Dapper 追踪树中，树节点是 Span 的基本工作单元。&lt;strong&gt;节点之间的连线表示一个 Span 与其父 Span 之间的因果关系&lt;/strong&gt;。不过，Span 在更大的树形结构中是相对独立的，&lt;strong&gt;一个 Span 就是简单的时间戳日志，记录了 Span 的开始时间与结束时间&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;下图说明了多个 Span 如何组成更大的追踪树。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Dapper 记录了每个 Span 的 &lt;em&gt;Name，ID，Parent ID&lt;/em&gt;，以便在单个分布式追踪链路中重建各个 Span 的因果关系。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;没有 Parent ID 的 Span 被称为 Root Span&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;一个追踪链路上的所有 Span 共享一个公共 Trace ID&lt;/strong&gt;（全局唯一的 64 位整数；图中并未展示）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在一个典型的 Dapper 追踪链路中，期望将每一个 RPC 调用对应一个单一的 Span，每一个额外的组件层都对应一个额外的树形结构的层级。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;补充，即每个 Span 看作一次 RPC 调用；每一层看作一个额外的组件&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;下图给出了典型 Dapper Trace Span 中记录事件（log event）更详细的视图。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;该图描述了图 2 中两个 RPC（Helper.Call）调用中跨度较长 Span&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Span 的开始时间（start time），结束时间（end time）以及任何 RPC 调用中的计时信息（timing information）都是由 Dapper 的 RPC 组件库记录的。&lt;/p&gt;

&lt;p&gt;如果应用程序开发者想要在 Trace 中添加自定义的注释（annotation, 如图中的 “foo”）以记录业务信息，这些信息也会和其他 Span 数据一样被记录下来。&lt;/p&gt;

&lt;p&gt;值得注意的是，&lt;strong&gt;&lt;em&gt;一个 Span 可以包含来自多个主机（host）的信息&lt;/em&gt;&lt;/strong&gt;。事实上，每个 RPC Span 都包含来自客户端与服务端进程的信息，这使得链接两个主机（two-host）的 Span 成为最常见的类型。&lt;/p&gt;

&lt;p&gt;由于客户端进程与服务端进程的时间戳（timestamp）来自不同的主机，因此我们必须要注意&lt;strong&gt;时钟漂移&lt;/strong&gt;（clock skew）。在我们的分析工具中，我们利用了这样一个事实，即 &lt;em&gt;RPC 客户端总是在服务端接收请求之前发送请求&lt;/em&gt;，反过来对服务端响应流程也是一样。 这样，我们可以得出 &lt;strong&gt;RPC 服务器端 Span 时间戳的下限和上限&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-2-instrumentation-points&quot;&gt;3-2 &lt;strong&gt;Instrumentation points&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 可以通过&lt;strong&gt;几乎零侵入成本&lt;/strong&gt;来实现对分布式路径的追踪（基本完全依赖于少量组件库的改造）常见的植入点有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;当一个线程处理一个被追踪的路径时，Dapper 会将&lt;em&gt;追踪上下文&lt;/em&gt;（context）附加到线程本地（thread local）存储。追踪上下文是一个轻量且易于复制的 Span 属性容器，这些属性包括 Span ID, Trace ID&lt;/li&gt;
  &lt;li&gt;当计算过程是延迟调用或是异步的，大多数 Google 开发者通过线程池或其他执行器，使用一个通用的控制流库来回调。Dapper 确保所有这样的回调可以存储这次跟踪的上下文，而当回调函数被触发时，这次跟踪的上下文会与适当的线程关联上。在这种方式下，Dapper 可以使用 Trace ID 和 Span ID 来辅助构建异步调用的路径&lt;/li&gt;
  &lt;li&gt;几乎所有的 Google 进程间通信都是建立在一个 RPC 调用框架上，支持 C++ 与 Java。我们已经使用该框架来定义所有 RPC Span。对于被追踪的 RPC，Span ID 与 Trace ID 会从客户端发送到服务端。像这样在 Google 内部被广泛使用的，以 RPC 通信为基础的系统，这是一个重要的植入点。我们计划在非 RPC 通信框架中找到用户群并对其进行植入&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dapper 的追踪数据是&lt;strong&gt;语言无关的&lt;/strong&gt;（language-independent），许多追踪数据同时包含了来自 C++ 与 Java 编写的进程。&lt;/p&gt;

&lt;h2 id=&quot;3-3--annotations&quot;&gt;3-3  &lt;strong&gt;Annotations&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;上述植入点足以推导出复杂分布式系统的追踪细节，使得 Dapper 核心功能可以应用于未经改造的 Google 应用。然而，&lt;strong&gt;Dapper 还允许用户添加额外的信息来丰富 Dapper 追踪数据&lt;/strong&gt;，这些被添加的信息可以用来监控更高级别的系统行为或者用于问题调试。&lt;/p&gt;

&lt;p&gt;我们允许用户通过简单的 API 定义&lt;strong&gt;带时间戳的 Annotation&lt;/strong&gt;（timestamped annotations），核心用法如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Annotation 中可以包含任意内容&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;为了避免用户过度添加 Annotation 记录，&lt;em&gt;每个 Dapper Span 都有一个可配置的 Annotation 总量上限&lt;/em&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;需要注意，不管应用程序行为如何，应用层面的 Annotation 都不能代替用于表示 Span 结构的信息或者 RPC 信息&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;除了简单的文本 Annotation，Dapper 还支持 &lt;strong&gt;Key-Value 型 Annotation&lt;/strong&gt;，可以为用户提供更多的追踪能力，如维护计数器，记录二进制信息，在进程内传输任意用户定义数据以及跟踪请求。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key-Value 型 Annotation 用来在分布式追踪的上下文中&lt;strong&gt;&lt;em&gt;定义某个特定应用程序的相关类型&lt;/em&gt;&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-4-sampling&quot;&gt;3-4 &lt;strong&gt;Sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;低负载（low overhead）是 Dapper 的一个关键设计目标。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果对服务性能有重大影响，那么用户是不愿意部署使用的。&lt;/li&gt;
  &lt;li&gt;我们希望允许用户使用 Annotation API 而不用担心额外的性能开销。&lt;/li&gt;
  &lt;li&gt;我们也发现有些 Web 服务确实对植入带来的性能开销比较敏感。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，除了使 Dapper 收集的基本植入性能开销尽可能小之外，我们还通过&lt;strong&gt;仅记录所有追踪的一小部分来进一步控制性能开销&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;3-5-trace-collection&quot;&gt;3-5 &lt;strong&gt;Trace Collection&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 追踪记录和收集是三阶段（three-stage）处理流程。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Span 数据被写入本地日志文件&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dapper 守护进程及收集组件把这些数据从所有主机中拉取出来&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;收集到的数据被写入 BigTable 仓库中&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;一次 Trace 被设计成 Bigtable 中的一行，每一列相当于一个 Span。Bigtable 支持稀疏表格的布局正适合这种情况，因为每一次跟踪可以有任意多个 Span。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Trace 数据收集（即从应用中的二进制数据传输到中央仓库所花费的时间）的延迟中位数少于 15 秒。TP98 延迟往往随着时间的推移呈现双峰型；大约 75% 的时间，TP98 延迟时间小于 2 分钟，但是另外大约 25% 的时间，可以增涨到几个小时。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Dapper 还提供了一个 API 来简化访问 BigTable 仓库中的 Trace 数据。 用户通过该 API，可以构建通用和特定应用程序的分析工具。&lt;/p&gt;

&lt;h3 id=&quot;3-5-1-out-of-band-trace-collection&quot;&gt;3-5-1 &lt;strong&gt;Out-of-band trace collection&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Dapper 通过请求树实现 Trace 数据（in-band）及带外数据（out-of-band）收集。这么做是出于两个不相关的原因：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;带内数据（in-band）收集方案会影响应用程序的网络动态：Trace 数据会在 RPC 响应头中携带。在 Google 的许多大型系统中，一次 Trace 中包含数千个 Span 是很常见的。然而，RPC 响应仍可能相对比较小，经常小于 10KB。这样， Dapper 带内的 Trace 数据会让应用程序数据和倾向于使用后续分析结果的数据量相形见绌，并使后续分析的结果产生偏差。&lt;/li&gt;
  &lt;li&gt;带内数据收集方案假设所有 RPC 调用都是完美嵌套的。我们发现，在所有后端系统返回最终结果之前，有许多中间件会把结果返回给他们的调用者。&lt;em&gt;带内收集系统是无法解释这种非嵌套的分布式执行模式的&lt;/em&gt;。&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;带外数据：传输层协议使用带外数据(out-of-band，OOB)来发送一些重要的数据,如果通信一方有重要的数据需要通知对方时,协议能够将这些数据快速地发送到对方。为了发送这些数据，协议一般不使用与普通数据相同的通道,而是使用另外的通道。&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;这里指的 in-band 策略是把跟踪数据随着调用链进行传送，out-of-band 是通过其他的链路进行跟踪数据的收集，Dapper 的写日志然后进行日志采集的方式就属于 out-of-band 策略&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h1 id=&quot;4-managing-tracing-overhead&quot;&gt;4-&lt;strong&gt;Managing Tracing Overhead&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;追踪系统的成本被认为包含：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;由于追踪数据生成和收集开销而导致的被监视系统的性能下降&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;存储和分析跟踪数据所需的资源量&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
  &lt;p&gt;尽管有人会说有价值的追踪系统值得性能损耗，但是我们仍相信如果基线开销可以忽略不计，那么将会极大的促进业务使用率&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;接下来将主要介绍 &lt;strong&gt;Dapper 植入操作的开销&lt;/strong&gt;，&lt;strong&gt;Trace 数据收集的开销&lt;/strong&gt;，以及 Dapper 对业务负载的影响。同时，还会介绍 Dapper 自适应采样机制如何平衡低性能损耗的需求与对代表性 Trace 追踪的需求。&lt;/p&gt;

&lt;h2 id=&quot;4-1-trace-generation-overhead&quot;&gt;4-1 &lt;strong&gt;Trace generation overhead&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Trace 生成开销是 Dapper 性能损耗中最关键的部份，因为 Trace 数据收集及分析可以在紧急情况下被关掉。&lt;/p&gt;

&lt;p&gt;Trace 生成开销主要来源有以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Span 的创建及销毁&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;将 Span 信息记录到本地磁盘，以便后续收集&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Root Span 创建及销毁平均需要 204 ns，非 Root Span 创建及销毁需要 176 ns；差别的原因是 需要给 Root Span 分配一个全局唯一的 Trace ID&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;如果不对 Span 进行追踪采样，那么额外的 Span Annotation 成本几乎可以忽略不计，包括 Dapper 运行时线程本地查找（平均耗时 9ns）。如果对 Span 进行追踪采样，那么会用字符串文本进行注释追踪 ???。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If it is sampled, annotating the trace with a string literal&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;将 Span 数据写入本地磁盘时 Dapper 运行时库最昂贵的操作，但是这部分损耗被大大减少，因为日志写入操作相对于被追踪的应用程序时异步执行的。然而，日志写入操作会对高吞吐量应用程序性能产生明显影响，尤其是在所有请求都被追踪的情况下。&lt;/p&gt;

&lt;h2 id=&quot;4-2-trace-collection-overhead&quot;&gt;4-2 &lt;strong&gt;Trace collection overhead&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;读取本地 Trace 数据也会对被追踪的前台应用负载有影响。下表展示了压力测试情况下 Dapper 守护进程的 CPU 使用率。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Dapper 守护进程在数据收集期间 CPU 使用率不超过 0.3%，并且内存占用非常小。同时我们也会将 Dapper 守护进程的内核调度优先级设置的尽可能低，以防止在高负载的主机中出现 CPU 争用的情况&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;Dapper 也是一个轻量级的带宽资源消费者，每个 Span 平均为 426 Byte；Dapper 数据收集流量仅占 Google 生产环境网络流量的不到 0.01%。&lt;/p&gt;

&lt;h2 id=&quot;4-3-effect-on-production-workloads&quot;&gt;4-3 &lt;strong&gt;Effect on production workloads&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;有些请求都会涉及到大量高吞吐量的线上服务，这是对有效追踪最主要的需求之一；这些请求往往会生成大量的追踪数据，同时它们对性能干扰也最敏感。在下表中，我们使用网络搜索集群作为这类服务的一个示例，当我们改变 Trace 采样率时，评估 Dapper 对平均延迟与吞吐量的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/dapper/dapper_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到，虽然对吞吐量的影响不是很明显，但是为了避免明显的延迟增加，Trace 采样确实很有必要。在实践中我们发现，即使使用 1/1024 的采样率，对于请求量大的服务仍然能够产生足够的 Trace 数据。&lt;/p&gt;

&lt;p&gt;将 Dapper 的基线开销降低很重要，因为用户可以使用全部范围的 Annotation API，而不必担心性能损耗。使用低采样率还有一个额外的好处，Trace 数据可以在主机被回收之前在磁盘上保存更长的时间，这为数据 Trace 数据收集设施提供了更大的灵活性。&lt;/p&gt;

&lt;h2 id=&quot;4-4-adaptive-sampling&quot;&gt;4-4 &lt;strong&gt;Adaptive sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Dapper 进程开销与单位时间处理 Trace 数据量成正比。Dapper 第一版对 Google 内所有进程使用统一的采样率 (1/1024)，这个简单的方案对高吞吐量的在线服务很有效，因为绝大多数我们感兴趣的事件可能经常会出现，足以被捕获。&lt;/p&gt;

&lt;p&gt;然而，有些低吞吐量（低负载）的服务可能会在低采样率的情况下错过一些重要的事件；同时，这类服务可以容忍高采样率带来的性能损耗。对于这类系统，解决方案是覆盖默认的采样率；对于这种需要手动干预的情况是我们在 Dapper 中力求避免的。&lt;/p&gt;

&lt;p&gt;我们正在部署一种自适应采样模型，该方案不是采用统一的采样率参数，而是使用一个采样期望率来标识单位时间内的采样。这样，&lt;strong&gt;低流量的服务会自动提高采样率，而高流量的服务会自动降低采样率，从而使采样开销保持在可控的范围内&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;4-5-coping-with-aggressive-sampling&quot;&gt;4-5 &lt;strong&gt;Coping with aggressive sampling&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;新的 Dapper 用户经常想知道低采样率是否会干扰他们的分析（在高吞吐量的服务下经常低至 0.01％）。Google 的经验让我们相信，激进的采样（aggressive sampling）并不会妨碍重要的分析：如果一个值得注意的时间在一个系统中出现一次，那么它将会出现很多次。对于流量比较小的服务（每秒处理几十个请求，而不是几万个请求），可以接受对每个请求进行监控。这就是我们决定采用自适应采样率的原因。&lt;/p&gt;

&lt;h1 id=&quot;5-experiences&quot;&gt;5-&lt;strong&gt;Experiences&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Dapper 在 Google 内部被广泛应用，一部分直接通过 Dapper 的用户界面，另一部分间接地通过对 Dapper API 的二次开发或者建立在基于 API 的应用上。在本节中，我们并不打算罗列出每一种已知的 Dapper 使用方式，而是试图覆盖 Dapper 使用方式的“基本向量”，并努力来说明什么样的应用是最成功的。&lt;/p&gt;

&lt;h2 id=&quot;5-1-using-dapper-during-development&quot;&gt;5-1 &lt;strong&gt;Using Dapper during development&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Google AdWords 系统是围绕一个关键词定位准则和相关文字广告的大型数据库搭建的。当新的关键字或广告被插入或修改时，它们必须通过服务策略术语的检查（如检查不恰当的语言）；这个过程如果使用自动复查系统来做的话会更加有效。&lt;/p&gt;

&lt;p&gt;当设计一个 Ads Review 服务时，这个团队迭代的从第一个系统原型开始使用 Dapper，并且最终用 Dapper 一直维护着他们的系统。Dapper 帮助他们从以下几个方面改进了他们的服务：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;性能（performance）&lt;/strong&gt;：开发人员针对请求延迟的目标进行跟踪，并对容易优化的地方进行定位。Dapper 也被用来确定在关键路径上不必要的串行请求（通常来源于不是开发者自己开发的子系统）并促使相关团队持续修复。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;正确性（correctness）&lt;/strong&gt;：Ads Review 服务围绕大型数据库系统搭建。系统同时具有只读副本（访问成本低）和读写主节点（访问成本高）两种方式。Dapper 用于识别一些不必要地向主节点而不是副本发出查询的情况。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;理解性（understanding）&lt;/strong&gt;：Ads Review 查询跨越了各种类型的系统，包括 BigTable，以及其他各种 C++，Java 后端服务。Dapper 数据追踪可以用来评估总查询成本，促进重新对业务的设计，从而减少系统依赖性负载。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;测试（testing）&lt;/strong&gt;：新代码发布通过 Dapper 跟踪 QA 流程，验证系统行为的正确性和性能，在这个过程中发现了许多问题，包括 Ads Review 服务代码本身和依赖库中的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;5-2-addressing-long-tail-latency&quot;&gt;5-2 &lt;strong&gt;Addressing long tail latency&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;由于移动部件（moving parts）的数量，代码库的大小，部署的范围，使得调试类似通用搜索这样的服务具有非常大的挑战性。接下来，我们将描述为了降低通用搜索延迟分布的长尾效应所做出的努力。&lt;/p&gt;

&lt;p&gt;Dapper 能够验证关于端到端延迟的假设，更具体来说，能够验证通用搜索请求的关键路径。当系统不仅涉及数十个子系统，而且涉及数十个开发团队时，即使最优秀，最有经验的工程师也不能准确判断导致端到端性能较差的根本原因。在这种情况下，Dapper 可以提供急需的数据，并且能够对许多重要的性能问题的出结论。&lt;/p&gt;

&lt;h2 id=&quot;5-3-inferring-service-dependencies&quot;&gt;5-3 &lt;strong&gt;Inferring service dependencies&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;在任何给定的时间内，Google 内部的一个典型的计算集群是一个汇集了成千上万个逻辑“任务”的主机，一套的处理器在执行一个通用的方法。Google 维护着许多这样的集群，事实上，我们发现在一个集群上计算着的这些任务通常依赖于其他的集群上的任务。由于任务之间的依赖是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。同时，在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及计划服务的迁移。&lt;/p&gt;

&lt;p&gt;Google 内部被称为 “Service Dependencies” 的项目是通过使用 Trace Annotation 和 Dapper API MapReduce 接口来实现自动化确定服务依赖。&lt;/p&gt;

&lt;p&gt;Dapper 核心组件与 Dapper  Trace Annotation 一起使用的情况下，“Service Dependencies” 项目能够推算出任务各自之间的依赖，以及任务和其他组件之间的依赖。&lt;/p&gt;

&lt;h2 id=&quot;5-4-layered-and-shared-storage-systems&quot;&gt;5-4 &lt;strong&gt;Layered and Shared Storage Systems&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Google 的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google 的 App Engine 就是搭建在一个可扩展的实体存储系统上的。该实体存储系统基于 BigTable 上公开某些RDBMS 功能。BigTable 同时使用Chubby 及 GFS。而且，像 BigTable 这样的系统简化了部署，并更好的利用了计算资源。&lt;/p&gt;

&lt;p&gt;在这种分层的系统，并不总是很容易确定最终用户资源的消费模式。例如，来自给定 BigTable 单元的大量 GFS 流量可能主要来自一个用户或多个用户，而在 GFS 层面，这两种不同使用模式之间的差异是模糊的。而且，如果缺乏像 Dapper 这样的工具，对此类共享服务的竞争可能会同样难以调试。&lt;/p&gt;

&lt;p&gt;Dapper 的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息，这就很容易让提供这些服务的源从多个维度给他们的用户排名（例如，入站的网络负载，出站的网络负载，或服务请求的总时间）。&lt;/p&gt;

&lt;h1 id=&quot;6-conclusions&quot;&gt;6-&lt;strong&gt;Conclusions&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;在本文中，我们介绍 Dapper 这个 Google 生产环境下的分布式系统跟踪平台，并汇报了我们开发和使用它的相关经验。&lt;/p&gt;

&lt;p&gt;Dapper 几乎在部署在 Google 所有系统上，并可以在&lt;strong&gt;不需要应用级修改的情况下进行跟踪，而且没有明显的性能影响&lt;/strong&gt;。Dapper 对于开发人员和运维团队带来的好处，可以从我们主要的跟踪用户界面的广泛使用上看出来，另外我们还列举了一些 Dapper 使用用例来说明 Dapper 的作用，这些用例有些甚至都没有 Dapper 开发团队参与，而是被应用的开发者开发出来的。&lt;/p&gt;

&lt;p&gt;我们相信，&lt;strong&gt;Dapper 比以前基于 Annotation 的分布式跟踪达到更高的应用透明度&lt;/strong&gt;，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。&lt;/p&gt;

&lt;p&gt;最后，通过开放 Dapper 仓库给内部开发者，促使了更多基于 Dapper 的分析工具的产生。&lt;/p&gt;</content><author><name>kkzhang</name></author><category term="system-design" /><summary type="html">1-Abstract</summary></entry><entry><title type="html">2022 Summary</title><link href="http://localhost:4000/summary-2022.html" rel="alternate" type="text/html" title="2022 Summary" /><published>2023-01-15T00:00:00+08:00</published><updated>2023-01-15T00:00:00+08:00</updated><id>http://localhost:4000/summary_2022</id><content type="html" xml:base="http://localhost:4000/summary-2022.html">&lt;blockquote&gt;
  &lt;p&gt;来上海三年多，第一次（2023-01-15）见到那么大的雪&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;如果用一个词表达今年的状态，那就是”&lt;strong&gt;焦虑&lt;/strong&gt;“。&lt;/p&gt;

&lt;p&gt;每个时间段焦虑的原因不同，持续的时间也不一样；但是接连不断的焦虑感让自己感觉压力不小。好在所有的事情最终都有一个比较满意的结果，也算苦尽甘来。&lt;/p&gt;

&lt;p&gt;今年比较跌宕，但收获也很多，个别比较重要的事情也都按照自己的预期有所进展，整体还是比较知足的。&lt;/p&gt;

&lt;h2 id=&quot;晋升&quot;&gt;晋升&lt;/h2&gt;

&lt;p&gt;晋升带给自己的焦虑算是最大的了，毕竟直接影响自己接下来的职业规划。从晋升准备到晋升答辩，整个过程冗长繁琐，令人疲惫，中途甚至想放弃，还好最终晋升成功，而且答辩排名在所有候选人中处于前列。&lt;/p&gt;

&lt;p&gt;在美团两年多，职级体系，晋升政策一直在变化，导致自己今年才有晋升机会。&lt;/p&gt;

&lt;p&gt;按照去年的政策，今年晋升应该安排在 5，6 月份（2022 年上半年绩效评估前），那么自己上半年理论上需要投入更多的精力在准备晋升材料，答辩等；对上半年绩效结果可以不那么在意，工作方面就可以投入较少的精力；但是再一次出现了晋升政策调整：晋升时间调整到下半年（7，8，9月份）。&lt;/p&gt;

&lt;p&gt;对自己来说，之前的规划就出现偏差：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;2021 年绩效整体还行，如果只看 2021 年两次绩效结果，对晋升概率还是有一定把握。&lt;/li&gt;
  &lt;li&gt;调整为 2022 年下半年晋升，那就会将 2022 H1 的绩效纳入评估范围。如果 2022 H1 的绩效一般，那么自己的竞争力会有所下降；因此，之前制定的划水策略行不通了，需要在 2022 H1 拿到一个不错的绩效才行。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;于是，在 202204 跟 Leader 的一次 1 on 1 中规划了下接下来的工作重点，为了在 2022H1 拿到一个满意的绩效结果，自己需要承担一项重要紧急且困难的推动工作，如果该工作交付结果达成预期，那么自己的绩效也会达到自己的目标；反之只能拿到一个一般的绩效。所以，在沟通之后，自己准备放手一搏了。经过两个多月的推动，基本投入了 100% 的人力，克服各种未知困难，最终工作进展超出预期，绩效也超出了预期。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;没想到这个工作在下半年还在推动，只是方向有所调整&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;至此，绩效方面可以成为比较强有力的晋升支撑，晋升成功看起来也许是水到渠成了。不过，晋升政策再次出现调整，晋升流程，比例，答辩策略等都发生了变化，每个步骤都需要严格卡控比例。在见识到一个绩效优秀的同事提前被卡掉之后，自己对晋升结果也保持了悲观态度，开始积极寻求其他机会了。政策的多次调整，让自己对整个晋升体系感到失望，对接下来的工作也表现出比较消极的态度。在美团两年多，主 R 了多个重点工作，也都拿到了超出预期的结果与绩效，如果最终晋升失败，我大概率不会反思自己能力不够，毕竟我做到了自己能做的最优解。&lt;/p&gt;

&lt;p&gt;持续两个多月的晋升材料准备，答辩，结果等待，最终晋升成功了，并且排名 Top。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;其实答辩刚结束的时候，Leader 基本可以判断出我晋升没问题，只是一直没说；反而从其他几个 Leader 中得到令人满意的反馈&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;晋升结果公布之后，就是晋升调薪了。不出意外，在互联网整体不景气的情况下，调薪比例不是特别高，不过自己也拿到了应该是最高档的比例，还算满意吧。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;晋升通过只给了现金调整，并没有给股票，反而在晋升前的 4，5 月份给了聊胜于无的股票，让我对美团的激励政策的理解又不清楚了&lt;/p&gt;

&lt;/blockquote&gt;

&lt;p&gt;回顾来看，焦虑多半是由公司晋升政策调整 + 不稳重的心态引发的，自己执迷于晋升最初是想给两年多的努力工作一个交代；但是，这个所谓的交代重要吗，如果自己晋升失败，大不了明年再来或者直接换一家公司，薪资涨幅肯定要比晋升带来的多。在与 Leader  1 on 1 中也提到了自己应该更加稳重，对于这一点还是比较认同。不管是工作还是生活，自己很容易情绪化，不利于后续的发展提升，在接下来的工作中需要努力改变。&lt;/p&gt;

&lt;h2 id=&quot;工作&quot;&gt;工作&lt;/h2&gt;

&lt;p&gt;为了在 2022H1 拿到满意的绩效，自己承担了一个重要任务，没想到竟然占据了我一年 50% 以上的人力投入，并且还将要在 2023 年继续投入。&lt;/p&gt;

&lt;p&gt;这个工作简单来说就是因为各种原因需要下线一个老系统，虽然目标比较明确，但是其中的各种问题没有一个成熟的经验，只能不断摸索调整。&lt;/p&gt;

&lt;p&gt;在上半年的时候，主要以 A 方向去推动，需要与公司内部大部分业务进行沟通。为了降低业务风险及成本，需要做很多前期准备工作，人力投入非常大。好在中后期与一些平台方建立了合作关系，多方一起去推动，最终拿到一个满意的结果。&lt;/p&gt;

&lt;p&gt;在下半年的时候，意识到 A 方向对最终目标达成影响较小，经过多次讨论，最终调整为 B 方向。此时涉及的业务基本是公司所有业务了，其中的业务风险更大。为了降低风险，制定了多阶段策略，先解决低风险业务，再推动高风险业务。虽然最终结果与既定目标有所偏差，但是整体还是有了长足的进步，拿到一定的成果。&lt;/p&gt;

&lt;p&gt;这个老系统下线工作之前持续了1，2 年，但是进展缓慢，并且后续如何下线一直没有明确的方案。自己接手之后，也是抱着死马当活马医的态度，做得了就做，做不了就算了。由于下线风险高，历史包袱重，涉及业务面广，业务情况复杂等各种原因，自己在推动前做了很多准备工作，但是对真正的实施方案并没有把握，只能走一步看一步，随时调整策略。在那段时间里，自己也是睡眠不足，总是想着如何尽快拿到结果。好在最终进展得到多方面的认可，努力付出也得到了回报。&lt;/p&gt;

&lt;p&gt;回想一下，这个工作很难，让自己身心疲惫，但是也确实因此收获颇丰：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;中长期任务规划能力提升&lt;/li&gt;
  &lt;li&gt;业务沟通能力提升&lt;/li&gt;
  &lt;li&gt;满意的绩效结果&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;生活&quot;&gt;生活&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;疫情&lt;/p&gt;

    &lt;p&gt;2022 年初，上海因为疫情封控了 3 个多月，自己一个人在出租屋里封闭了 3 个多月。回想这段时间，真是煎熬，每天吃着相同且味道寡淡的饭菜，还要担心明天能不能吃饱，详细规划每天的食物量，每天早晨准时抢菜，切身体会到粮食的重要性。一粒米真的能饿死一个国家。&lt;/p&gt;

    &lt;p&gt;解封之后，由于各地政策限制，无法自由出入，一些事情并没有按照预期在发展。&lt;/p&gt;

    &lt;p&gt;2022 年尾，全国疫情管控放开，不出意外地感染了，幸运的是症状不是很严重，大概三天就恢复了。&lt;/p&gt;

    &lt;p&gt;因为疫情，2022 年变得很魔幻。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;女朋友&lt;/p&gt;

    &lt;p&gt;女朋友今年毕业，一直在准备考编。期间有希望，有挫败，她这一年比我更焦虑，压力也更大。好在最终考上了相对比较满意的单位，也要开始下一段人生旅程。&lt;/p&gt;

    &lt;p&gt;今年我们都再次见了双方父母，感情也更进了一步，一切都在稳步前进。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;学习&lt;/p&gt;

    &lt;p&gt;今年专业知识学习主要集中在上半年，主要集中在分布式系统及 Linux 内核，看的论文比预期少。下半年更专注工作与生活，基本没有专业知识的学习。&lt;/p&gt;

    &lt;blockquote&gt;
      &lt;p&gt;上半年翻译了一篇课程，并在公司内分享了&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;锻炼&lt;/p&gt;

    &lt;p&gt;在 2022 年尾感染新冠之前，一直保持锻炼，身材也比较稳定。阳康之后，再也没有重新锻炼了，预计等过年回来重新开始。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;投资&lt;/p&gt;

    &lt;p&gt;以基金为主，暂时少量投入，长期持有，整体不亏不盈。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="annual-summary" /><summary type="html">来上海三年多，第一次（2023-01-15）见到那么大的雪</summary></entry><entry><title type="html">供给，需求与政府政策</title><link href="http://localhost:4000/principles-of-economics-3.html" rel="alternate" type="text/html" title="供给，需求与政府政策" /><published>2022-10-22T00:00:00+08:00</published><updated>2022-10-22T00:00:00+08:00</updated><id>http://localhost:4000/principles-of-economics-3</id><content type="html" xml:base="http://localhost:4000/principles-of-economics-3.html">&lt;h1 id=&quot;价格控制&quot;&gt;价格控制&lt;/h1&gt;

&lt;p&gt;在一个没有政府管制的竞争市场上，冰淇淋的价格将自发调整，使得供求达到平衡：均衡价格时，买者想买的冰淇淋数目等于卖者想卖的冰淇淋数目。&lt;/p&gt;

&lt;p&gt;不过，政府可以对冰淇淋的价格进行控制：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;价格上限&lt;/strong&gt;：出售一种物品的法定最高价格&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;价格下限&lt;/strong&gt;：出售一种物品的法定最低价格&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;价格上限对市场的影响&quot;&gt;价格上限对市场的影响&lt;/h2&gt;

&lt;p&gt;假设在没有政府干预的情况下，冰淇淋的均衡价格为 3 美元。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;非限制性价格上限&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设价格上限为 4 美元，此时均衡价格低于价格上限，那么该价格上限是非限制性的，&lt;strong&gt;价格上限对价格或者销售量没有影响&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;限制性价格上限&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设价格上限为 2 美元，此时均衡价格高于价格上限，那么该价格上限是限制性的。&lt;/p&gt;

    &lt;p&gt;这种情况下，&lt;strong&gt;供给小于需求，冰淇淋出现短缺&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;当由于价格上限而导致短缺时，一些配给机制会出现：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;购买者排长队，愿意提前来并等候的人可以买到冰淇淋&lt;/li&gt;
      &lt;li&gt;卖者根据自己的偏好来配给冰淇淋&lt;/li&gt;
    &lt;/ul&gt;

    &lt;blockquote&gt;
      &lt;p&gt;设置价格上限的动机是为了帮助买者，但是并不是所有买者都能从中受益，存在一些买者根本买不到冰淇淋&lt;/p&gt;

    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;结论：&lt;strong&gt;当政府对竞争市场实行限制性价格上限时，就产生了物品短缺，而且卖者必须在大量潜在买者中配给稀缺商品&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;在自由市场中，价格用来配给商品&lt;/p&gt;

&lt;/blockquote&gt;

&lt;h2 id=&quot;价格下限对市场的影响&quot;&gt;价格下限对市场的影响&lt;/h2&gt;

&lt;p&gt;假设在没有政府干预的情况下，冰淇淋的均衡价格为 3 美元。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;非限制性价格下限&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设价格下限为 2 美元，低于均衡价格，此时价格下限没有限制作用；市场力量自然地使价格向均衡价格移动。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;限制性价格下限&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;假设价格下限为 4 美元，高于均衡价格，此时价格下限存在限制性约束。&lt;/p&gt;

    &lt;p&gt;这种情况下，&lt;strong&gt;供给大于需求，冰淇淋出现过剩&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;价格下限引发的过剩也会导致不合意的配给机制：&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;买者由于个人偏好可以选择产品&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;对价格控制的评价&quot;&gt;对价格控制的评价&lt;/h2&gt;

&lt;p&gt;在经济学中，价格时隐藏在供给曲线和需求曲线背后的千百万企业和消费者决策的结果，价格有平衡供求从而协调经济活动的关键作用。&lt;em&gt;当决策者通过法令确定价格时，就模糊了正常情况下指引社会资源配置的信号&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;价格控制的目标往往是帮助穷人，但是&lt;strong&gt;往往会损害哪些它本想帮助的人&lt;/strong&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;租金控制可以保持低租金，但是无法鼓励房东修缮住房，并使找房变得困难&lt;/li&gt;
  &lt;li&gt;最低工资可以增加一些工人的收入，但是也会使其他工人成为失业者&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;税收&quot;&gt;税收&lt;/h1&gt;

&lt;p&gt;当政府对一种物品征税时，谁实际上承担了税收负担？买者？卖者？还是两者共同承担？&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;税收归宿&lt;/strong&gt;（tax incidence）是指税收负担如何在组成市场的不同人之间分配。&lt;/p&gt;

&lt;h2 id=&quot;向卖者征税对市场的影响&quot;&gt;向卖者征税对市场的影响&lt;/h2&gt;

&lt;p&gt;假设政府规定，向冰淇淋卖者卖出的每个冰淇淋征收 0.5 美元的税收。那么将如何影响卖者和买者？&lt;/p&gt;

&lt;p&gt;可以按照分析供求的三个步骤：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;确定该法律影响的是供给曲线还是需求曲线&lt;/li&gt;
  &lt;li&gt;确定曲线移动的方向&lt;/li&gt;
  &lt;li&gt;考察这种移动如何影响均衡价格和数量&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;第一步：税收对卖者产生直接影响，因此使&lt;strong&gt;供给曲线移动&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;第二步：对卖者征税提高了生产和销售冰淇淋的成本，因此征税减少了每一种价格下的供给量，使&lt;strong&gt;供给曲线左移（或者说上移）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;供给曲线移动幅度：在每一种供给量下，卖者必须将价格提高 0.5 美元，以便弥补税收的影响。因此，供给曲线从 S1 向上移动到 S2，&lt;strong&gt;移动幅度正好是税收量&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;第三步：在新平衡下，冰淇淋价格由 3 美元上升为 3.3 美元；均衡数量由 100 个减少到 90 个。卖者的销售量减少了，买者的购买量也减少了，因此&lt;strong&gt;税收缩小了冰淇淋市场的规模&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;回到税收归宿问题，谁支付了税收？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;买者：购买价格增加了 0.3 美元&lt;/li&gt;
  &lt;li&gt;卖者：销售价格虽然为 3.3 美元，但是交税后的有效价格为 3.3 - 0.5 = 2.8 美元，比之前的 3 美元少了 0.2 美元&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因此，我们可以得出两个结论：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;税收抑制了市场活动&lt;/strong&gt;：物品在新均衡的销售量减少了&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;买者与卖者分摊了税收负担&lt;/strong&gt;：在新均衡时，买者支付更多，卖者得到更少&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;向买者征税对市场的影响&quot;&gt;向买者征税对市场的影响&lt;/h2&gt;

&lt;p&gt;假设政府规定，向冰淇淋买者购买的每个冰淇淋征收 0.5 美元的税收。那么将如何影响卖者和买者？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;仍然按照三个步骤分析：&lt;/p&gt;

&lt;p&gt;第一步：向买者征税，直接影响需求，使得&lt;strong&gt;需求曲线移动&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;第二步：征税使买者在每一价格下的冰淇淋的需求量减少，使得需&lt;strong&gt;求曲线向左移动（或者说向下移动）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;需求曲线移动幅度：买者关注的是包括税收在内的总成本，因此在每一种需求量下，市场价格必须降低 0.5 美元，以弥补税收的影响。因此，税收使需求曲线从 D1 向下移动到 D2，移动幅度正好是税收量（0.5 美元）。&lt;/p&gt;

&lt;p&gt;第三步：在新平衡下，均衡价格由 3 美元下降到 2.8 美元；均衡数量由 100 下降到 90，冰淇淋市场规模缩小。同时，买者与卖者分摊了税收负担。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;买者：购买成本 2.8 + 0.5 = 3.3 美元&lt;/li&gt;
  &lt;li&gt;卖者：销售价格由 3 美元降低到 2.8 美元&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;结论：&lt;strong&gt;对卖者征税和对买者征税使相同的：在新均衡下，买者和卖者共同承担了税收负担&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&quot;弹性与税收归宿&quot;&gt;弹性与税收归宿&lt;/h2&gt;

&lt;p&gt;对物品征税时，由卖者与买者共同分摊税收负担，但是如何准确划分？&lt;/p&gt;

&lt;p&gt;税收负担更多地落在缺乏弹性的市场一方身上：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;当供给比需求更富有弹性时，税收更多地由消费者承担&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;当需求比供给更富有弹性时，税收更多地由生产者承担&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap6/eco_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;总结&quot;&gt;总结&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;价格上限是某种物品与服务的法定最高价格；价格下限是某种物品与服务的法定最低价格&lt;/li&gt;
  &lt;li&gt;当政府对一种物品征收税收时，该物品的均衡数量减少，市场规模缩小&lt;/li&gt;
  &lt;li&gt;税收归宿并不取决于向卖者征税还是向买者征税；税收归宿取决于供给和需求的价格弹性，税收负担更多地落在缺乏弹性的市场一方&lt;/li&gt;
&lt;/ol&gt;</content><author><name>kkzhang</name></author><category term="economics" /><summary type="html">价格控制</summary></entry><entry><title type="html">供给与需求的市场力量</title><link href="http://localhost:4000/principles-of-economics-2.html" rel="alternate" type="text/html" title="供给与需求的市场力量" /><published>2022-07-21T00:00:00+08:00</published><updated>2022-07-21T00:00:00+08:00</updated><id>http://localhost:4000/principles-of-economics-2</id><content type="html" xml:base="http://localhost:4000/principles-of-economics-2.html">&lt;p&gt;&lt;strong&gt;供给&lt;/strong&gt;与&lt;strong&gt;需求&lt;/strong&gt;是使市场经济运行的力量，它们决定了每种物品的产量及出售价格。&lt;/p&gt;

&lt;h1 id=&quot;市场与竞争&quot;&gt;市场与竞争&lt;/h1&gt;

&lt;p&gt;供给与需求这两个术语是指人们在&lt;strong&gt;竞争市场&lt;/strong&gt;上相互交易时的行为。&lt;/p&gt;

&lt;h2 id=&quot;什么是市场&quot;&gt;什么是市场&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;市场&lt;/strong&gt;（market）是&lt;em&gt;由某种物品或者服务的买者与卖者组成的一个群体&lt;/em&gt;。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;买者决定了产品的需求&lt;/li&gt;
  &lt;li&gt;卖者决定了产品的供给&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;市场有多种形式：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;组织健全的市场&lt;/strong&gt;：如农产品市场上，买者与卖者在特定的时间与地点聚集在一起，同时市场上还有一些拍卖者协助确定价格并安排销售&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;没有组织的市场&lt;/strong&gt;：如某个小镇的冰淇淋市场，买者与卖者并没有在特定时间聚集在一起，冰淇淋卖者分散在各个地方并提供略有差异的产品，各个卖者标出冰淇淋价格，而各个买者决定在每个店中买多少冰淇淋&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;什么是竞争&quot;&gt;什么是竞争&lt;/h2&gt;

&lt;p&gt;大多数市场是高度竞争的。以冰淇淋市场为例，每个买者都知道有一些卖者可供选择，并且每个卖者也认识到其提供的产品与其他卖者提供的产品是相似的。因此，冰淇淋价格并不是由任何一个买者或者卖者决定的。确切地说，&lt;strong&gt;&lt;em&gt;冰淇淋的价格和销售量是由所有买者和卖者通过在市场上相互交易而共同决定的&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;竞争市场&lt;/strong&gt;（competitive market）：&lt;em&gt;有许多买者和卖者，以至于每个人对市场价格的影响都微乎其微的市场&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;完全竞争市场是竞争市场的最高形式，该市场必须具备两个特征：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;可供销售的物品是完全相同的&lt;/li&gt;
  &lt;li&gt;买者与卖者人数众多，以至于没有任何一个买者和卖者可以影响市场价格&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在完全竞争市场中，买者和卖者必须接受市场决定的价格，被称为价格接受者。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;垄断市场&lt;/strong&gt;：一些市场只有一个卖者，而这个卖者决定市场价格。&lt;/p&gt;

&lt;h1 id=&quot;需求&quot;&gt;需求&lt;/h1&gt;

&lt;h2 id=&quot;需求曲线价格与需求量之间的关系&quot;&gt;需求曲线：价格与需求量之间的关系&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;需求量&lt;/strong&gt;（quantity demanded）：买者愿意并且能够购买的一种物品的数量。&lt;/p&gt;

&lt;p&gt;需求量由很多因素决定，其中最主要的因素是物品的&lt;strong&gt;价格&lt;/strong&gt;。&lt;em&gt;在其他条件不变时，一种物品的价格上升，则对该物品的需求量减少；一种物品的价格下降，则对该物品的需求量降低&lt;/em&gt;，被称为&lt;strong&gt;需求定理&lt;/strong&gt;（law of demand）。&lt;/p&gt;

&lt;p&gt;把价格与需求联系在一起的曲线被称为&lt;strong&gt;需求曲线&lt;/strong&gt;（demand curve）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;市场需求与个人需求&quot;&gt;市场需求与个人需求&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;市场需&lt;/strong&gt;求是&lt;em&gt;所有人对某个特定物品或服务的需求总和&lt;/em&gt;。同样，市场需求曲线表示在所有影响消费者购买数量的其他因素不变时，一种物品的需求总量与该物品价格的关系。&lt;/p&gt;

&lt;h2 id=&quot;需求曲线的移动&quot;&gt;需求曲线的移动&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;如果某种因素改变了既定价格下的需求量，需求曲线就会移动&lt;/em&gt;&lt;/strong&gt;（之前我们假设其他因素保持不变）。例如：假如研究发现经常吃冰淇淋有助于身体健康，那么这个发现会增加对冰淇淋的需求。在现有价格下，买者会购买更多的冰淇淋，因此需求曲线就会移动。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;使每一种价格水平下的需求量增加的任何变动，都会使需求曲线向右移动，称之为&lt;strong&gt;需求增加&lt;/strong&gt;。&lt;/li&gt;
  &lt;li&gt;使每一种价格水平下的需求量减少的任何变动，都会使需求曲线向左移动，称之为&lt;strong&gt;需求减少&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有许多因素会导致需求曲线移动：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;收入&lt;/li&gt;
  &lt;li&gt;相关物品价格&lt;/li&gt;
  &lt;li&gt;爱好&lt;/li&gt;
  &lt;li&gt;预期&lt;/li&gt;
  &lt;li&gt;购买者数量&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;需求曲线表示在&lt;strong&gt;其他&lt;/strong&gt;所有影响买者的&lt;strong&gt;变量保持不变&lt;/strong&gt;的情况下，一种&lt;strong&gt;物品的价格变动时，该物品的需求量会发生什么变动&lt;/strong&gt;。当这些&lt;strong&gt;变量&lt;/strong&gt;中的一个&lt;strong&gt;变动&lt;/strong&gt;时，&lt;strong&gt;需求曲线会发生移动&lt;/strong&gt;。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;变量&lt;/th&gt;
      &lt;th&gt;变量的变动将导致&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;价格&lt;/td&gt;
      &lt;td&gt;沿着需求曲线变动&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;收入，相关物品价格，爱好，预期，买者数量&lt;/td&gt;
      &lt;td&gt;使需求曲线移动&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;供给&quot;&gt;供给&lt;/h1&gt;

&lt;h2 id=&quot;供给曲线价格与供给量之间的关系&quot;&gt;供给曲线：价格与供给量之间的关系&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;供给量&lt;/strong&gt;（quantity supplied）：卖者愿意并且能够出售的该种物品的数量。&lt;/p&gt;

&lt;p&gt;决定供给量的因素有很多，价格仍然起着主要作用。价格与供给量之间的关系被称为&lt;strong&gt;供给定理&lt;/strong&gt;（law of supply）：&lt;em&gt;在其他条件不变时，一种物品价格上升，该物品供给量增加；一种物品价格下降，该物品供给量减少&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;把价格与供给量联系在一起的曲线被称为&lt;strong&gt;供给曲线&lt;/strong&gt;（supply curve）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;市场供给与个人供给&quot;&gt;市场供给与个人供给&lt;/h2&gt;

&lt;p&gt;与市场需求一样，市场供给是所有卖者供给的总和。&lt;/p&gt;

&lt;h2 id=&quot;供给曲线移动&quot;&gt;供给曲线移动&lt;/h2&gt;

&lt;p&gt;供给曲线是假设其他条件不变时，价格与供给量之间的关系；但是当其他因素发生变化时，供给曲线将发生移动。例如，糖的价格下降了，会增加冰淇淋的供给：在任何一种既定价格水平下，卖者愿意生产更多的冰淇淋，冰淇淋的供给曲线向右移动。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在既定价格水平下，使供给量增加的任何一种变动（如，糖价格下降），都会使供给曲线向右移动，称之为&lt;strong&gt;供给增加&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;在既定价格水平下，使供给量减少的任何一种变动，都会使供给曲线左移，称之为&lt;strong&gt;供给减少&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有许多变量会使供给曲线发生移动，包括：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;投入品价格&lt;/li&gt;
  &lt;li&gt;技术&lt;/li&gt;
  &lt;li&gt;预期&lt;/li&gt;
  &lt;li&gt;卖者数量&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结-1&quot;&gt;总结&lt;/h2&gt;

&lt;p&gt;供给曲线表示在&lt;strong&gt;其他&lt;/strong&gt;所有影响卖者的&lt;strong&gt;变量保持不变&lt;/strong&gt;的情况下，一种物品&lt;strong&gt;价格变动&lt;/strong&gt;时，该物品的供给量会发生什么变动。当这些&lt;strong&gt;变量&lt;/strong&gt;中的一个&lt;strong&gt;变动&lt;/strong&gt;时，&lt;strong&gt;供给曲线就会发生移动&lt;/strong&gt;。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;变量&lt;/th&gt;
      &lt;th&gt;变量的变动将导致&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;价格&lt;/td&gt;
      &lt;td&gt;沿着供给曲线的变动&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;技术，投入品价格，预期，卖者数量&lt;/td&gt;
      &lt;td&gt;使供给曲线移动&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;供给与需求的结合&quot;&gt;供给与需求的结合&lt;/h1&gt;

&lt;h2 id=&quot;均衡&quot;&gt;均衡&lt;/h2&gt;

&lt;p&gt;市场价格达到使供给量与需求量相等的水平时的状态被称为&lt;strong&gt;均衡状态&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;均衡价格&lt;/strong&gt;：使供给与需求平衡的价格；&lt;strong&gt;均衡数量&lt;/strong&gt;：均衡价格下的供给量与需求量。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;供给曲线与需求曲线相交于一点，该点被称为市场的均衡。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;在均衡价格时，买者愿意并且能够购买的物品数量正好与卖者愿意并且能够卖出的数量相等&lt;/em&gt;。均衡价格有时候也会被称为&lt;strong&gt;市场出清价格&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;买者与卖者的行为自然而然地使市场向供给与需求的均衡变动。当市场价格不等于均衡价格时，物品会表现为过剩或者短缺，并使市场达到均衡为止。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;过剩&lt;/strong&gt;：&lt;em&gt;供给量大于需求量&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;当市场价格高于均衡价格时，会使得供给量大于需求量，此时物品就会出现过剩。&lt;/p&gt;

    &lt;p&gt;卖者对过剩的反应时降低其价格。当价格下降时，会使需求量增加，供给减少。&lt;/p&gt;

    &lt;p&gt;这种变化表现为沿着供给与需求曲线的变动，而不是曲线的移动。价格会持续下降，最终市场达到均衡。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;短缺&lt;/strong&gt;：&lt;em&gt;需求量大于供给量&lt;/em&gt;&lt;/p&gt;

    &lt;p&gt;当市场价格低于均衡价格时，会使得需求量大于供给量，此时物品就会出现短缺。&lt;/p&gt;

    &lt;p&gt;由于太多的买者抢购太少的物品，卖者可以提高物品价格。当价格提高时，引起需求减少，供给增加。&lt;/p&gt;

    &lt;p&gt;这种变化表现为沿着供给和需求曲线移动，并推动市场走向均衡。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

    &lt;p&gt;在大多数自由市场上，价格最终都要变动到其均衡水平，过剩与短缺都只是暂时的。&lt;em&gt;任何物品的价格都会自发调整，使该物品的供给与需求达到平衡&lt;/em&gt;，被称为&lt;strong&gt;供求定理&lt;/strong&gt;（law of supply and demand）。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;分析均衡变动的步骤&quot;&gt;分析均衡变动的步骤&lt;/h2&gt;

&lt;p&gt;当分析某个事件如何影响一个市场上的均衡时，按照三个步骤进行：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;确定该事件是使供给曲线移动还是时需求曲线移动&lt;/strong&gt;（或者两者均移动）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;确定曲线移动的方向&lt;/strong&gt;（左还是右）&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;用供求图来说明这种移动如何改变均衡价格与均衡数量&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;例由需求移动引起的市场均衡变动&quot;&gt;例：由需求移动引起的市场均衡变动&lt;/h3&gt;

&lt;p&gt;假设某年夏季天气特别炎热，这种情况如何影响冰淇淋市场？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;天气炎热改变了需求曲线，人们在既定价格下想要购买更多的冰淇淋。供给曲线不会变，因为天气并不直接影响销售企业&lt;/li&gt;
  &lt;li&gt;由于既定价格下需求增多，所以需求曲线向右移动&lt;/li&gt;
  &lt;li&gt;在原有价格下，需求 &amp;gt; 供给（因为需求增多，而不是供给减少），引起短缺，因此卖家提高冰淇淋价格，达到新的均衡。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;整体来看，&lt;strong&gt;&lt;em&gt;天气炎热提高了冰淇淋价格，增加了冰淇淋的销售量&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;曲线的移动与沿着曲线的移动&quot;&gt;曲线的移动与沿着曲线的移动&lt;/h3&gt;

&lt;p&gt;我们注意到，当天气炎热时，冰淇淋需求增加，并使其价格上升；尽管供给曲线不变，但是供给数量增加了。这种情况下，我们称为，&lt;strong&gt;“供给量”增加，但是“供给不变”&lt;/strong&gt;。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;供给是指供给曲线的位置，供给量是指供给者希望出售的数量&lt;/p&gt;

&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;供给曲线的移动&lt;/strong&gt;被称为“&lt;strong&gt;供给变动&lt;/strong&gt;”，&lt;strong&gt;需求曲线的移动&lt;/strong&gt;被称为“&lt;strong&gt;需求变动&lt;/strong&gt;”&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;沿着固定的供给曲线变动&lt;/strong&gt;被称为“&lt;strong&gt;供给量的变动&lt;/strong&gt;”，&lt;strong&gt;沿着固定需求曲线的变动&lt;/strong&gt;被称为“&lt;strong&gt;需求量的变动&lt;/strong&gt;”&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;例由供给移动引起的市场均衡变动&quot;&gt;例：由供给移动引起的市场均衡变动&lt;/h3&gt;

&lt;p&gt;假设在另一个夏季，台风摧毁了部分甘蔗田，使得糖的价格上升，这个事件如何影响冰淇淋市场？&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;糖作为冰淇淋的投入品，其价格上升影响了供给曲线，企业在既定价格下减少冰淇淋的供给。需求曲线没变。&lt;/li&gt;
  &lt;li&gt;供给曲线向左移动&lt;/li&gt;
  &lt;li&gt;在原有价格下，供给 &amp;lt; 需求（因为供给减少，而不是需求增多），引起短缺，因此卖家提高冰淇淋价格，达到新的均衡。&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;整体来看，糖的价格上升，导致冰淇淋的价格上升，但是销售量减少了&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/images/economics/chap4/eco_9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;当供给或需求移动时价格和数量将如何变化&quot;&gt;当供给或需求移动时，价格和数量将如何变化？&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;供给未变&lt;/th&gt;
      &lt;th&gt;供给增加&lt;/th&gt;
      &lt;th&gt;供给减少&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;需求未变&lt;/td&gt;
      &lt;td&gt;价格相同 数量相同&lt;/td&gt;
      &lt;td&gt;价格下降 数量增加&lt;/td&gt;
      &lt;td&gt;价格上升 数量减少&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;需求增加&lt;/td&gt;
      &lt;td&gt;价格上升 数量增加&lt;/td&gt;
      &lt;td&gt;数量增加 价格不定&lt;/td&gt;
      &lt;td&gt;价格上升 数量不定&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;需求减少&lt;/td&gt;
      &lt;td&gt;价格下降 数量减少&lt;/td&gt;
      &lt;td&gt;价格下降 数量不定&lt;/td&gt;
      &lt;td&gt;价格不定 数量减少&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1 id=&quot;结论价格如何配置资源&quot;&gt;结论：价格如何配置资源&lt;/h1&gt;

&lt;p&gt;在市场经济中，价格是配置稀缺资源的机制。对于经济中的每种物品来说，价格确保供给与需求达到平衡。均衡价格决定了买者选择购买多少这种物品，以及卖者选择生产多少这种物品。&lt;/p&gt;</content><author><name>kkzhang</name></author><category term="economics" /><summary type="html">供给与需求是使市场经济运行的力量，它们决定了每种物品的产量及出售价格。</summary></entry><entry><title type="html">编程珠玑: 算法设计技术</title><link href="http://localhost:4000/programming-pearls-8.html" rel="alternate" type="text/html" title="编程珠玑: 算法设计技术" /><published>2022-06-19T00:00:00+08:00</published><updated>2022-06-19T00:00:00+08:00</updated><id>http://localhost:4000/programming-pearls-8</id><content type="html" xml:base="http://localhost:4000/programming-pearls-8.html">&lt;h2 id=&quot;问题描述&quot;&gt;问题描述&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;输入&lt;/strong&gt;：具有 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; 个浮点数的向量 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;输出&lt;/strong&gt;：输入向量的任意连续子向量的最大和。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;示例&lt;/strong&gt;：输入向量 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; 为 [31, -41, 59, 26, -53, 58, 97, -93, -23, 84]，那么该程序输出为 x[2…6] 的总和。&lt;/p&gt;

&lt;h2 id=&quot;分析&quot;&gt;分析&lt;/h2&gt;

&lt;p&gt;当所有数都是正数时，问题比较简单，此时最大子向量就是整个输入向量。&lt;/p&gt;

&lt;p&gt;当输入向量中含有负数时，是否应该包含某个负数并期望旁边的正数会弥补它呢？&lt;/p&gt;

&lt;p&gt;为了使问题定义更加完整，假设所有的输入都是负数时，最大子向量为空向量，总和为 0.&lt;/p&gt;

&lt;h2 id=&quot;on3-算法&quot;&gt;O(n^3) 算法&lt;/h2&gt;

&lt;p&gt;该问题最直接的解法是对所有满足 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0 ≤ i ≤ j &amp;lt; n&lt;/code&gt; 的 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(i, j)&lt;/code&gt; 整数对进行迭代。对每个整数对，都需要计算 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[i, j]&lt;/code&gt; 的总和，并判断此时该和是否是迄今为止最大的和。&lt;/p&gt;

&lt;p&gt;代码比较简单，但是运行速度很慢。&lt;/p&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// sum is sum of x[i...j]&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;on2-算法&quot;&gt;O(n^2) 算法&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;我们注意到，&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[i...j]&lt;/code&gt; 的总和与前面已经计算出的总和 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[i...j-1]&lt;/code&gt; 相关，利用该关系可以得到第一个平方算法。&lt;/p&gt;

    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// sum is sum of x[i...j]&lt;/span&gt;
 	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 		&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;另一种平方算法是提前计算 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[0...i]&lt;/code&gt; 各个数累加的和。&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cumarr[i]&lt;/code&gt; 表示 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[0...i]&lt;/code&gt; 中各个数的累加和，则 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x[i..j]&lt;/code&gt; 的累加和可以通过 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;cumarr[j] - cumarr[i-1]&lt;/code&gt; 得到。&lt;/p&gt;

    &lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; &lt;span class=&quot;n&quot;&gt;cumarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 	&lt;span class=&quot;n&quot;&gt;cumarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
 &lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
 &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
 		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cumarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;cumarr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// sum is sum of x[i...j]&lt;/span&gt;
 		&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;分治算法onlogn&quot;&gt;分治算法：O(nlogn)&lt;/h2&gt;

&lt;p&gt;前面讨论的算法考虑了所有的子向量，并计算每个子向量中的所有数的和。由于存在 O(n^2) 个子向量，因此至少需要 O(n^2) 的运行时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;分治法原理&lt;/strong&gt;：&lt;em&gt;要解决规模为 n 的问题，可以递归地解决两个规模近似为 n/2 的子问题，然后对它们的答案进行合并可以得到整个问题的答案&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;在本问题中，我们将大小为 n 的向量分解为两个大小近似的子向量 a, b，之后递归地找出 a, b 中的最大子向量 ma, mb。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;整个向量的最大子向量为 ma：子向量在 a 中&lt;/li&gt;
  &lt;li&gt;整个向量的最大子向量为 mb：子向量在 b 中&lt;/li&gt;
  &lt;li&gt;整个向量的最大子向量为 mc：子向量跨越 a, b 之间的边界&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;float&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// zero elements&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// one element&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// find max crossing to left&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;lmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;lmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// find max crossing to right&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;rmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;rmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lmax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;扫描算法on&quot;&gt;扫描算法：O(n)&lt;/h2&gt;

&lt;p&gt;扫描算法是从数组的最左端（x[0]）开始扫描，一直到最右端（x[n-1]），并记下所遇到的总和最大的子向量。&lt;/p&gt;

&lt;p&gt;假设已经解决了 x[0…i-1] 的问题，如何将其扩展为包含 x[i] 的问题？&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;类似分治算法原理：前 i 个元素中，最大总和的子向量要么在前 i-1 个元素中（maxsofar），要么其结束位置为 i（maxendinghere）&lt;/p&gt;

    &lt;table&gt;
      &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt; &lt;/th&gt;
          &lt;th&gt;maxsofar&lt;/th&gt;
          &lt;th&gt; &lt;/th&gt;
          &lt;th&gt;maxendinghere&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt; &lt;/td&gt;
          &lt;td&gt;i&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-c highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;maxendinghere&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// maxendinghere 一开始为结束位置为 x-1 的最大子向量的和，此处将其更新为结束位置为 i 的最大子向量的和&lt;/span&gt;
	&lt;span class=&quot;c1&quot;&gt;// 如果加上 x[i] 之后仍然为正值，那么 maxendinghere 则加上 x[i]；否则将 maxendinghere 设置为 0（空向量）&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;maxendinghere&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxendinghere&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxsofar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maxendinghere&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;原理&quot;&gt;原理&lt;/h2&gt;

&lt;p&gt;上述几个算法给出了几个重要的算法设计技术：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;保存状态，避免重复计算：动态规划&lt;/li&gt;
  &lt;li&gt;分治算法&lt;/li&gt;
  &lt;li&gt;扫描算法&lt;/li&gt;
  &lt;li&gt;将信息预处理至数据结构中&lt;/li&gt;
&lt;/ul&gt;</content><author><name>kkzhang</name></author><category term="algrithom" /><summary type="html">问题描述</summary></entry><entry><title type="html">编程珠玑: 编程小事</title><link href="http://localhost:4000/programming-pearls-5.html" rel="alternate" type="text/html" title="编程珠玑: 编程小事" /><published>2022-06-11T00:00:00+08:00</published><updated>2022-06-11T00:00:00+08:00</updated><id>http://localhost:4000/programming-pearls-5</id><content type="html" xml:base="http://localhost:4000/programming-pearls-5.html">&lt;h3 id=&quot;脚手架&quot;&gt;脚手架&lt;/h3&gt;

&lt;p&gt;使用脚手架更方便地访问函数；最简单的脚手架是命令行技术&lt;/p&gt;

&lt;h3 id=&quot;编码&quot;&gt;编码&lt;/h3&gt;

&lt;p&gt;首先使用伪代码构建程序框架，然后将伪代码翻译成要实现的语言&lt;/p&gt;

&lt;h3 id=&quot;测试&quot;&gt;测试&lt;/h3&gt;

&lt;p&gt;在脚手架中对组件进行测试；通过脚手架对程序进行自动化测试&lt;/p&gt;

&lt;h3 id=&quot;调试&quot;&gt;调试&lt;/h3&gt;

&lt;p&gt;不管是脚手架还是真实运行环境，调试工作总是很困难的&lt;/p&gt;

&lt;h3 id=&quot;计时&quot;&gt;计时&lt;/h3&gt;

&lt;p&gt;对程序执行时间进行计时，确保程序能够达到我们预期的性能&lt;/p&gt;

&lt;h3 id=&quot;断言的艺术&quot;&gt;断言的艺术&lt;/h3&gt;

&lt;p&gt;断言既可以知道程序的代码开发，也可以用来判断程序的正确性。我们可以将断言插入代码中，以确保程序运行时的行为与我们的理解一致&lt;/p&gt;</content><author><name>kkzhang</name></author><category term="algrithom" /><summary type="html">脚手架</summary></entry></feed>