I"<h1 id="无主节点复制">无主节点复制</h1>

<p>单主节点 &amp; 多主节点复制中，客户端先向主节点发送写请求，然后系统将写请求复制到其他副本。对于无主节点复制，选择放弃主节点，允许任何副本直接接收来自客户端的请求。</p>

<blockquote>
  <p>亚马逊的 Dynamo 系统是无主复制的典型</p>
</blockquote>

<p>在有些无主节点系统中，客户端直接将写请求发送到多副本；而在另一些系统中，由一个协调者节点代表客户端进行写入。</p>

<h2 id="节点失效时写入数据库">节点失效时写入数据库</h2>

<p>对于主从复制模型，主节点失效时，如果想继续处理写操作，那么需要先进行节点切换；对于无主节点模型，则不需要节点切换。</p>

<p><img src="/images/ddia_7_1.png" alt="" /></p>

<ol>
  <li>客户端将<strong>写请求并行发送给三个副本</strong>，有两个副本可以正常处理请求，而失效的副本无法处理。如果两个正常工作的节点可以成功确认写操作，那么客户端收到两个确认之后，即可认为写入成功；完全忽律其中一个副本无法写入的情况。</li>
  <li>失效的节点重新工作后，在其失效期间的数据尚未同步，此时用户可能会访问到过期的数据。因此，当客户端读取数据时，将<strong>读请求并行发送给三个副本</strong>；多个副本的响应结果可能不同，可以通过版本号等技术确定哪个值更新。</li>
</ol>

<h3 id="读修复--反熵">读修复 &amp; 反熵</h3>

<p>复制模型应该确保所有数据最终复制到所有副本上。为了保证失效节点重新追上错过的写请求，经常使用两种机制：</p>

<ol>
  <li>
    <p><strong>读修复</strong></p>

    <p>当客户端并行读取多个副本时，可以检测到过期的返回值；因而可以<strong>将新值写入该副本</strong>，这种方法适合频繁读取的场景。</p>
  </li>
  <li>
    <p><strong>反熵过程</strong></p>

    <p>通过一些后台进程不断查找副本之间的数据差异，<strong>将任何缺少的数据从一个副本复制到另一副本</strong>。</p>

    <blockquote>
      <p>与基于主节点复制的复制日志不同，反熵过程并不保证数据以特定的顺序复制写入，并且会引入明显的滞后。</p>
    </blockquote>
  </li>
</ol>

<p>有的系统可能没有实现反熵过程，那么当缺少反熵过程时，由于读修复只在发生读取时才能执行修复，那么对于一些很少访问的数据来说，有可能在某些副本中已经丢失而无法被检测到，从而降低写的持久性。</p>

<h3 id="读写-quorum">读写 quorum</h3>

<p>一般情况下，<strong>如果有 n 个副本，写入需要 w 个节点确认，读取至少查询 r 个节点，则只要 w + r &gt; n，那么读取的节点中一定会包含最新值</strong>。在之前的例子中，n = 3, w = 2, r = 2；满足上述这些 r, w 的读写操作称之为<em>法定票数读（仲裁读）或法定票数写（仲裁写</em>）。</p>

<blockquote>
  <p>r &amp; w 是用于判断读写是否有效的最低票数；通常 w = r =(n+1)/2</p>
</blockquote>

<p>仲裁条件 w + r &gt; n 定义了系统可容忍的失效节点书：</p>

<ul>
  <li>w &lt; n，如果一个节点不可用，仍然可以处理写入</li>
  <li>r &lt; n，如果一个节点不可用，仍然可以处理读取</li>
  <li>假定 n = 3, w = 2, r = 2，则可以容忍一个节点不可用</li>
  <li>假定 n = 5, w = 3, r = 3，则可以容忍两个不可用的节点</li>
</ul>

<blockquote>
  <p>通常，读取与写入总是并行发送到所有的 n 个副本；参数 w &amp; r 只是决定要等待的节点数，即有多少个节点需要返回结果，才能判断出结果的正确性</p>
</blockquote>

<p><img src="/images/ddia_7_2.png" alt="" /></p>

<p>如果可用节点数小于 w 或者 r，那么写入或者读取就会返回错误。</p>

<h2 id="quorum-一致性的局限性">Quorum 一致性的局限性</h2>

<p>w + r &gt; n 使客户端能够获取最新值是因为，成功写入的节点集合和读取的节点集合必然有重合，这样读取的节点中至少又一个具有最新值。</p>

<p>通常会假定 w &amp; r 为大多数（多于 n / 2）节点，此时能够容忍 n / 2 个节点故障；但是 quorum 并不一定非得是多数，读写的节点集中又一个重叠的节点才是关键。</p>

<p>如果 w + r ≤ n，此时可以获得更低的延迟和更高的可用性；但是读取请求中可能恰好没有包含最新值的节点，客户端就会获取一个过期的旧值。</p>

<p>不过，即使满足 w + r &gt; n，也可能存在返回旧值的边界条件：</p>

<ul>
  <li>如果采用了 sloppy quorum，那么<em>写操作的 w 个节点和读取的 r 个节点可能完全不同</em>，因此无法保证读写请求一定存在重叠的节点</li>
  <li>如果写操作与读操作同时发生，写操作肯跟仅在一部分副本上完成，此时读取返回是旧值还是新值存在不确定性</li>
  <li>如果某些副本写入成功，其他副本写入失败，且成功副本数 &lt; n，哪些成功的副本不会进行回滚；那么后续的读仍可能返回新值</li>
  <li>两个写操作同时发生，无法明确先后顺序；这种情况下采用了 Last Write Win 方案，此时可能会把新值给抛弃</li>
</ul>

<p>虽然 Quorum 设计上似乎可以保证读取最新值，但是实际情况往往更加复杂。</p>
:ET